# -*- coding: utf-8 -*-
# åœ¨æœ€å¼€å§‹å°±ç¦ç”¨SSLè­¦å‘Š
import os
# è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨SSLè­¦å‘Š
os.environ['PYTHONWARNINGS'] = 'ignore:Unverified HTTPS request'
os.environ['URLLIB3_DISABLE_WARNINGS'] = '1'

import warnings
warnings.filterwarnings('ignore', message='Unverified HTTPS request')
warnings.filterwarnings('ignore', message='.*certificate verification.*')
warnings.filterwarnings('ignore', message='.*SSL.*')
warnings.filterwarnings('ignore', category=UserWarning, module='urllib3')

import logging.handlers
import os
import sys
import asyncio
import logging
import logging
logging.getLogger("telethon").setLevel(logging.WARNING)
from pathlib import Path
from urllib.parse import urlparse
from typing import Optional, Dict, Any
from enum import Enum
from dataclasses import dataclass
import time
import threading
import requests
import urllib3
# ç«‹å³ç¦ç”¨urllib3çš„SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å°è¯•ç¦ç”¨å…¶ä»–å¯èƒ½å­˜åœ¨çš„SSLè­¦å‘Š
try:
    urllib3.disable_warnings(urllib3.exceptions.SubjectAltNameWarning)
except AttributeError:
    pass  # è¯¥è­¦å‘Šç±»å‹ä¸å­˜åœ¨ï¼Œå¿½ç•¥

try:
    urllib3.disable_warnings(urllib3.exceptions.InsecurePlatformWarning)
except AttributeError:
    pass  # è¯¥è­¦å‘Šç±»å‹ä¸å­˜åœ¨ï¼Œå¿½ç•¥

try:
    urllib3.disable_warnings(urllib3.exceptions.SNIMissingWarning)
except AttributeError:
    pass  # è¯¥è­¦å‘Šç±»å‹ä¸å­˜åœ¨ï¼Œå¿½ç•¥

import re
import uuid
import mimetypes
import json
import subprocess
from telethon import TelegramClient, types
from telethon.sessions import StringSession
from telegram import (
    Update,
    InputFile,
    Audio,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
)
from telegram.constants import ParseMode
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
    CallbackContext,
    CallbackQueryHandler,
)
import yt_dlp
import qbittorrentapi
import signal
import gc
from concurrent.futures import ThreadPoolExecutor

# ç½‘ç»œé”™è¯¯å¤„ç†ç›¸å…³å¯¼å…¥
import httpx
from telegram.error import NetworkError, TimedOut, RetryAfter

# å¥åº·æ£€æŸ¥æœåŠ¡å™¨ç›¸å…³
from flask import Flask, jsonify, request
import threading

def extract_xiaohongshu_url(text):
    import re
    # å…ˆå°è¯•æå–æ ‡å‡†http/httpsé“¾æ¥
    urls = re.findall(r'http[s]?://[^\s]+', text)
    for url in urls:
        if 'xhslink.com' in url or 'xiaohongshu.com' in url:
            return url
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†é“¾æ¥ï¼Œå°è¯•æå–å…¶ä»–æ ¼å¼çš„å°çº¢ä¹¦é“¾æ¥
    # åŒ¹é… p://ã€tp://ã€ttp:// ç­‰åè®®ï¼Œå¹¶è½¬æ¢ä¸ºhttps://
    non_http_urls = re.findall(r'(p|tp|ttp)://([^\s]+)', text)
    for protocol, url in non_http_urls:
        if 'xhslink.com' in url or 'xiaohongshu.com' in url:
            return f"https://{url}"
    
    # åŒ¹é…æ²¡æœ‰åè®®çš„å°çº¢ä¹¦åŸŸå
    domain_urls = re.findall(r'(xhslink\.com/[^\s]+|xiaohongshu\.com/[^\s]+)', text)
    for url in domain_urls:
        return f"https://{url}"
    
    return None
# æŠ–éŸ³å’Œå°çº¢ä¹¦ä¸‹è½½ç›¸å…³å¯¼å…¥
try:
    from playwright.async_api import async_playwright
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    print("è­¦å‘Š: playwright æœªå®‰è£…ï¼ŒæŠ–éŸ³å’Œå°çº¢ä¹¦ä¸‹è½½åŠŸèƒ½å°†ä¸å¯ç”¨")


# ç¨‹åºç‰ˆæœ¬ä¿¡æ¯
BOT_VERSION = "v0.6 (Enhanced)"
# åˆ›å»º Flask åº”ç”¨
app = Flask(__name__)
# å…¨å±€å¿ƒè·³å˜é‡
last_heartbeat = time.time()

# å°è¯•å¯¼å…¥ gallery-dl
try:
    import gallery_dl
    GALLERY_DL_AVAILABLE = True
except ImportError:
    GALLERY_DL_AVAILABLE = False
    print("è­¦å‘Š: gallery-dl æœªå®‰è£…ï¼ŒXå›¾ç‰‡ä¸‹è½½åŠŸèƒ½å°†ä¸å¯ç”¨")


def update_heartbeat():
    """æ›´æ–°å¿ƒè·³æ—¶é—´"""
    global last_heartbeat
    last_heartbeat = time.time()


@app.route("/health")
def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    global last_heartbeat
    current_time = time.time()
    time_since_last_heartbeat = current_time - last_heartbeat
    # è¶…è¿‡ 1 å°æ—¶æ— æ´»åŠ¨ï¼Œè®¤ä¸ºç¨‹åºå¯èƒ½æ— å“åº”
    if time_since_last_heartbeat > 3600:
        return (
            jsonify(
                {
                    "status": "unhealthy",
                    "message": "ç¨‹åºå¯èƒ½æ— å“åº”",
                    "last_heartbeat": time_since_last_heartbeat,
                    "timestamp": current_time,
                }
            ),
            503,
        )
    return jsonify(
        {
            "status": "healthy",
            "message": "ç¨‹åºè¿è¡Œæ­£å¸¸",
            "last_heartbeat": time_since_last_heartbeat,
            "timestamp": current_time,
        }
    )


def run_health_check_server():
    """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œå¥åº·æ£€æŸ¥æœåŠ¡å™¨"""
    port = int(os.getenv("HEALTHCHECK_PORT", 8080))
    # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º ERROR ä»¥æŠ‘åˆ¶å¼€å‘æœåŠ¡å™¨è­¦å‘Š
    import logging

    log = logging.getLogger("werkzeug")
    log.setLevel(logging.ERROR)
    # æ¸…é™¤å¯èƒ½å†²çªçš„ç¯å¢ƒå˜é‡
    os.environ.pop("WERKZEUG_RUN_MAIN", None)
    os.environ.pop("WERKZEUG_SERVER_FD", None)
    try:
        # ä½¿ç”¨æ›´ç¨³å®šçš„å¯åŠ¨æ–¹å¼
        from werkzeug.serving import make_server

        server = make_server("0.0.0.0", port, app)
        server.serve_forever()
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        # å›é€€åˆ°åŸå§‹æ–¹æ³•
        try:
            app.run(host="0.0.0.0", port=port, debug=False, use_reloader=False)
        except Exception as e2:
            logger.error(f"å¥åº·æ£€æŸ¥æœåŠ¡å™¨å›é€€å¯åŠ¨ä¹Ÿå¤±è´¥: {e2}")


try:
    from telegram import Update
    from telegram.ext import (
        Application,
        CommandHandler,
        MessageHandler,
        filters,
        ContextTypes,
    )
    import yt_dlp
except ImportError as e:
    print(f"Error importing required packages: {e}")
    print("Please install: pip install python-telegram-bot yt-dlp requests")
    sys.exit(1)

# é…ç½®å¢å¼ºçš„æ—¥å¿—ç³»ç»Ÿ
def setup_logging():
    """é…ç½®å¢å¼ºçš„æ—¥å¿—ç³»ç»Ÿï¼Œæ”¯æŒè¿œç¨‹NASç›®å½•"""
    # ä»ç¯å¢ƒå˜é‡è·å–æ—¥å¿—é…ç½®
    log_level = os.getenv("LOG_LEVEL", "INFO").upper()
    log_dir = os.getenv("LOG_DIR", "./logs")  # æ”¹ä¸ºå½“å‰ç›®å½•ä¸‹çš„logs
    log_max_size = int(os.getenv("LOG_MAX_SIZE", "10")) * 1024 * 1024  # é»˜è®¤10MB
    log_backup_count = int(os.getenv("LOG_BACKUP_COUNT", "5"))
    log_to_console = os.getenv("LOG_TO_CONSOLE", "true").lower() == "true"
    log_to_file = os.getenv("LOG_TO_FILE", "true").lower() == "true"
    # åˆ›å»ºæ—¥å¿—ç›®å½•ï¼ˆæ”¯æŒè¿œç¨‹NASè·¯å¾„ï¼‰
    log_path = Path(log_dir)
    try:
        log_path.mkdir(parents=True, exist_ok=True)
    except Exception as e:
        print(f"è­¦å‘Šï¼šæ— æ³•åˆ›å»ºæ—¥å¿—ç›®å½• {log_path}: {e}")
        # å¦‚æœæ— æ³•åˆ›å»ºè¿œç¨‹ç›®å½•ï¼Œå›é€€åˆ°æœ¬åœ°ç›®å½•
        log_path = Path("./logs")  # æ”¹ä¸ºå½“å‰ç›®å½•ä¸‹çš„logs
        log_path.mkdir(parents=True, exist_ok=True)
        print(f"å·²å›é€€åˆ°æœ¬åœ°æ—¥å¿—ç›®å½•: {log_path}")
    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    date_format = "%Y-%m-%d %H:%M:%S"
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(log_format, date_format)
    # è·å–æ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, log_level))
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    # æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨ï¼ˆå¸¦è½®è½¬ï¼‰
    if log_to_file:
        try:
            file_handler = logging.handlers.RotatingFileHandler(
                log_path / "savextube.log",
                maxBytes=log_max_size,
                backupCount=log_backup_count,
                encoding="utf-8",
            )
            file_handler.setFormatter(formatter)
            file_handler.setLevel(getattr(logging, log_level))
            root_logger.addHandler(file_handler)
        except Exception as e:
            print(f"è­¦å‘Šï¼šæ— æ³•åˆ›å»ºæ–‡ä»¶æ—¥å¿—å¤„ç†å™¨: {e}")
            log_to_file = False
    # æ§åˆ¶å°æ—¥å¿—å¤„ç†å™¨
    if log_to_console:
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        console_handler.setLevel(getattr(logging, log_level))
        root_logger.addHandler(console_handler)

    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«ï¼Œå‡å°‘å†—ä½™è¾“å‡º
    # httpx - Telegram API è¯·æ±‚æ—¥å¿—
    logging.getLogger("httpx").setLevel(logging.WARNING)
    # urllib3 - HTTP è¯·æ±‚æ—¥å¿—
    logging.getLogger("urllib3").setLevel(logging.ERROR)
    logging.getLogger("urllib3.connectionpool").setLevel(logging.ERROR)
    logging.getLogger("urllib3.util.retry").setLevel(logging.ERROR)
    # ç¦ç”¨urllib3çš„æ‰€æœ‰è­¦å‘Š
    logging.getLogger("urllib3").disabled = True

# è®¾ç½®æ—¥å¿—
setup_logging()
logger = logging.getLogger("savextube")

# ç»Ÿä¸€çš„è¿›åº¦ç®¡ç†å‡½æ•°
def create_unified_progress_hook(message_updater=None, progress_data=None):
    """
    åˆ›å»ºç»Ÿä¸€çš„è¿›åº¦å›è°ƒå‡½æ•°ï¼Œé€‚ç”¨äºæ‰€æœ‰åŸºäº yt-dlp çš„ä¸‹è½½
    
    Args:
        message_updater: åŒæ­¥æˆ–å¼‚æ­¥æ¶ˆæ¯æ›´æ–°å‡½æ•°
        progress_data: è¿›åº¦æ•°æ®å­—å…¸ï¼Œç”¨äºå­˜å‚¨æœ€ç»ˆæ–‡ä»¶åç­‰ä¿¡æ¯
    
    Returns:
        progress_hook: ç»Ÿä¸€çš„è¿›åº¦å›è°ƒå‡½æ•°
    """
    def progress_hook(d):
        try:
            if d.get('status') == 'downloading':
                # å®‰å…¨åœ°è·å–ä¸‹è½½è¿›åº¦ä¿¡æ¯
                downloaded = d.get('downloaded_bytes', 0) or 0
                total = d.get('total_bytes') or d.get('total_bytes_estimate', 0) or 0
                
                # ç¡®ä¿æ•°å€¼æœ‰æ•ˆ
                if downloaded is None:
                    downloaded = 0
                if total is None or total <= 0:
                    total = 1  # é¿å…é™¤é›¶é”™è¯¯
                
                # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
                if total > 0:
                    percent = (downloaded / total) * 100
                else:
                    percent = 0
                
                # æ ¼å¼åŒ–é€Ÿåº¦
                speed = d.get('speed', 0) or 0
                if speed and speed > 0:
                    speed_str = f"{speed / 1024 / 1024:.2f} MB/s"
                else:
                    speed_str = "æœªçŸ¥"
                
                # æ ¼å¼åŒ–å‰©ä½™æ—¶é—´
                eta = d.get('eta', 0) or 0
                if eta and eta > 0:
                    eta_str = f"{eta}ç§’"
                else:
                    eta_str = "æœªçŸ¥"
                
                # è·å–æ–‡ä»¶å
                filename = os.path.basename(d.get('filename', '')) or "æ­£åœ¨ä¸‹è½½..."
                
                # æ›´æ–°è¿›åº¦æ•°æ®
                if progress_data:
                    progress_data.update({
                        'downloaded': downloaded,
                        'total': total,
                        'percent': percent,
                        'speed': speed_str,
                        'eta': eta_str,
                        'status': 'downloading',
                        'filename': filename
                    })
                
                # è®°å½•è¿›åº¦ä¿¡æ¯
                logger.info(f"ä¸‹è½½è¿›åº¦: {percent:.1f}% ({downloaded}/{total} bytes) - {speed_str} - å‰©ä½™: {eta_str}")
                
                # å¦‚æœæœ‰æ¶ˆæ¯æ›´æ–°å™¨ï¼Œè°ƒç”¨å®ƒ
                if message_updater:
                    try:
                        # æ£€æŸ¥æ˜¯å¦ä¸ºåç¨‹å¯¹è±¡ï¼ˆé”™è¯¯æƒ…å†µï¼‰
                        if asyncio.iscoroutine(message_updater):
                            logger.error(f"âŒ [progress_hook] message_updater æ˜¯åç¨‹å¯¹è±¡ï¼Œä¸æ˜¯å‡½æ•°ï¼")
                            return

                        # æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚æ­¥å‡½æ•°
                        if asyncio.iscoroutinefunction(message_updater):
                            # å¼‚æ­¥å‡½æ•°ï¼Œä½¿ç”¨ run_coroutine_threadsafe
                            try:
                                loop = asyncio.get_running_loop()
                            except RuntimeError:
                                try:
                                    loop = asyncio.get_event_loop()
                                except RuntimeError:
                                    loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(loop)

                            # ç›´æ¥ä¼ é€’åŸå§‹è¿›åº¦æ•°æ®å­—å…¸
                            asyncio.run_coroutine_threadsafe(
                                message_updater(d), loop)
                        else:
                            # åŒæ­¥å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
                            message_updater(d)
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ›´æ–°è¿›åº¦æ¶ˆæ¯å¤±è´¥: {e}")
                        logger.warning(f"âš ï¸ å¼‚å¸¸ç±»å‹: {type(e)}")
                        import traceback
                        logger.warning(f"âš ï¸ å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                        
            if d.get('status') == 'finished':
                logger.info("ä¸‹è½½å®Œæˆï¼Œå¼€å§‹åå¤„ç†...")
                
                # æ›´æ–°è¿›åº¦æ•°æ®
                if progress_data:
                    progress_data['status'] = 'finished'
                
                # å®‰å…¨åœ°è·å–æ–‡ä»¶å
                filename = d.get('filename', '')
                if filename and progress_data:
                    progress_data['final_filename'] = filename
                    logger.info(f"æœ€ç»ˆæ–‡ä»¶å: {filename}")

                    # ç›‘æ§æ–‡ä»¶åˆå¹¶çŠ¶æ€
                    if filename.endswith('.part'):
                        logger.warning(f"âš ï¸ æ–‡ä»¶åˆå¹¶å¯èƒ½å¤±è´¥: {filename}")
                    else:
                        logger.info(f"âœ… æ–‡ä»¶ä¸‹è½½å¹¶åˆå¹¶æˆåŠŸ: {filename}")
                else:
                    logger.warning("progress_hook ä¸­æœªè·å–åˆ°æ–‡ä»¶å")
                
                # å¦‚æœæœ‰æ¶ˆæ¯æ›´æ–°å™¨ï¼Œå‘é€å®Œæˆæ¶ˆæ¯
                if message_updater:
                    try:
                        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
                        logger.info(f"ğŸ” [progress_hook] finishedçŠ¶æ€ - message_updater ç±»å‹: {type(message_updater)}")
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºåç¨‹å¯¹è±¡ï¼ˆé”™è¯¯æƒ…å†µï¼‰
                        if asyncio.iscoroutine(message_updater):
                            logger.error(f"âŒ [progress_hook] finishedçŠ¶æ€ - message_updater æ˜¯åç¨‹å¯¹è±¡ï¼Œä¸æ˜¯å‡½æ•°ï¼")
                            return
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚æ­¥å‡½æ•°
                        if asyncio.iscoroutinefunction(message_updater):
                            logger.info(f"ğŸ” [progress_hook] finishedçŠ¶æ€ - æ£€æµ‹åˆ°å¼‚æ­¥å‡½æ•°ï¼Œä½¿ç”¨ run_coroutine_threadsafe")
                            # å¼‚æ­¥å‡½æ•°ï¼Œä½¿ç”¨ run_coroutine_threadsafe
                            try:
                                loop = asyncio.get_running_loop()
                            except RuntimeError:
                                try:
                                    loop = asyncio.get_event_loop()
                                except RuntimeError:
                                    loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(loop)
                            
                            # ç›´æ¥ä¼ é€’åŸå§‹è¿›åº¦æ•°æ®å­—å…¸
                            asyncio.run_coroutine_threadsafe(
                                message_updater(d), loop)
                        else:
                            logger.info(f"ğŸ” [progress_hook] finishedçŠ¶æ€ - æ£€æµ‹åˆ°åŒæ­¥å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨")
                            # åŒæ­¥å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
                            message_updater(d)
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ›´æ–°å®Œæˆæ¶ˆæ¯å¤±è´¥: {e}")
                        logger.warning(f"âš ï¸ å¼‚å¸¸ç±»å‹: {type(e)}")
                        import traceback
                        logger.warning(f"âš ï¸ å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                    
        except Exception as e:
            logger.error(f"progress_hook å¤„ç†é”™è¯¯: {e}")
            import traceback
            logger.error(f"progress_hook å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            # ä¸ä¸­æ–­ä¸‹è½½ï¼Œåªè®°å½•é”™è¯¯
    
    return progress_hook
def create_bilibili_message_updater(status_message, context, progress_data):
    """
    ä¸“é—¨ä¸ºBç«™å¤šPä¸‹è½½åˆ›å»ºçš„æ¶ˆæ¯æ›´æ–°å™¨
    å®Œå…¨å¤åˆ¶YouTubeçš„æˆåŠŸé€»è¾‘
    """
    import time
    import asyncio

    # ç¼“å­˜ä¸Šæ¬¡å‘é€çš„å†…å®¹ï¼Œé¿å…é‡å¤å‘é€
    last_progress_text = {"text": None}

    # --- è¿›åº¦å›è°ƒ ---
    last_update_time = {"time": time.time()}
    last_progress_percent = {"value": 0}
    progress_state = {"last_stage": None, "last_percent": 0, "finished_shown": False}
    last_progress_text = {"text": ""}

    # åˆ›å»ºBç«™ä¸“ç”¨çš„æ¶ˆæ¯æ›´æ–°å™¨å‡½æ•°
    async def bilibili_message_updater(text_or_dict):
        try:
            logger.info(f"ğŸ” bilibili_message_updater è¢«è°ƒç”¨ï¼Œå‚æ•°ç±»å‹: {type(text_or_dict)}")
            logger.info(f"ğŸ” bilibili_message_updater å‚æ•°å†…å®¹: {text_or_dict}")

            # å¦‚æœå·²ç»æ˜¾ç¤ºå®ŒæˆçŠ¶æ€ï¼Œå¿½ç•¥æ‰€æœ‰åç»­è°ƒç”¨
            if progress_state["finished_shown"]:
                logger.info("Bç«™ä¸‹è½½å·²å®Œæˆï¼Œå¿½ç•¥bilibili_message_updateråç»­è°ƒç”¨")
                return

            # å¤„ç†å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…é‡å¤å‘é€ç›¸åŒå†…å®¹
            if isinstance(text_or_dict, str):
                if text_or_dict == last_progress_text["text"]:
                    logger.info("ğŸ” è·³è¿‡é‡å¤å†…å®¹")
                    return  # è·³è¿‡é‡å¤å†…å®¹
                last_progress_text["text"] = text_or_dict
                await status_message.edit_text(text_or_dict)
                return

            # æ£€æŸ¥æ˜¯å¦ä¸ºå­—å…¸ç±»å‹ï¼ˆæ¥è‡ªprogress_hookçš„è¿›åº¦æ•°æ®ï¼‰
            if isinstance(text_or_dict, dict):
                logger.info(f"ğŸ” æ£€æµ‹åˆ°å­—å…¸ç±»å‹ï¼ŒçŠ¶æ€: {text_or_dict.get('status')}")

                # è®°å½•æ–‡ä»¶åï¼ˆç”¨äºæ–‡ä»¶æŸ¥æ‰¾ï¼‰
                if text_or_dict.get("status") == "finished":
                    filename = text_or_dict.get('filename', '')
                    if filename:
                        # è®°å½•åˆ°progress_dataä¸­
                        if 'downloaded_files' not in progress_data:
                            progress_data['downloaded_files'] = []
                        progress_data['downloaded_files'].append(filename)
                        logger.info(f"ğŸ“ Bç«™ä¸‹è½½å™¨è®°å½•å®Œæˆæ–‡ä»¶: {filename}")

                if text_or_dict.get("status") == "finished":
                    # å¯¹äºfinishedçŠ¶æ€ï¼Œä¸è°ƒç”¨update_progressï¼Œé¿å…æ˜¾ç¤ºé”™è¯¯çš„è¿›åº¦ä¿¡æ¯
                    logger.info("ğŸ” æ£€æµ‹åˆ°finishedçŠ¶æ€ï¼Œè·³è¿‡update_progressè°ƒç”¨")
                    return
                elif text_or_dict.get("status") == "downloading":
                    # è¿™æ˜¯æ¥è‡ªprogress_hookçš„ä¸‹è½½è¿›åº¦æ•°æ®
                    logger.info("ğŸ” æ£€æµ‹åˆ°ä¸‹è½½è¿›åº¦æ•°æ®ï¼Œå‡†å¤‡è°ƒç”¨ update_progress...")
                    # è¿™é‡Œéœ€è¦å®ç°update_progressé€»è¾‘ï¼Œæš‚æ—¶å…ˆè®°å½•
                    logger.info(f"ğŸ“Š Bç«™ä¸‹è½½è¿›åº¦: {text_or_dict}")
                else:
                    # å…¶ä»–å­—å…¸çŠ¶æ€ï¼Œè½¬æ¢ä¸ºæ–‡æœ¬
                    logger.info(f"ğŸ” å…¶ä»–å­—å…¸çŠ¶æ€: {text_or_dict}")
                    dict_text = str(text_or_dict)
                    if dict_text == last_progress_text["text"]:
                        logger.info("ğŸ” è·³è¿‡é‡å¤å­—å…¸å†…å®¹")
                        return  # è·³è¿‡é‡å¤å†…å®¹
                    last_progress_text["text"] = dict_text
                    await status_message.edit_text(dict_text)
            else:
                # æ™®é€šæ–‡æœ¬æ¶ˆæ¯
                logger.info(f"ğŸ” æ™®é€šæ–‡æœ¬æ¶ˆæ¯: {text_or_dict}")
                text_str = str(text_or_dict)
                if text_str == last_progress_text["text"]:
                    logger.info("ğŸ” è·³è¿‡é‡å¤æ–‡æœ¬å†…å®¹")
                    return  # è·³è¿‡é‡å¤å†…å®¹
                last_progress_text["text"] = text_str
                await status_message.edit_text(text_str)
        except Exception as e:
            logger.error(f"âŒ bilibili_message_updater å¤„ç†é”™è¯¯: {e}")
            logger.error(f"âŒ å¼‚å¸¸ç±»å‹: {type(e)}")
            import traceback
            logger.error(f"âŒ å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            if "Message is not modified" not in str(e):
                logger.warning(f"æ›´æ–°Bç«™çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")

    return bilibili_message_updater

def single_video_progress_hook(message_updater=None, progress_data=None, status_message=None, context=None):
    """
    é€‚ç”¨äºæ‰€æœ‰å•é›†ä¸‹è½½çš„ yt-dlp è¿›åº¦å›è°ƒï¼Œä¸‹è½½è¿‡ç¨‹ä¸­æ˜¾ç¤ºè¿›åº¦ï¼Œä¸‹è½½å®Œæˆåæ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯ã€‚
    æ•´åˆäº†å®Œæ•´çš„è¿›åº¦æ˜¾ç¤ºé€»è¾‘ï¼ŒåŒ…æ‹¬è¿›åº¦æ¡ã€é€Ÿåº¦ã€å‰©ä½™æ—¶é—´ç­‰ã€‚
    """
    # åˆå§‹åŒ–è¿›åº¦æ•°æ®
    if progress_data is None:
        progress_data = {"final_filename": None, "lock": threading.Lock()}
    
    # åˆå§‹åŒ–æ›´æ–°é¢‘ç‡æ§åˆ¶
    last_update_time = {"time": 0}
    
    def progress_hook(d):
        # æ”¯æŒå­—ç¬¦ä¸²ç±»å‹ï¼Œç›´æ¥å‘åˆ°Telegram
        import os
        if isinstance(d, str):
            if message_updater and status_message:
                try:
                    loop = asyncio.get_running_loop()
                except RuntimeError:
                    try:
                        loop = asyncio.get_event_loop()
                    except RuntimeError:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                
                async def do_update():
                    try:
                        await status_message.edit_text(d)
                    except Exception as e:
                        logger.warning(f"å‘é€å­—ç¬¦ä¸²è¿›åº¦åˆ°TGå¤±è´¥: {e}")
                
                asyncio.run_coroutine_threadsafe(do_update(), loop)
            return
        
        # æ·»åŠ ç±»å‹æ£€æŸ¥ï¼Œç¡®ä¿dæ˜¯å­—å…¸ç±»å‹
        if not isinstance(d, dict):
            logger.warning(f"progress_hookæ¥æ”¶åˆ°éå­—å…¸ç±»å‹å‚æ•°: {type(d)}, å†…å®¹: {d}")
            return
        
        # æ›´æ–° progress_data
        try:
            if d['status'] == 'downloading':
                raw_filename = d.get('filename', '')
                display_filename = os.path.basename(raw_filename) if raw_filename else 'video.mp4'
                progress_data.update({
                    'filename': display_filename,
                    'total_bytes': d.get('total_bytes') or d.get('total_bytes_estimate', 0),
                    'downloaded_bytes': d.get('downloaded_bytes', 0),
                    'speed': d.get('speed', 0),
                    'status': 'downloading',
                    'progress': (d.get('downloaded_bytes', 0) / (d.get('total_bytes') or d.get('total_bytes_estimate', 1))) * 100 if (d.get('total_bytes') or d.get('total_bytes_estimate', 0)) > 0 else 0.0
                })
            elif d['status'] == 'finished':
                final_filename = d.get('filename', '')
                display_filename = os.path.basename(final_filename) if final_filename else 'video.mp4'
                progress_data.update({
                    'filename': display_filename,
                    'status': 'finished',
                    'final_filename': final_filename,
                    'progress': 100.0
                })
                logger.info(f"ğŸ“ è®°å½•æœ€ç»ˆæ–‡ä»¶å: {final_filename}")
        except Exception as e:
            logger.error(f"æ›´æ–° progress_data é”™è¯¯: {str(e)}")
        
        # å¦‚æœæ²¡æœ‰status_messageå’Œcontextï¼Œä½¿ç”¨ç®€å•çš„message_updater
        if not status_message or not context:
            if message_updater:
                if asyncio.iscoroutinefunction(message_updater):
                    try:
                        loop = asyncio.get_running_loop()
                    except RuntimeError:
                        try:
                            loop = asyncio.get_event_loop()
                        except RuntimeError:
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                    asyncio.run_coroutine_threadsafe(message_updater(d), loop)
                else:
                    try:
                        message_updater(d)
                    except Exception as e:
                        logger.warning(f"è¿›åº¦å›è°ƒè°ƒç”¨å¤±è´¥: {e}")
            return
        
        # å®Œæ•´çš„è¿›åº¦æ˜¾ç¤ºé€»è¾‘
        now = time.time()

        # åŠ¨æ€æ›´æ–°é¢‘ç‡æ§åˆ¶ï¼šå°æ–‡ä»¶ä½¿ç”¨æ›´é«˜é¢‘ç‡
        total_bytes = d.get('total_bytes') or d.get('total_bytes_estimate', 0)
        if total_bytes > 0 and total_bytes < 5 * 1024 * 1024:  # å°äº5MBçš„æ–‡ä»¶
            update_interval = 0.2  # 200msæ›´æ–°ä¸€æ¬¡
        else:
            update_interval = 1.0  # å¤§æ–‡ä»¶1ç§’æ›´æ–°ä¸€æ¬¡

        if now - last_update_time['time'] < update_interval:
            return
        
        # å¤„ç†ä¸‹è½½å®ŒæˆçŠ¶æ€ - ç›´æ¥æ˜¾ç¤ºå®Œæˆä¿¡æ¯å¹¶è¿”å›
        if d.get('status') == 'finished':
            logger.info("yt-dlpä¸‹è½½å®Œæˆï¼Œæ˜¾ç¤ºå®Œæˆä¿¡æ¯")

            # è·å–è¿›åº¦ä¿¡æ¯
            filename = progress_data.get('filename', 'video.mp4')
            total_bytes = progress_data.get('total_bytes', 0)
            downloaded_bytes = progress_data.get('downloaded_bytes', 0)

            # ç›‘æ§æ–‡ä»¶åˆå¹¶çŠ¶æ€
            actual_filename = d.get('filename', filename)
            if actual_filename.endswith('.part'):
                logger.warning(f"âš ï¸ æ–‡ä»¶åˆå¹¶å¯èƒ½å¤±è´¥: {actual_filename}")
            else:
                logger.info(f"âœ… æ–‡ä»¶ä¸‹è½½å¹¶åˆå¹¶æˆåŠŸ: {actual_filename}")
            
            # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
            display_filename = _clean_filename_for_display(filename)
            progress_bar = _create_progress_bar(100.0)
            size_mb = total_bytes / (1024 * 1024) if total_bytes > 0 else downloaded_bytes / (1024 * 1024)
            
            completion_text = (
                f"ğŸ“ æ–‡ä»¶ï¼š{display_filename}\n"
                f"ğŸ’¾ å¤§å°ï¼š{size_mb:.2f}MB\n"
                f"âš¡ é€Ÿåº¦ï¼šå®Œæˆ\n"
                f"â³ é¢„è®¡å‰©ä½™ï¼š0ç§’\n"
                f"ğŸ“Š è¿›åº¦ï¼š{progress_bar} (100.0%)"
            )
            
            async def do_update():
                try:
                    await status_message.edit_text(completion_text)
                    logger.info("æ˜¾ç¤ºä¸‹è½½å®Œæˆè¿›åº¦ä¿¡æ¯")
                except Exception as e:
                    logger.warning(f"æ˜¾ç¤ºå®Œæˆè¿›åº¦ä¿¡æ¯å¤±è´¥: {e}")
            
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                try:
                    loop = asyncio.get_event_loop()
                except RuntimeError:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            
            asyncio.run_coroutine_threadsafe(do_update(), loop)
            return
        
        # å¤„ç†ä¸‹è½½ä¸­çŠ¶æ€
        if d.get('status') == 'downloading':
            last_update_time['time'] = now
            
            total_bytes = d.get('total_bytes') or d.get('total_bytes_estimate', 0)
            downloaded_bytes = d.get('downloaded_bytes', 0)
            speed_bytes_s = d.get('speed', 0)
            eta_seconds = d.get('eta', 0)
            filename = d.get('filename', '') or "æ­£åœ¨ä¸‹è½½..."
            
            # è®¡ç®—è¿›åº¦
            if total_bytes > 0:
                progress = (downloaded_bytes / total_bytes) * 100
                progress_bar = _create_progress_bar(progress)
                size_mb = total_bytes / (1024 * 1024)
                speed_mb = (speed_bytes_s or 0) / (1024 * 1024)
                
                # è®¡ç®—é¢„è®¡å‰©ä½™æ—¶é—´
                eta_text = ""
                if speed_bytes_s and total_bytes and downloaded_bytes < total_bytes:
                    remaining = total_bytes - downloaded_bytes
                    eta = int(remaining / speed_bytes_s)
                    mins, secs = divmod(eta, 60)
                    if mins > 0:
                        eta_text = f"{mins}åˆ†{secs}ç§’"
                    else:
                        eta_text = f"{secs}ç§’"
                elif speed_bytes_s:
                    eta_text = "è®¡ç®—ä¸­"
                else:
                    eta_text = "æœªçŸ¥"
                
                display_filename = _clean_filename_for_display(filename)
                progress_text = (
                    f"ğŸ“ æ–‡ä»¶ï¼š{display_filename}\n"
                    f"ğŸ’¾ å¤§å°ï¼š{size_mb:.2f}MB\n"
                    f"âš¡ é€Ÿåº¦ï¼š{speed_mb:.2f}MB/s\n"
                    f"â³ é¢„è®¡å‰©ä½™ï¼š{eta_text}\n"
                    f"ğŸ“Š è¿›åº¦ï¼š{progress_bar} ({progress:.1f}%)"
                )
                
                async def do_update():
                    try:
                        await status_message.edit_text(progress_text)
                    except Exception as e:
                        if "Message is not modified" not in str(e):
                            logger.warning(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
                
                try:
                    loop = asyncio.get_running_loop()
                except RuntimeError:
                    try:
                        loop = asyncio.get_event_loop()
                    except RuntimeError:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                
                asyncio.run_coroutine_threadsafe(do_update(), loop)
            else:
                # æ²¡æœ‰æ€»å¤§å°ä¿¡æ¯æ—¶çš„å¤„ç†
                display_filename = _clean_filename_for_display(filename)
                downloaded_mb = downloaded_bytes / (1024 * 1024)
                speed_mb = (speed_bytes_s or 0) / (1024 * 1024)
                
                progress_text = (
                    f"ğŸ“ æ–‡ä»¶ï¼š{display_filename}\n"
                    f"ğŸ’¾ å·²ä¸‹è½½ï¼š{downloaded_mb:.2f}MB\n"
                    f"âš¡ é€Ÿåº¦ï¼š{speed_mb:.2f}MB/s\n"
                    f"â³ é¢„è®¡å‰©ä½™ï¼šæœªçŸ¥\n"
                    f"ğŸ“Š è¿›åº¦ï¼šè®¡ç®—ä¸­..."
                )
                
                async def do_update():
                    try:
                        await status_message.edit_text(progress_text)
                    except Exception as e:
                        if "Message is not modified" not in str(e):
                            logger.warning(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
                
                try:
                    loop = asyncio.get_running_loop()
                except RuntimeError:
                    try:
                        loop = asyncio.get_event_loop()
                    except RuntimeError:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                
                asyncio.run_coroutine_threadsafe(do_update(), loop)
    
    # è¾…åŠ©å‡½æ•°
    def _clean_filename_for_display(filename):
        """æ¸…ç†æ–‡ä»¶åç”¨äºæ˜¾ç¤º"""
        try:
            # ç§»é™¤æ—¶é—´æˆ³å‰ç¼€å¦‚æœå­˜åœ¨
            import re
            import os
            if re.match(r"^\d{10}_", filename):
                display_name = filename[11:]
            else:
                display_name = filename

            # å¦‚æœæ–‡ä»¶åå¤ªé•¿ï¼Œè¿›è¡Œæ™ºèƒ½æˆªæ–­
            if len(display_name) > 35:
                name, ext = os.path.splitext(display_name)
                display_name = name[:30] + "..." + ext

            return display_name
        except BaseException:
            return filename if len(filename) <= 35 else filename[:32] + "..."
    
    def _create_progress_bar(percent: float, length: int = 20) -> str:
        """åˆ›å»ºè¿›åº¦æ¡"""
        filled_length = int(length * percent / 100)
        bar = "â–ˆ" * filled_length + "â–‘" * (length - filled_length)
        return bar
    
    return progress_hook
class VideoDownloader:
    # å¹³å°æšä¸¾å®šä¹‰
    class Platform(str, Enum):
        DOUYIN = "douyin"
        KUAISHOU = "kuaishou"
        XIAOHONGSHU = "xiaohongshu"
        UNKNOWN = "unknown"
    
    def __init__(
        self,
        base_download_path: str,
        x_cookies_path: str = None,
        b_cookies_path: str = None,
        youtube_cookies_path: str = None,
        douyin_cookies_path: str = None,
        kuaishou_cookies_path: str = None,
        facebook_cookies_path: str = None,
    ):
        self.download_path = Path(base_download_path).resolve()
        self.x_download_path = self.download_path / "X"
        self.bilibili_download_path = self.download_path / "Bilibili"
        self.youtube_download_path = self.download_path / "YouTube"
        self.music_download_path = self.download_path / "Music"
        self.pornhub_download_path = self.download_path / "Pornhub"
        self.telegram_download_path = self.download_path / "Telegram"
        self.telegraph_download_path = self.download_path / "Telegraph"
        self.douyin_download_path = self.download_path / "Douyin"
        self.kuaishou_download_path = self.download_path / "Kuaishou"
        self.facebook_download_path = self.download_path / "Facebook"
        self.weibo_download_path = self.download_path / "Weibo"
        self.instagram_download_path = self.download_path / "Instagram"
        self.tiktok_download_path = self.download_path / "TikTok"
        self.x_cookies_path = x_cookies_path
        self.b_cookies_path = b_cookies_path
        self.youtube_cookies_path = youtube_cookies_path
        self.douyin_cookies_path = douyin_cookies_path
        self.kuaishou_cookies_path = kuaishou_cookies_path
        self.facebook_cookies_path = facebook_cookies_path
        self.proxy_host = os.environ.get("PROXY_HOST")
        self._main_loop = None
        try:
            import asyncio

            self._main_loop = asyncio.get_running_loop()
        except Exception:
            self._main_loop = None
        # ä»ç¯å¢ƒå˜é‡è·å–æ˜¯å¦è½¬æ¢æ ¼å¼çš„é…ç½®
        self.convert_to_mp4 = (
            os.getenv("YOUTUBE_CONVERT_TO_MP4", "true").lower() == "true"
        )
        logger.info(f"è§†é¢‘æ ¼å¼è½¬æ¢: {'å¼€å¯' if self.convert_to_mp4 else 'å…³é—­'}")
        # æ”¯æŒè‡ªå®šä¹‰ä¸‹è½½ç›®å½•
        self.custom_download_path = (
            os.getenv("CUSTOM_DOWNLOAD_PATH", "false").lower() == "true"
        )
        if self.custom_download_path:
            # å¦‚æœå¯ç”¨äº†è‡ªå®šä¹‰ä¸‹è½½è·¯å¾„ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–å„å¹³å°çš„ä¸‹è½½è·¯å¾„
            self.x_download_path = Path(
                os.getenv("X_DOWNLOAD_PATH", str(self.download_path / "X"))
            ).resolve()
            self.youtube_download_path = Path(
                os.getenv("YOUTUBE_DOWNLOAD_PATH", str(self.download_path / "YouTube"))
            ).resolve()
            self.xvideos_download_path = Path(
                os.getenv("XVIDEOS_DOWNLOAD_PATH", str(self.download_path / "Xvideos"))
            ).resolve()
            self.pornhub_download_path = Path(
                os.getenv("PORNHUB_DOWNLOAD_PATH", str(self.download_path / "Pornhub"))
            ).resolve()
            self.bilibili_download_path = Path(
                os.getenv(
                    "BILIBILI_DOWNLOAD_PATH", str(self.download_path / "Bilibili")
                )
            ).resolve()
            self.music_download_path = Path(
                os.getenv("MUSIC_DOWNLOAD_PATH", str(self.download_path / "Music"))
            ).resolve()
            self.telegram_download_path = Path(
                os.getenv(
                    "TELEGRAM_DOWNLOAD_PATH", str(self.download_path / "Telegram")
                )
            ).resolve()
            self.telegraph_download_path = Path(
                os.getenv(
                    "TELEGRAPH_DOWNLOAD_PATH", str(self.download_path / "Telegraph")
                )
            ).resolve()
            self.douyin_download_path = Path(
                os.getenv(
                    "DOUYIN_DOWNLOAD_PATH", str(self.download_path / "Douyin")
                )
            ).resolve()
            self.kuaishou_download_path = Path(
                os.getenv(
                    "KUAISHOU_DOWNLOAD_PATH", str(self.download_path / "Kuaishou")
                )
            ).resolve()
            self.facebook_download_path = Path(
                os.getenv(
                    "FACEBOOK_DOWNLOAD_PATH", str(self.download_path / "Facebook")
                )
            ).resolve()
            self.xiaohongshu_download_path = Path(
                os.getenv(
                    "XIAOHONGSHU_DOWNLOAD_PATH", str(self.download_path / "Xiaohongshu")
                )
            ).resolve()
            self.weibo_download_path = Path(
                os.getenv(
                    "WEIBO_DOWNLOAD_PATH", str(self.download_path / "Weibo")
                )
            ).resolve()
            self.instagram_download_path = Path(
                os.getenv(
                    "INSTAGRAM_DOWNLOAD_PATH", str(self.download_path / "Instagram")
                )
            ).resolve()
            self.tiktok_download_path = Path(
                os.getenv(
                    "TIKTOK_DOWNLOAD_PATH", str(self.download_path / "TikTok")
                )
            ).resolve()
        else:
            # å¦‚æœæœªå¯ç”¨è‡ªå®šä¹‰ä¸‹è½½è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤çš„å­ç›®å½•ç»“æ„
            self.x_download_path = self.download_path / "X"
            self.youtube_download_path = self.download_path / "YouTube"
            self.xvideos_download_path = self.download_path / "Xvideos"
            self.pornhub_download_path = self.download_path / "Pornhub"
            self.bilibili_download_path = self.download_path / "Bilibili"
            self.music_download_path = self.download_path / "Music"
            self.telegram_download_path = self.download_path / "Telegram"
            self.telegraph_download_path = self.download_path / "Telegraph"
            self.xiaohongshu_download_path = self.download_path / "Xiaohongshu"
            self.weibo_download_path = self.download_path / "Weibo"
            self.instagram_download_path = self.download_path / "Instagram"
            self.tiktok_download_path = self.download_path / "TikTok"
        # åˆ›å»ºæ‰€æœ‰ä¸‹è½½ç›®å½•
        for path in [
            self.x_download_path,
            self.youtube_download_path,
            self.xvideos_download_path,
            self.pornhub_download_path,
            self.bilibili_download_path,
            self.music_download_path,
            self.telegram_download_path,
            self.telegraph_download_path,
            self.douyin_download_path,
            self.kuaishou_download_path,
            self.facebook_download_path,
            self.xiaohongshu_download_path,
            self.weibo_download_path,
            self.instagram_download_path,
            self.tiktok_download_path,
        ]:
            path.mkdir(parents=True, exist_ok=True)
        logger.info(f"X ä¸‹è½½è·¯å¾„: {self.x_download_path}")
        logger.info(f"YouTube ä¸‹è½½è·¯å¾„: {self.youtube_download_path}")
        logger.info(f"Xvideos ä¸‹è½½è·¯å¾„: {self.xvideos_download_path}")
        logger.info(f"Pornhub ä¸‹è½½è·¯å¾„: {self.pornhub_download_path}")
        logger.info(f"Bilibili ä¸‹è½½è·¯å¾„: {self.bilibili_download_path}")
        logger.info(f"éŸ³ä¹ä¸‹è½½è·¯å¾„: {self.music_download_path}")
        logger.info(f"Telegram æ–‡ä»¶ä¸‹è½½è·¯å¾„: {self.telegram_download_path}")
        logger.info(f"Telegraph æ–‡ä»¶ä¸‹è½½è·¯å¾„: {self.telegraph_download_path}")
        logger.info(f"æŠ–éŸ³ä¸‹è½½è·¯å¾„: {self.douyin_download_path}")
        logger.info(f"å¿«æ‰‹ä¸‹è½½è·¯å¾„: {self.kuaishou_download_path}")
        logger.info(f"Facebookä¸‹è½½è·¯å¾„: {self.facebook_download_path}")
        logger.info(f"å°çº¢ä¹¦ä¸‹è½½è·¯å¾„: {self.xiaohongshu_download_path}")
        logger.info(f"å¾®åšä¸‹è½½è·¯å¾„: {self.weibo_download_path}")
        logger.info(f"Instagramä¸‹è½½è·¯å¾„: {self.instagram_download_path}")
        logger.info(f"TikTokä¸‹è½½è·¯å¾„: {self.tiktok_download_path}")
        # å¦‚æœè®¾ç½®äº† Bilibili cookiesï¼Œè®°å½•æ—¥å¿—
        if self.b_cookies_path:
            logger.info(f"Bilibili Cookies è·¯å¾„: {self.b_cookies_path}")
        # å¦‚æœè®¾ç½®äº† YouTube cookiesï¼Œè®°å½•æ—¥å¿—
        if self.youtube_cookies_path:
            logger.info(f"ğŸª ä½¿ç”¨YouTube cookies: {self.youtube_cookies_path}")
            
        # å¦‚æœè®¾ç½®äº†æŠ–éŸ³ cookiesï¼Œè®°å½•æ—¥å¿—
        if self.douyin_cookies_path:
            logger.info(f"ğŸª ä½¿ç”¨æŠ–éŸ³ cookies: {self.douyin_cookies_path}")

        # å¦‚æœè®¾ç½®äº†å¿«æ‰‹ cookiesï¼Œè®°å½•æ—¥å¿—
        if self.kuaishou_cookies_path:
            logger.info(f"ğŸª ä½¿ç”¨å¿«æ‰‹ cookies: {self.kuaishou_cookies_path}")
            
        # æµ‹è¯•ä»£ç†è¿æ¥
        if self.proxy_host:
            if self._test_proxy_connection():
                logger.info(f"ä»£ç†æœåŠ¡å™¨å·²é…ç½®å¹¶è¿æ¥æˆåŠŸ: {self.proxy_host}")
                logger.info(f"yt-dlp ä½¿ç”¨ä»£ç†: {self.proxy_host}")
                # è®¾ç½®ç³»ç»Ÿä»£ç†ç¯å¢ƒå˜é‡
                os.environ['HTTP_PROXY'] = self.proxy_host
                os.environ['HTTPS_PROXY'] = self.proxy_host
                os.environ['NO_PROXY'] = 'localhost,127.0.0.1'
            else:
                logger.warning(f"ä»£ç†æœåŠ¡å™¨å·²é…ç½®ä½†è¿æ¥å¤±è´¥: {self.proxy_host}")
                logger.info("yt-dlp ç›´æ¥è¿æ¥")
                self.proxy_host = None  # è¿æ¥å¤±è´¥æ—¶ç¦ç”¨ä»£ç†
                # æ¸…é™¤ç³»ç»Ÿä»£ç†ç¯å¢ƒå˜é‡
                os.environ.pop('HTTP_PROXY', None)
                os.environ.pop('HTTPS_PROXY', None)
                os.environ.pop('NO_PROXY', None)
        else:
            logger.info("ä»£ç†æœåŠ¡å™¨æœªé…ç½®ï¼Œå°†ç›´æ¥è¿æ¥")
            logger.info("yt-dlp ç›´æ¥è¿æ¥")
            
        # åˆ›å»º gallery-dl.conf é…ç½®æ–‡ä»¶
        try:
            self._create_gallery_dl_config()
        except Exception as e:
            logger.warning(f"åˆ›å»º gallery-dl é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    def _parse_cookies_file(self, cookies_path: str) -> dict:
        """è§£æ Netscape æ ¼å¼çš„ X cookies æ–‡ä»¶å¹¶è½¬æ¢ä¸º JSON æ ¼å¼"""
        try:
            cookies_dict = {}
            
            with open(cookies_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # è·³è¿‡æ³¨é‡Šè¡Œå’Œç©ºè¡Œ
                    if line.startswith('#') or not line:
                        continue
                    
                    # Netscape æ ¼å¼: domain, domain_specified, path, secure, expiry, name, value
                    parts = line.split('\t')
                    if len(parts) >= 7:
                        domain = parts[0]
                        secure = parts[3] == 'TRUE'
                        expiry = parts[4]
                        name = parts[5]
                        value = parts[6]
                        
                        # åªå¤„ç† twitter.com å’Œ x.com çš„ cookies
                        if domain in ['.twitter.com', '.x.com', 'twitter.com', 'x.com']:
                            cookies_dict[name] = value
                            logger.debug(f"è§£æ X cookie: {name} = {value[:10]}...")
            
            logger.info(f"æˆåŠŸè§£æ {len(cookies_dict)} ä¸ª X cookies")
            return cookies_dict
            
        except Exception as e:
            logger.error(f"è§£æ X cookies æ–‡ä»¶å¤±è´¥: {e}")
            return {}

    def _parse_douyin_cookies_file(self, cookies_path: str) -> dict:
        """è§£æ Netscape æ ¼å¼çš„æŠ–éŸ³ cookies æ–‡ä»¶å¹¶è½¬æ¢ä¸º JSON æ ¼å¼"""
        try:
            cookies_dict = {}
            
            with open(cookies_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # è·³è¿‡æ³¨é‡Šè¡Œå’Œç©ºè¡Œ
                    if line.startswith('#') or not line:
                        continue
                    
                    # Netscape æ ¼å¼: domain, domain_specified, path, secure, expiry, name, value
                    parts = line.split('\t')
                    if len(parts) >= 7:
                        domain = parts[0]
                        secure = parts[3] == 'TRUE'
                        expiry = parts[4]
                        name = parts[5]
                        value = parts[6]
                        
                        # åªå¤„ç†æŠ–éŸ³ç›¸å…³çš„ cookies
                        if domain in ['.douyin.com', 'douyin.com', 'www.douyin.com', 'v.douyin.com', 'www.iesdouyin.com', 'iesdouyin.com']:
                            cookies_dict[name] = value
                            logger.debug(f"è§£ææŠ–éŸ³ cookie: {name} = {value[:10]}...")
            
            logger.info(f"æˆåŠŸè§£æ {len(cookies_dict)} ä¸ªæŠ–éŸ³ cookies")
            return cookies_dict
            
        except Exception as e:
            logger.error(f"è§£ææŠ–éŸ³ cookies æ–‡ä»¶å¤±è´¥: {e}")
            return {}

    def _parse_kuaishou_cookies_file(self, cookies_path: str) -> dict:
        """è§£æ Netscape æ ¼å¼çš„å¿«æ‰‹ cookies æ–‡ä»¶å¹¶è½¬æ¢ä¸º JSON æ ¼å¼"""
        try:
            cookies_dict = {}

            with open(cookies_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        parts = line.split('\t')
                        if len(parts) >= 7:
                            domain = parts[0]
                            flag = parts[1] == 'TRUE'
                            path = parts[2]
                            secure = parts[3] == 'TRUE'
                            expiry = parts[4]
                            name = parts[5]
                            value = parts[6]

                            # åªå¤„ç†å¿«æ‰‹ç›¸å…³çš„ cookies
                            if domain in ['.kuaishou.com', 'kuaishou.com', 'www.kuaishou.com', 'v.kuaishou.com']:
                                cookies_dict[name] = value
                                logger.debug(f"è§£æå¿«æ‰‹ cookie: {name} = {value[:10]}...")

            logger.info(f"æˆåŠŸè§£æ {len(cookies_dict)} ä¸ªå¿«æ‰‹ cookies")
            return cookies_dict

        except Exception as e:
            logger.error(f"è§£æå¿«æ‰‹ cookies æ–‡ä»¶å¤±è´¥: {e}")
            return {}

    def _test_proxy_connection(self) -> bool:
        """æµ‹è¯•ä»£ç†æœåŠ¡å™¨è¿æ¥"""
        if not self.proxy_host:
            return False
        try:
            # è§£æä»£ç†åœ°å€
            proxy_url = urlparse(self.proxy_host)
            proxies = {"http": self.proxy_host, "https": self.proxy_host}
            # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º5ç§’
            response = requests.get(
                "http://www.google.com", proxies=proxies, timeout=5, verify=False
            )
            return response.status_code == 200
        except Exception as e:
            logger.error(f"ä»£ç†è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def is_x_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º X (Twitter) URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "twitter.com",
            "x.com",
            "www.twitter.com",
            "www.x.com",
        ]

    def is_youtube_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º YouTube URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "youtube.com",
            "www.youtube.com",
            "youtu.be",
            "m.youtube.com",
        ]

    def is_facebook_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º Facebook URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "facebook.com",
            "www.facebook.com",
            "m.facebook.com",
            "fb.watch",
            "fb.com",
        ]

    def is_xvideos_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º xvideos URL"""
        parsed = urlparse(url)
        return any(
            domain in parsed.netloc for domain in ["xvideos.com", "www.xvideos.com"]
        )

    def is_pornhub_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º pornhub URL"""
        parsed = urlparse(url)
        return any(
            domain in parsed.netloc
            for domain in ["pornhub.com", "www.pornhub.com", "cn.pornhub.com"]
        )

    def is_bilibili_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º Bilibili URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "bilibili.com",
            "www.bilibili.com",
            "space.bilibili.com",
            "b23.tv",
        ]

    def is_telegraph_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º Telegraph URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in ["telegra.ph", "telegraph.co"]

    def is_douyin_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæŠ–éŸ³ URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "douyin.com",
            "www.douyin.com",
            "v.douyin.com",
            "www.iesdouyin.com",
            "iesdouyin.com"
        ]

    def is_kuaishou_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¿«æ‰‹ URL"""
        parsed = urlparse(url)
        # æ”¯æŒå¤šç§å¿«æ‰‹URLæ ¼å¼
        if parsed.netloc.lower() in [
            "kuaishou.com",
            "www.kuaishou.com",
            "v.kuaishou.com",
            "m.kuaishou.com",
            "f.kuaishou.com"
        ]:
            return True

        # æ£€æŸ¥URLè·¯å¾„æ˜¯å¦åŒ…å«å¿«æ‰‹ç‰¹å¾
        if 'kuaishou.com' in url.lower():
            return True

        return False

    def extract_urls_from_text(self, text: str) -> list:
        """ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰URL - æ”¹è¿›ç‰ˆæœ¬æ”¯æŒæ›´å¤šæ ¼å¼"""
        urls = []

        # åŸºç¡€URLæ­£åˆ™æ¨¡å¼ - æ”¯æŒä¸­æ–‡æ–‡æœ¬ä¸­çš„URL
        url_patterns = [
            # æ ‡å‡†HTTP/HTTPS URL
            r'https?://[^\s\u4e00-\u9fff]+',
            # å¿«æ‰‹çŸ­é“¾æ¥ç‰¹æ®Šå¤„ç†
            r'v\.kuaishou\.com/[A-Za-z0-9]+',
            # æŠ–éŸ³çŸ­é“¾æ¥
            r'v\.douyin\.com/[A-Za-z0-9]+',
            # Facebooké“¾æ¥
            r'facebook\.com/[A-Za-z0-9/._-]+',
            r'fb\.watch/[A-Za-z0-9]+',
            # å…¶ä»–çŸ­é“¾æ¥æ ¼å¼
            r'[a-zA-Z0-9.-]+\.com/[A-Za-z0-9/]+',
        ]

        for pattern in url_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                # æ¸…ç†URLæœ«å°¾çš„æ ‡ç‚¹ç¬¦å·
                clean_url = match.rstrip('.,;!?ã€‚ï¼Œï¼›ï¼ï¼Ÿ')
                # ç¡®ä¿URLæœ‰åè®®å‰ç¼€
                if not clean_url.startswith(('http://', 'https://')):
                    clean_url = 'https://' + clean_url
                urls.append(clean_url)

        # å»é‡å¹¶ä¿æŒé¡ºåº
        seen = set()
        unique_urls = []
        for url in urls:
            if url not in seen:
                seen.add(url)
                unique_urls.append(url)

        return unique_urls

    def _extract_clean_url_from_text(self, text: str) -> str:
        """ä»åŒ…å«æè¿°æ–‡æœ¬çš„å­—ç¬¦ä¸²ä¸­æå–çº¯å‡€çš„URL"""
        try:
            # ä½¿ç”¨å·²æœ‰çš„URLæå–æ–¹æ³•
            urls = self.extract_urls_from_text(text)
            if urls:
                return urls[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„URL

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå¯èƒ½æ–‡æœ¬æœ¬èº«å°±æ˜¯ä¸€ä¸ªURL
            text = text.strip()
            if text.startswith(('http://', 'https://')):
                # æå–URLéƒ¨åˆ†ï¼ˆåˆ°ç¬¬ä¸€ä¸ªç©ºæ ¼ä¸ºæ­¢ï¼‰
                url_part = text.split()[0] if ' ' in text else text
                return url_part

            return None
        except Exception as e:
            logger.warning(f"æå–çº¯å‡€URLå¤±è´¥: {e}")
            return None

    def is_xiaohongshu_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå°çº¢ä¹¦ URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "xiaohongshu.com",
            "www.xiaohongshu.com",
            "xhslink.com",
        ]

    def is_weibo_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¾®åš URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "weibo.com",
            "www.weibo.com",
            "m.weibo.com",
            "video.weibo.com",
            "t.cn",  # å¾®åšçŸ­é“¾æ¥
            "weibo.cn",  # å¾®åšçŸ­é“¾æ¥
            "sinaurl.cn",  # æ–°æµªçŸ­é“¾æ¥
        ]

    def _expand_weibo_short_url(self, url: str) -> str:
        """å±•å¼€å¾®åšçŸ­é“¾æ¥ä¸ºé•¿é“¾æ¥"""
        import requests
        import re

        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¾®åšçŸ­é“¾æ¥
            parsed = urlparse(url)
            short_domains = ["t.cn", "weibo.cn", "sinaurl.cn"]

            if parsed.netloc.lower() in short_domains:
                logger.info(f"ğŸ”„ æ£€æµ‹åˆ°å¾®åšçŸ­é“¾æ¥ï¼Œå¼€å§‹å±•å¼€: {url}")

                # ä¼˜å…ˆä½¿ç”¨ç§»åŠ¨ç«¯User-Agentï¼Œé¿å…é‡å®šå‘åˆ°ç™»å½•é¡µé¢
                mobile_headers = {
                    'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                }

                # æ¡Œé¢ç«¯User-Agentä½œä¸ºå¤‡ç”¨
                desktop_headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                }

                # å…ˆå°è¯•ç§»åŠ¨ç«¯User-Agentçš„GETè¯·æ±‚
                expanded_url = None
                try:
                    logger.info(f"ğŸ”„ ä½¿ç”¨ç§»åŠ¨ç«¯User-Agentè¯·æ±‚...")
                    response = requests.get(url, headers=mobile_headers, allow_redirects=True, timeout=10)
                    expanded_url = response.url
                    logger.info(f"ğŸ”„ ç§»åŠ¨ç«¯è¯·æ±‚é‡å®šå‘åˆ°: {expanded_url}")

                    # æ£€æŸ¥æ˜¯å¦å¾—åˆ°äº†æœ‰æ•ˆçš„å¾®åšè§†é¢‘URL
                    if "weibo.com" in expanded_url and ("tv/show" in expanded_url or "video" in expanded_url):
                        logger.info(f"âœ… ç§»åŠ¨ç«¯è¯·æ±‚æˆåŠŸè·å–å¾®åšè§†é¢‘URL")
                        # å¦‚æœæ˜¯h5.video.weibo.comï¼Œè½¬æ¢ä¸ºæ ‡å‡†çš„weibo.comæ ¼å¼
                        if "h5.video.weibo.com" in expanded_url:
                            expanded_url = expanded_url.replace("h5.video.weibo.com", "weibo.com/tv")
                            logger.info(f"ğŸ”„ è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼: {expanded_url}")
                    else:
                        logger.info(f"âš ï¸ ç§»åŠ¨ç«¯è¯·æ±‚æœªè·å–åˆ°æ ‡å‡†å¾®åšè§†é¢‘URLï¼Œå°è¯•æ¡Œé¢ç«¯...")
                        raise Exception("ç§»åŠ¨ç«¯æœªè·å–åˆ°æ ‡å‡†URL")

                except Exception as e:
                    logger.warning(f"âš ï¸ ç§»åŠ¨ç«¯è¯·æ±‚å¤±è´¥: {e}")
                    # å¦‚æœç§»åŠ¨ç«¯è¯·æ±‚å¤±è´¥ï¼Œå°è¯•æ¡Œé¢ç«¯è¯·æ±‚
                    try:
                        logger.info(f"ğŸ”„ ä½¿ç”¨æ¡Œé¢ç«¯User-Agentè¯·æ±‚...")
                        response = requests.get(url, headers=desktop_headers, allow_redirects=True, timeout=10)
                        expanded_url = response.url
                        logger.info(f"ğŸ”„ æ¡Œé¢ç«¯è¯·æ±‚é‡å®šå‘åˆ°: {expanded_url}")
                    except Exception as e2:
                        logger.warning(f"âš ï¸ æ¡Œé¢ç«¯è¯·æ±‚ä¹Ÿå¤±è´¥: {e2}")
                        return url

                # æ£€æŸ¥å±•å¼€åçš„URLæ˜¯å¦æœ‰æ•ˆ
                if expanded_url and expanded_url != url:
                    # è¿›ä¸€æ­¥å¤„ç†å¯èƒ½çš„ä¸­é—´è·³è½¬é¡µé¢
                    if "passport.weibo.com" in expanded_url and "url=" in expanded_url:
                        # ä»è·³è½¬é¡µé¢URLä¸­æå–çœŸå®çš„ç›®æ ‡URL
                        import urllib.parse
                        try:
                            # å°è¯•å¤šç§URLå‚æ•°æå–æ–¹å¼
                            match = re.search(r'url=([^&]+)', expanded_url)
                            if match:
                                encoded_url = match.group(1)
                                # å¤šæ¬¡URLè§£ç ï¼Œå› ä¸ºå¯èƒ½è¢«å¤šæ¬¡ç¼–ç 
                                real_url = urllib.parse.unquote(encoded_url)
                                real_url = urllib.parse.unquote(real_url)  # å†æ¬¡è§£ç 

                                # æ¸…ç†URLå‚æ•°ï¼Œç§»é™¤ä¸å¿…è¦çš„å‚æ•°
                                if '?' in real_url:
                                    base_url, params = real_url.split('?', 1)
                                    # ä¿ç•™é‡è¦å‚æ•°ï¼Œç§»é™¤è·Ÿè¸ªå‚æ•°
                                    important_params = []
                                    for param in params.split('&'):
                                        if '=' in param:
                                            key, value = param.split('=', 1)
                                            if key in ['fid', 'id', 'video_id']:  # ä¿ç•™é‡è¦çš„è§†é¢‘IDå‚æ•°
                                                important_params.append(param)

                                    if important_params:
                                        real_url = base_url + '?' + '&'.join(important_params)
                                    else:
                                        real_url = base_url

                                logger.info(f"ğŸ”„ ä»è·³è½¬é¡µé¢æå–çœŸå®URL: {real_url}")
                                expanded_url = real_url
                        except Exception as e:
                            logger.warning(f"âš ï¸ æå–çœŸå®URLå¤±è´¥: {e}")
                            # å¦‚æœæå–å¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨åŸå§‹çŸ­é“¾æ¥
                            logger.info(f"ğŸ”„ å›é€€åˆ°åŸå§‹çŸ­é“¾æ¥: {url}")
                            expanded_url = url

                    logger.info(f"âœ… å¾®åšçŸ­é“¾æ¥å±•å¼€æˆåŠŸ: {url} -> {expanded_url}")
                    return expanded_url
                else:
                    logger.warning(f"âš ï¸ çŸ­é“¾æ¥å±•å¼€åURLæ— å˜åŒ–ï¼Œä½¿ç”¨åŸURL: {url}")
                    return url
            else:
                # ä¸æ˜¯çŸ­é“¾æ¥ï¼Œç›´æ¥è¿”å›åŸURL
                return url

        except Exception as e:
            logger.warning(f"âš ï¸ å±•å¼€å¾®åšçŸ­é“¾æ¥å¤±è´¥: {e}")
            logger.warning(f"âš ï¸ å°†ä½¿ç”¨åŸå§‹URL: {url}")
            return url

    def is_instagram_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºInstagram URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "instagram.com",
            "www.instagram.com",
            "m.instagram.com",
        ]

    def is_tiktok_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºTikTok URL"""
        parsed = urlparse(url)
        return parsed.netloc.lower() in [
            "tiktok.com",
            "www.tiktok.com",
            "m.tiktok.com",
            "vm.tiktok.com",
        ]

    def is_x_playlist_url(self, url: str) -> tuple:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºXæ’­æ”¾åˆ—è¡¨URLï¼Œå¹¶æå–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯
        Returns:
            tuple: (is_playlist, playlist_info) æˆ– (False, None)
        """
        import yt_dlp
        
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºX URL
            if not self.is_x_url(url):
                return False, None
            
            # ä½¿ç”¨yt-dlpæ£€æŸ¥æ˜¯å¦ä¸ºæ’­æ”¾åˆ—è¡¨
            ydl_opts = {
                'quiet': True,
                'no_warnings': True,
                'extract_flat': True,
            }
            
            if self.proxy_host:
                ydl_opts['proxy'] = self.proxy_host
            
            if self.x_cookies_path:
                ydl_opts['cookiefile'] = self.x_cookies_path
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæ’­æ”¾åˆ—è¡¨
                if info and '_type' in info and info['_type'] == 'playlist':
                    entries = info.get('entries', [])
                    if len(entries) > 1:
                        playlist_info = {
                            'total_videos': len(entries),
                            'playlist_title': info.get('title', 'Xæ’­æ”¾åˆ—è¡¨'),
                            'playlist_url': url,
                            'entries': entries
                        }
                        logger.info(f"æ£€æµ‹åˆ°Xæ’­æ”¾åˆ—è¡¨: {playlist_info['playlist_title']}, å…±{len(entries)}ä¸ªè§†é¢‘")
                        return True, playlist_info
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæ¡ç›®
                if info and 'entries' in info and len(info['entries']) > 1:
                    playlist_info = {
                        'total_videos': len(info['entries']),
                        'playlist_title': info.get('title', 'Xæ’­æ”¾åˆ—è¡¨'),
                        'playlist_url': url,
                        'entries': info['entries']
                    }
                    logger.info(f"æ£€æµ‹åˆ°Xæ’­æ”¾åˆ—è¡¨: {playlist_info['playlist_title']}, å…±{len(info['entries'])}ä¸ªè§†é¢‘")
                    return True, playlist_info
                    
            return False, None
        except Exception as e:
            logger.warning(f"æ£€æŸ¥Xæ’­æ”¾åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            return False, None

    def is_bilibili_list_url(self, url: str) -> tuple:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºBç«™ç”¨æˆ·åˆ—è¡¨URLï¼Œå¹¶æå–ç”¨æˆ·IDå’Œåˆ—è¡¨ID
        Returns:
            tuple: (is_list, uid, list_id) æˆ– (False, None, None)
        """
        import re

        # åŒ¹é…Bç«™ç”¨æˆ·åˆ—è¡¨URL:
        # https://space.bilibili.com/477348669/lists/2111173?type=season
        pattern = r"space\.bilibili\.com/(\d+)/lists/(\d+)"
        match = re.search(pattern, url)
        if match:
            uid = match.group(1)
            list_id = match.group(2)
            return True, uid, list_id
        return False, None, None

    def is_bilibili_multi_part_video(self, url: str) -> tuple:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºBç«™å¤šPè§†é¢‘ï¼Œå¹¶æå–BVå·
        Returns:
            tuple: (is_multi_part, bv_id) æˆ– (False, None)
        """
        import re
        import yt_dlp
        try:
            # é¦–å…ˆå°è¯•ä»URLä¸­æå–BVå·
            bv_pattern = r'BV[a-zA-Z0-9]+'
            bv_match = re.search(bv_pattern, url)

            # å¦‚æœURLä¸­æ²¡æœ‰BVå·ï¼Œå¯èƒ½æ˜¯çŸ­é“¾æ¥ï¼Œéœ€è¦å…ˆè§£æ
            if not bv_match and ("b23.tv" in url or "b23.wtf" in url):
                logger.info(f"ğŸ”„ æ£€æµ‹åˆ°Bç«™çŸ­é“¾æ¥ï¼Œå…ˆè§£æè·å–çœŸå®URL: {url}")
                try:
                    # ä½¿ç”¨yt-dlpè§£æçŸ­é“¾æ¥
                    temp_opts = {
                        'quiet': True,
                        'no_warnings': True,
                    }
                    with yt_dlp.YoutubeDL(temp_opts) as ydl:
                        temp_info = ydl.extract_info(url, download=False)

                    if temp_info.get('webpage_url'):
                        real_url = temp_info['webpage_url']
                        logger.info(f"ğŸ”„ çŸ­é“¾æ¥è§£æç»“æœ: {real_url}")
                        # ä»çœŸå®URLä¸­æå–BVå·
                        bv_match = re.search(bv_pattern, real_url)
                        if bv_match:
                            logger.info(f"âœ… ä»çŸ­é“¾æ¥ä¸­æå–åˆ°BVå·: {bv_match.group(0)}")
                except Exception as e:
                    logger.warning(f"âš ï¸ è§£æçŸ­é“¾æ¥å¤±è´¥: {e}")

            if not bv_match:
                return False, None

            bv_id = bv_match.group(0)
            
            # ä½¿ç”¨yt-dlpæ£€æŸ¥æ˜¯å¦ä¸ºå¤šPè§†é¢‘æˆ–åˆé›†
            # å…ˆå°è¯•å¿«é€Ÿæ£€æµ‹ï¼ˆextract_flat=Trueï¼‰
            ydl_opts_flat = {
                'quiet': True,
                'no_warnings': True,
                'extract_flat': True,
                'flat_playlist': True,
            }

            try:
                with yt_dlp.YoutubeDL(ydl_opts_flat) as ydl:
                    info = ydl.extract_info(url, download=False)

                    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæ¡ç›®
                    if info and '_type' in info and info['_type'] == 'playlist':
                        entries = info.get('entries', [])
                        if len(entries) > 1:
                            logger.info(f"âœ… æ£€æµ‹åˆ°Bç«™å¤šå†…å®¹è§†é¢‘: {bv_id}, å…±{len(entries)}ä¸ªæ¡ç›®")
                            return True, bv_id

                    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†Pä¿¡æ¯
                    if info and 'entries' in info and len(info['entries']) > 1:
                        logger.info(f"âœ… æ£€æµ‹åˆ°Bç«™å¤šå†…å®¹è§†é¢‘: {bv_id}, å…±{len(info['entries'])}ä¸ªæ¡ç›®")
                        return True, bv_id
            except Exception as e:
                logger.warning(f"å¿«é€Ÿæ£€æµ‹å¤±è´¥: {e}")

            # å¦‚æœå¿«é€Ÿæ£€æµ‹å¤±è´¥ï¼Œå°è¯•å®Œæ•´æ£€æµ‹ï¼ˆextract_flat=Falseï¼‰
            logger.info(f"ğŸ”„ å¿«é€Ÿæ£€æµ‹æœªå‘ç°å¤šå†…å®¹ï¼Œå°è¯•å®Œæ•´æ£€æµ‹: {bv_id}")

            # ä½¿ç”¨è¾“å‡ºæ•è·æ¥æ£€æµ‹anthology
            import io
            from contextlib import redirect_stdout, redirect_stderr

            stdout_capture = io.StringIO()
            stderr_capture = io.StringIO()

            ydl_opts_full = {
                'quiet': False,  # æ”¹ä¸ºFalseä»¥ä¾¿çœ‹åˆ°æ›´å¤šä¿¡æ¯
                'no_warnings': False,  # æ”¹ä¸ºFalseä»¥ä¾¿çœ‹åˆ°è­¦å‘Šä¿¡æ¯
                'extract_flat': False,
                'noplaylist': False,
                'simulate': True,  # æ·»åŠ æ¨¡æ‹Ÿæ¨¡å¼
            }

            try:
                with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                    with yt_dlp.YoutubeDL(ydl_opts_full) as ydl:
                        info = ydl.extract_info(url, download=False)

                # æ£€æŸ¥æ•è·çš„è¾“å‡ºä¸­æ˜¯å¦åŒ…å«anthology
                stdout_output = stdout_capture.getvalue()
                stderr_output = stderr_capture.getvalue()
                all_output = (stdout_output + stderr_output).lower()

                if 'anthology' in all_output or 'extracting videos in anthology' in all_output:
                    logger.info(f"âœ… ä»yt-dlpè¾“å‡ºä¸­æ£€æµ‹åˆ°anthology: {bv_id}")
                    return True, bv_id

                # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæ¡ç›®
                    if info and '_type' in info and info['_type'] == 'playlist':
                        entries = info.get('entries', [])
                        if len(entries) > 1:
                            logger.info(f"âœ… å®Œæ•´æ£€æµ‹å‘ç°Bç«™å¤šå†…å®¹è§†é¢‘: {bv_id}, å…±{len(entries)}ä¸ªæ¡ç›®")
                            return True, bv_id

                    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†Pä¿¡æ¯
                    if info and 'entries' in info and len(info['entries']) > 1:
                        logger.info(f"âœ… å®Œæ•´æ£€æµ‹å‘ç°Bç«™å¤šå†…å®¹è§†é¢‘: {bv_id}, å…±{len(info['entries'])}ä¸ªæ¡ç›®")
                        return True, bv_id

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«anthologyä¿¡æ¯ï¼ˆBç«™åˆé›†çš„ç‰¹å¾ï¼‰
                    info_str = str(info).lower()
                    if info and any(key in info_str for key in ['anthology', 'collection', 'series']):
                        logger.info(f"âœ… æ£€æµ‹åˆ°Bç«™åˆé›†ç‰¹å¾: {bv_id}")
                        return True, bv_id

                    # é¢å¤–æ£€æŸ¥ï¼šä½¿ç”¨æ¨¡æ‹Ÿä¸‹è½½æ¥æ£€æµ‹anthology
                    try:
                        logger.info(f"ğŸ” ä½¿ç”¨æ¨¡æ‹Ÿä¸‹è½½æ£€æµ‹anthology: {bv_id}")

                        # ä½¿ç”¨æ›´è¯¦ç»†çš„æ—¥å¿—æ•è·anthologyä¿¡æ¯
                        import io
                        import sys
                        from contextlib import redirect_stdout, redirect_stderr

                        # æ•è·yt-dlpçš„è¾“å‡º
                        stdout_capture = io.StringIO()
                        stderr_capture = io.StringIO()

                        simulate_opts = {
                            'quiet': False,  # æ”¹ä¸ºFalseä»¥æ•è·anthologyä¿¡æ¯
                            'no_warnings': False,  # æ”¹ä¸ºFalseä»¥æ•è·æ›´å¤šä¿¡æ¯
                            'simulate': True,
                            'extract_flat': False,
                        }

                        with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                            with yt_dlp.YoutubeDL(simulate_opts) as sim_ydl:
                                sim_info = sim_ydl.extract_info(url, download=False)

                        # æ£€æŸ¥æ•è·çš„è¾“å‡ºä¸­æ˜¯å¦åŒ…å«anthology
                        stdout_output = stdout_capture.getvalue().lower()
                        stderr_output = stderr_capture.getvalue().lower()
                        all_output = stdout_output + stderr_output

                        if 'anthology' in all_output or 'extracting videos in anthology' in all_output:
                            logger.info(f"âœ… ä»è¾“å‡ºä¸­æ£€æµ‹åˆ°anthologyå…³é”®è¯: {bv_id}")
                            return True, bv_id

                        # æ£€æŸ¥æ¨¡æ‹Ÿä¸‹è½½çš„ä¿¡æ¯ä¸­æ˜¯å¦åŒ…å«anthology
                        sim_str = str(sim_info).lower()
                        if 'anthology' in sim_str:
                            logger.info(f"âœ… æ¨¡æ‹Ÿä¸‹è½½æ£€æµ‹åˆ°anthologyå…³é”®è¯: {bv_id}")
                            return True, bv_id

                        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªentries
                        if sim_info and 'entries' in sim_info and len(sim_info['entries']) > 1:
                            logger.info(f"âœ… æ¨¡æ‹Ÿä¸‹è½½æ£€æµ‹åˆ°å¤šä¸ªæ¡ç›®: {bv_id}, å…±{len(sim_info['entries'])}ä¸ª")
                            return True, bv_id

                    except Exception as sim_e:
                        logger.warning(f"æ¨¡æ‹Ÿä¸‹è½½æ£€æµ‹å¤±è´¥: {sim_e}")

                    # å°è¯•ä»é‡å®šå‘URLä¸­æå–ç”¨æˆ·IDï¼Œæ£€æŸ¥ç”¨æˆ·ç©ºé—´æ˜¯å¦æœ‰å¤šä¸ªè§†é¢‘
                    webpage_url = info.get('webpage_url', '')
                    if webpage_url and 'up_id=' in webpage_url:
                        import re
                        up_id_match = re.search(r'up_id=(\d+)', webpage_url)
                        if up_id_match:
                            up_id = up_id_match.group(1)
                            logger.info(f"ğŸ” å°è¯•æ£€æŸ¥ç”¨æˆ·ç©ºé—´: {up_id}")

                            # æ£€æŸ¥ç”¨æˆ·ç©ºé—´æ˜¯å¦æœ‰å¤šä¸ªè§†é¢‘
                            user_space_url = f"https://space.bilibili.com/{up_id}"
                            try:
                                user_opts = {
                                    'quiet': True,
                                    'no_warnings': True,
                                    'extract_flat': True,
                                    'flat_playlist': True,
                                }
                                with yt_dlp.YoutubeDL(user_opts) as user_ydl:
                                    user_info = user_ydl.extract_info(user_space_url, download=False)

                                if user_info and 'entries' in user_info:
                                    user_entries = user_info['entries']
                                    if len(user_entries) > 1:
                                        logger.info(f"âœ… ç”¨æˆ·ç©ºé—´æ£€æµ‹åˆ°å¤šä¸ªè§†é¢‘: {len(user_entries)}ä¸ªï¼Œå¯èƒ½æ˜¯åˆé›†åˆ†äº«")
                                        return True, bv_id
                            except Exception as user_e:
                                logger.warning(f"ç”¨æˆ·ç©ºé—´æ£€æµ‹å¤±è´¥: {user_e}")

            except Exception as e:
                logger.warning(f"å®Œæ•´æ£€æµ‹å¤±è´¥: {e}")
                    
            return False, bv_id
        except Exception as e:
            logger.warning(f"æ£€æŸ¥Bç«™å¤šPè§†é¢‘æ—¶å‡ºé”™: {e}")
            return False, None

    def is_youtube_playlist_url(self, url: str) -> tuple:
        """æ£€æŸ¥æ˜¯å¦ä¸º YouTube æ’­æ”¾åˆ—è¡¨ URL"""
        import re

        # åŒ¹é… YouTube æ’­æ”¾åˆ—è¡¨ URL
        patterns = [
            r"(?:youtube\.com/playlist\?list=|youtube\.com/watch\?.*&list=)([a-zA-Z0-9_-]+)",
            r"youtube\.com/playlist\?list=([a-zA-Z0-9_-]+)",
        ]
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                playlist_id = match.group(1)
                return True, playlist_id
        return False, None

    def is_youtube_channel_playlists_url(self, url: str) -> tuple:
        """æ£€æŸ¥æ˜¯å¦ä¸º YouTube é¢‘é“æ’­æ”¾åˆ—è¡¨é¡µé¢ URL æˆ–é¢‘é“ä¸»é¡µ URL"""
        import re

        # é¦–å…ˆåŒ¹é…å·²ç»åŒ…å« /playlists çš„URL
        playlists_patterns = [
            r"youtube\.com/@([^/\?]+)/playlists",
            r"youtube\.com/c/([^/\?]+)/playlists",
            r"youtube\.com/channel/([^/\?]+)/playlists",
            r"youtube\.com/user/([^/\?]+)/playlists",
        ]
        for pattern in playlists_patterns:
            match = re.search(pattern, url)
            if match:
                channel_identifier = match.group(1)
                return True, url

        # ç„¶ååŒ¹é…é¢‘é“ä¸»é¡µURLï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºæ’­æ”¾åˆ—è¡¨URL
        channel_patterns = [
            r"youtube\.com/@([^/\?]+)(?:\?.*)?$",  # @username æ ¼å¼
            r"youtube\.com/c/([^/\?]+)(?:\?.*)?$",  # /c/channel æ ¼å¼
            r"youtube\.com/channel/([^/\?]+)(?:\?.*)?$",  # /channel/ID æ ¼å¼
            r"youtube\.com/user/([^/\?]+)(?:\?.*)?$",  # /user/username æ ¼å¼
        ]
        for pattern in channel_patterns:
            match = re.search(pattern, url)
            if match:
                channel_identifier = match.group(1)
                # æ„å»ºæ’­æ”¾åˆ—è¡¨URL
                if "@" in url:
                    playlists_url = f"https://www.youtube.com/@{channel_identifier}/playlists"
                elif "/c/" in url:
                    playlists_url = f"https://www.youtube.com/c/{channel_identifier}/playlists"
                elif "/channel/" in url:
                    playlists_url = f"https://www.youtube.com/channel/{channel_identifier}/playlists"
                elif "/user/" in url:
                    playlists_url = f"https://www.youtube.com/user/{channel_identifier}/playlists"
                else:
                    playlists_url = url

                logger.info(f"ğŸ” æ£€æµ‹åˆ°YouTubeé¢‘é“ä¸»é¡µï¼Œè½¬æ¢ä¸ºæ’­æ”¾åˆ—è¡¨URL: {playlists_url}")
                return True, playlists_url
        return False, None

    def get_download_path(self, url: str) -> Path:
        """æ ¹æ® URL ç¡®å®šä¸‹è½½è·¯å¾„"""
        if self.is_x_url(url):
            return self.x_download_path.resolve()
        elif self.is_youtube_url(url):
            return self.youtube_download_path.resolve()
        elif self.is_xvideos_url(url):
            return self.xvideos_download_path.resolve()
        elif self.is_pornhub_url(url):
            return self.pornhub_download_path.resolve()
        elif self.is_bilibili_url(url):
            return self.bilibili_download_path.resolve()
        elif self.is_telegraph_url(url):
            return self.telegraph_download_path.resolve()
        elif self.is_douyin_url(url):
            return self.douyin_download_path.resolve()
        elif self.is_kuaishou_url(url):
            return self.kuaishou_download_path.resolve()
        elif self.is_facebook_url(url):
            return self.facebook_download_path.resolve()
        elif self.is_xiaohongshu_url(url):
            return self.xiaohongshu_download_path.resolve()  # å°çº¢ä¹¦ä½¿ç”¨è‡ªå·±çš„ç›®å½•
        elif self.is_weibo_url(url):
            return self.weibo_download_path.resolve()
        elif self.is_instagram_url(url):
            return self.instagram_download_path.resolve()
        elif self.is_tiktok_url(url):
            return self.tiktok_download_path.resolve()
        else:
            return self.youtube_download_path.resolve()

    def get_platform_name(self, url: str) -> str:
        """è·å–å¹³å°åç§°"""
        if self.is_x_url(url):
            return "x"
        elif self.is_youtube_url(url):
            return "youtube"
        elif self.is_xvideos_url(url):
            return "xvideos"
        elif self.is_pornhub_url(url):
            return "pornhub"
        elif self.is_bilibili_url(url):
            return "bilibili"
        elif self.is_telegraph_url(url):
            return "telegraph"
        elif self.is_douyin_url(url):
            return "douyin"
        elif self.is_kuaishou_url(url):
            return "kuaishou"
        elif self.is_facebook_url(url):
            return "facebook"
        elif self.is_xiaohongshu_url(url):
            return "xiaohongshu"
        elif self.is_weibo_url(url):
            return "weibo"
        elif self.is_instagram_url(url):
            return "instagram"
        elif self.is_tiktok_url(url):
            return "tiktok"
        else:
            return "other"

    def check_ytdlp_version(self) -> Dict[str, Any]:
        """æ£€æŸ¥yt-dlpç‰ˆæœ¬"""
        try:
            import yt_dlp

            version = yt_dlp.version.__version__
            return {
                "success": True,
                "version": version,
                "info": f"yt-dlp ç‰ˆæœ¬: {version}",
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

    def check_video_formats(self, url: str) -> Dict[str, Any]:
        """æ£€æŸ¥è§†é¢‘çš„å¯ç”¨æ ¼å¼"""
        try:
            ydl_opts = {
                "quiet": True,
                "no_warnings": True,
                "listformats": True,
            }
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                formats = info.get("formats", [])
                video_formats = []
                audio_formats = []
                for fmt in formats:
                    format_info = {
                        "id": fmt.get("format_id", "unknown"),
                        "ext": fmt.get("ext", "unknown"),
                        "quality": fmt.get("format_note", "unknown"),
                        "filesize": fmt.get("filesize", 0),
                        "height": fmt.get("height", 0),
                        "width": fmt.get("width", 0),
                        "fps": fmt.get("fps", 0),
                        "vcodec": fmt.get("vcodec", "none"),
                        "acodec": fmt.get("acodec", "none"),
                        "format_type": (
                            "video" if fmt.get("vcodec", "none") != "none" else "audio"
                        ),
                    }
                    if format_info["format_type"] == "video":
                        video_formats.append(format_info)
                    else:
                        audio_formats.append(format_info)
                # æŒ‰è´¨é‡æ’åº
                video_formats.sort(
                    key=lambda x: (x["height"], x["filesize"]), reverse=True
                )
                audio_formats.sort(key=lambda x: x["filesize"], reverse=True)
                # æ£€æŸ¥æ˜¯å¦æœ‰é«˜åˆ†è¾¨ç‡æ ¼å¼
                has_high_res = any(f.get("height", 0) >= 2160 for f in video_formats)
                has_4k = any(f.get("height", 0) >= 2160 for f in video_formats)
                has_1080p = any(f.get("height", 0) >= 1080 for f in video_formats)
                has_720p = any(f.get("height", 0) >= 720 for f in video_formats)
                return {
                    "success": True,
                    "title": info.get("title", "Unknown"),
                    "duration": info.get("duration", 0),
                    "video_formats": video_formats[:10],  # åªæ˜¾ç¤ºå‰10ä¸ªè§†é¢‘æ ¼å¼
                    "audio_formats": audio_formats[:5],  # åªæ˜¾ç¤ºå‰5ä¸ªéŸ³é¢‘æ ¼å¼
                    "quality_info": {
                        "has_4k": has_4k,
                        "has_1080p": has_1080p,
                        "has_720p": has_720p,
                        "total_video_formats": len(video_formats),
                        "total_audio_formats": len(audio_formats),
                    },
                }
        except Exception as e:
            logger.error(f"æ ¼å¼æ£€æŸ¥å¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    def get_media_info(self, file_path: str) -> Dict[str, Any]:
        """ä½¿ç”¨ ffprobe è·å–åª’ä½“æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return {}
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logger.warning(f"âš ï¸ æ–‡ä»¶å¤§å°ä¸º0: {file_path}")
                return {}
            
            cmd = [
                "ffprobe",
                "-v",
                "quiet",
                "-print_format",
                "json",
                "-show_format",
                "-show_streams",
                str(file_path),
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            info = json.loads(result.stdout)
            media_info = {}
            if "format" in info:
                duration = float(info["format"].get("duration", 0))
                if duration > 0:
                    media_info["duration"] = (
                        time.strftime("%H:%M:%S", time.gmtime(duration))
                        if duration >= 3600
                        else time.strftime("%M:%S", time.gmtime(duration))
                    )
                size = int(info["format"].get("size", 0) or 0)
                if size > 0:
                    media_info["size"] = f"{size / (1024 * 1024):.2f} MB"
            video_stream = next(
                (s for s in info.get("streams", []) if s.get("codec_type") == "video"),
                None,
            )
            if video_stream:
                width, height = video_stream.get("width"), video_stream.get("height")
                if width and height:
                    media_info["resolution"] = f"{width}x{height}"
            audio_stream = next(
                (s for s in info.get("streams", []) if s.get("codec_type") == "audio"),
                None,
            )
            if audio_stream:
                bit_rate = int(audio_stream.get("bit_rate", 0))
                if bit_rate > 0:
                    media_info["bit_rate"] = f"{bit_rate // 1000} kbps"
            return media_info
        except (
            subprocess.CalledProcessError,
            FileNotFoundError,
            json.JSONDecodeError,
        ) as e:
            logger.warning(f"âš ï¸ æ— æ³•ä½¿ç”¨ ffprobe è·å–åª’ä½“ä¿¡æ¯: {e}")
            # è¿”å›åŸºæœ¬çš„æ–‡ä»¶ä¿¡æ¯
            try:
                if os.path.exists(file_path):
                    file_size = os.path.getsize(file_path)
                    if file_size > 0:
                        return {"size": f"{file_size / (1024 * 1024):.2f} MB"}
            except Exception as e2:
                logger.warning(f"âš ï¸ è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {e2}")
            return {}

    def single_video_find_downloaded_file(
        self, download_path: Path, progress_data: dict = None, expected_title: str = None, url: str = None
    ) -> str:
        """
        å•è§†é¢‘ä¸‹è½½çš„æ–‡ä»¶æŸ¥æ‰¾æ–¹æ³•

        Args:
            download_path: ä¸‹è½½ç›®å½•
            progress_data: è¿›åº¦æ•°æ®ï¼ŒåŒ…å«final_filename
            expected_title: é¢„æœŸçš„æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰
            url: åŸå§‹URLï¼Œç”¨äºåˆ¤æ–­å¹³å°ç±»å‹

        Returns:
            str: æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
        """
        # 1. ä¼˜å…ˆä½¿ç”¨progress_hookè®°å½•çš„æ–‡ä»¶è·¯å¾„
        if progress_data and progress_data.get("final_filename"):
            final_file_path = progress_data["final_filename"]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­é—´æ–‡ä»¶ï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥æŸ¥æ‰¾åˆå¹¶åçš„æ–‡ä»¶
            original_path = Path(final_file_path)
            base_name = original_path.stem
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­é—´æ–‡ä»¶ï¼ˆåŒ…å«.f140, .f401ç­‰æ ¼å¼æ ‡è¯†ç¬¦ï¼‰
            is_intermediate_file = False
            if "." in base_name:
                parts = base_name.split(".")
                # å¦‚æœæœ€åä¸€éƒ¨åˆ†æ˜¯æ•°å­—ï¼ˆå¦‚f140, f401ï¼‰ï¼Œåˆ™ç§»é™¤å®ƒ
                if (
                    len(parts) > 1
                    and parts[-1].startswith("f")
                    and parts[-1][1:].isdigit()
                ):
                    base_name = ".".join(parts[:-1])
                    is_intermediate_file = True
            
            # å¦‚æœæ˜¯ä¸­é—´æ–‡ä»¶ï¼Œç›´æ¥æŸ¥æ‰¾åˆå¹¶åçš„æ–‡ä»¶
            if is_intermediate_file:
                logger.info(f"ğŸ” æ£€æµ‹åˆ°ä¸­é—´æ–‡ä»¶ï¼Œç›´æ¥æŸ¥æ‰¾åˆå¹¶åçš„æ–‡ä»¶: {final_file_path}")
                # æ„é€ æœ€ç»ˆæ–‡ä»¶åï¼ˆä¼˜å…ˆæŸ¥æ‰¾.mp4ï¼Œç„¶åæ˜¯å…¶ä»–æ ¼å¼ï¼‰
                possible_extensions = [".mp4", ".mkv", ".webm", ".avi", ".mov"]
                for ext in possible_extensions:
                    final_merged_file = original_path.parent / f"{base_name}{ext}"
                    logger.info(f"ğŸ” å°è¯•æŸ¥æ‰¾åˆå¹¶åçš„æ–‡ä»¶: {final_merged_file}")
                    
                    if os.path.exists(final_merged_file):
                        logger.info(f"âœ… æ‰¾åˆ°åˆå¹¶åçš„æ–‡ä»¶: {final_merged_file}")
                        return str(final_merged_file)
                
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åˆå¹¶åçš„æ–‡ä»¶ï¼ŒåŸºç¡€åç§°: {base_name}")
            else:
                # ä¸æ˜¯ä¸­é—´æ–‡ä»¶ï¼Œç›´æ¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨
                if os.path.exists(final_file_path):
                    logger.info(f"âœ… ä½¿ç”¨progress_hookè®°å½•çš„æ–‡ä»¶è·¯å¾„: {final_file_path}")
                    return final_file_path
                else:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºä¸­é—´æ–‡ä»¶ï¼ˆåŒ…å«æ ¼å¼ä»£ç çš„æ–‡ä»¶ï¼‰
                    original_path = Path(final_file_path)
                    filename = original_path.name

                    # æ£€æŸ¥æ˜¯å¦ä¸ºDASHä¸­é—´æ–‡ä»¶
                    is_dash_intermediate = (
                        '.fdash-' in filename or
                        '.f' in filename and filename.count('.') >= 2 or
                        'dash-' in filename
                    )

                    if is_dash_intermediate:
                        logger.info(f"ğŸ” æ£€æµ‹åˆ°DASHä¸­é—´æ–‡ä»¶ï¼Œå°è¯•æŸ¥æ‰¾åˆå¹¶åçš„æ–‡ä»¶: {filename}")
                        # å°è¯•æŸ¥æ‰¾åˆå¹¶åçš„æ–‡ä»¶
                        base_name = filename.split('.f')[0] if '.f' in filename else filename.split('.')[0]
                        ext = '.mp4'  # åˆå¹¶åé€šå¸¸æ˜¯mp4æ ¼å¼
                        final_merged_file = original_path.parent / f"{base_name}{ext}"

                        if os.path.exists(final_merged_file):
                            logger.info(f"âœ… æ‰¾åˆ°DASHåˆå¹¶åçš„æ–‡ä»¶: {final_merged_file}")
                            return str(final_merged_file)
                        else:
                            logger.info(f"ğŸ” DASHåˆå¹¶æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨å…¶ä»–æ–¹æ³•æŸ¥æ‰¾: {final_merged_file}")
                    else:
                        logger.warning(f"âš ï¸ progress_hookè®°å½•çš„æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨: {final_file_path}")

        # 2. åŸºäºé¢„æœŸæ–‡ä»¶åæŸ¥æ‰¾
        if expected_title:
            logger.info(f"ğŸ” åŸºäºé¢„æœŸæ–‡ä»¶åæŸ¥æ‰¾: {expected_title}")
            # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶åæ¸…ç†æ–¹æ³•
            safe_title = self._sanitize_filename(expected_title)
            if safe_title:
                # å°è¯•ä¸åŒçš„æ‰©å±•å
                possible_extensions = [".mp4", ".mkv", ".webm", ".avi", ".mov"]
                for ext in possible_extensions:
                    expected_file = download_path / f"{safe_title}{ext}"
                    logger.info(f"ğŸ” å°è¯•æŸ¥æ‰¾æ–‡ä»¶: {expected_file}")
                    if os.path.exists(expected_file):
                        logger.info(f"âœ… æ‰¾åˆ°åŸºäºæ ‡é¢˜çš„æ–‡ä»¶: {expected_file}")
                        return str(expected_file)
                
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŸºäºæ ‡é¢˜çš„æ–‡ä»¶: {safe_title}")

        # 3. åŸºäºå¹³å°ç‰¹å®šé€»è¾‘æŸ¥æ‰¾
        if url:
            logger.info(f"ğŸ” åŸºäºå¹³å°ç‰¹å®šé€»è¾‘æŸ¥æ‰¾: {url}")
            try:
                if self.is_x_url(url):
                    # Xå¹³å°ï¼šåŸºäºè§†é¢‘æ ‡é¢˜æŸ¥æ‰¾
                    logger.info("ğŸ” Xå¹³å°ï¼šå°è¯•è·å–è§†é¢‘æ ‡é¢˜å¹¶æŸ¥æ‰¾")
                    info_opts = {
                        "quiet": True,
                        "no_warnings": True,
                        "socket_timeout": 15,
                        "retries": 2,
                    }
                    if self.x_cookies_path and os.path.exists(self.x_cookies_path):
                        info_opts["cookiefile"] = self.x_cookies_path
                    
                    with yt_dlp.YoutubeDL(info_opts) as ydl:
                        info = ydl.extract_info(url, download=False)
                        if info and info.get('title'):
                            title = info.get('title')
                            safe_title = self._sanitize_filename(title)
                            if safe_title:
                                logger.info(f"ğŸ” Xå¹³å°æ ‡é¢˜: {safe_title}")
                                # å°è¯•ä¸åŒçš„æ‰©å±•å
                                possible_extensions = [".mp4", ".mkv", ".webm", ".avi", ".mov"]
                                for ext in possible_extensions:
                                    expected_file = download_path / f"{safe_title}{ext}"
                                    logger.info(f"ğŸ” å°è¯•æŸ¥æ‰¾Xå¹³å°æ–‡ä»¶: {expected_file}")
                                    if os.path.exists(expected_file):
                                        logger.info(f"âœ… æ‰¾åˆ°Xå¹³å°æ–‡ä»¶: {expected_file}")
                                        return str(expected_file)
                                
                                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°Xå¹³å°æ–‡ä»¶ï¼Œæ ‡é¢˜: {safe_title}")
                            else:
                                logger.warning("âš ï¸ Xå¹³å°æ ‡é¢˜ä¸ºç©ºæˆ–æ— æ•ˆ")
                        else:
                            logger.warning("âš ï¸ æ— æ³•è·å–Xå¹³å°è§†é¢‘æ ‡é¢˜")
                else:
                    # å…¶ä»–å¹³å°ï¼šåŸºäºæ ‡é¢˜æŸ¥æ‰¾ï¼ˆå¦‚æœè¿˜æ²¡æœ‰å°è¯•è¿‡ï¼‰
                    if not expected_title:
                        logger.info("ğŸ” å…¶ä»–å¹³å°ï¼šå°è¯•è·å–è§†é¢‘æ ‡é¢˜å¹¶æŸ¥æ‰¾")
                        info_opts = {
                            "quiet": True,
                            "no_warnings": True,
                            "socket_timeout": 15,
                            "retries": 2,
                        }
                        if self.youtube_cookies_path and os.path.exists(self.youtube_cookies_path):
                            info_opts["cookiefile"] = self.youtube_cookies_path
                        if self.douyin_cookies_path and os.path.exists(self.douyin_cookies_path):
                            info_opts["cookiefile"] = self.douyin_cookies_path
                        
                        with yt_dlp.YoutubeDL(info_opts) as ydl:
                            info = ydl.extract_info(url, download=False)
                            if info and info.get('title'):
                                title = info.get('title')
                                safe_title = self._sanitize_filename(title)
                                if safe_title:
                                    logger.info(f"ğŸ” å…¶ä»–å¹³å°æ ‡é¢˜: {safe_title}")
                                    # å°è¯•ä¸åŒçš„æ‰©å±•å
                                    possible_extensions = [".mp4", ".mkv", ".webm", ".avi", ".mov"]
                                    for ext in possible_extensions:
                                        expected_file = download_path / f"{safe_title}{ext}"
                                        logger.info(f"ğŸ” å°è¯•æŸ¥æ‰¾å…¶ä»–å¹³å°æ–‡ä»¶: {expected_file}")
                                        if os.path.exists(expected_file):
                                            logger.info(f"âœ… æ‰¾åˆ°å…¶ä»–å¹³å°æ–‡ä»¶: {expected_file}")
                                            return str(expected_file)
                                    
                                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°å…¶ä»–å¹³å°æ–‡ä»¶ï¼Œæ ‡é¢˜: {safe_title}")
            except Exception as e:
                logger.warning(f"âš ï¸ å¹³å°ç‰¹å®šæŸ¥æ‰¾å¤±è´¥: {e}")

        # 4. å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›None
        logger.error("âŒ æ— æ³•æ‰¾åˆ°é¢„æœŸçš„ä¸‹è½½æ–‡ä»¶")
        return None

    async def _download_with_ytdlp_unified(
        self, 
        url: str, 
        download_path: Path, 
        message_updater=None, 
        platform_name: str = "Unknown",
        content_type: str = "video",
        format_spec: str = "best[height<=1080]",
        cookies_path: str = None
    ) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„ yt-dlp ä¸‹è½½å‡½æ•°
        
        Args:
            url: ä¸‹è½½URL
            download_path: ä¸‹è½½ç›®å½•
            message_updater: æ¶ˆæ¯æ›´æ–°å™¨
            platform_name: å¹³å°åç§°
            content_type: å†…å®¹ç±»å‹ (video/image)
            format_spec: æ ¼å¼è§„æ ¼
            cookies_path: cookiesæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, Any]: ä¸‹è½½ç»“æœ
        """
        try:
            import yt_dlp
            
            # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
            os.makedirs(download_path, exist_ok=True)
            
            # é…ç½® yt-dlp
            ydl_opts = {
                'format': format_spec,
                'outtmpl': os.path.join(str(download_path), '%(title).50s.%(ext)s'),
                'verbose': False,
                'no_warnings': True,
                'extract_flat': False,
                'ignoreerrors': False,
                'no_check_certificate': True,
                'http_headers': {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                }
            }
            
            # æ·»åŠ  cookies æ”¯æŒ
            if cookies_path and os.path.exists(cookies_path):
                ydl_opts["cookiefile"] = cookies_path
                logger.info(f"ğŸª ä½¿ç”¨cookies: {cookies_path}")
            
            # è¿›åº¦æ•°æ®å­˜å‚¨
            progress_data = {"final_filename": None, "lock": threading.Lock()}
            
            # ä½¿ç”¨ç»Ÿä¸€çš„å•é›†ä¸‹è½½è¿›åº¦å›è°ƒ
            # æ£€æŸ¥ message_updater æ˜¯å¦æ˜¯å¢å¼ºç‰ˆè¿›åº¦å›è°ƒå‡½æ•°
            if callable(message_updater) and message_updater.__name__ == 'enhanced_progress_callback':
                # å¦‚æœæ˜¯å¢å¼ºç‰ˆè¿›åº¦å›è°ƒï¼Œç›´æ¥ä½¿ç”¨å®ƒè¿”å›çš„ progress_hook
                progress_hook = message_updater(progress_data)
            else:
                # å¦åˆ™ä½¿ç”¨æ ‡å‡†çš„ single_video_progress_hook
                progress_hook = single_video_progress_hook(message_updater, progress_data)
            
            ydl_opts["progress_hooks"] = [progress_hook]
            
            # å¼€å§‹ä¸‹è½½
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                logger.info(f"ğŸ¬ yt-dlp å¼€å§‹ä¸‹è½½ {platform_name} {content_type}...")
                info = ydl.extract_info(url, download=True)
                
                if not info:
                    raise Exception(f"yt-dlp æœªè·å–åˆ°{content_type}ä¿¡æ¯")
                
                # æ£€æŸ¥infoçš„ç±»å‹ï¼Œç¡®ä¿å®ƒæ˜¯å­—å…¸
                if not isinstance(info, dict):
                    logger.error(f"âŒ yt-dlp è¿”å›äº†éå­—å…¸ç±»å‹çš„ç»“æœ: {type(info)}, å†…å®¹: {info}")
                    raise Exception(f"yt-dlp è¿”å›äº†æ„å¤–çš„æ•°æ®ç±»å‹: {type(info)}")
                
                # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
                filename = ydl.prepare_filename(info)
                logger.info(f"ğŸ” yt-dlp å‡†å¤‡çš„æ–‡ä»¶å: {filename}")
                
                if not os.path.exists(filename):
                    logger.info(f"âš ï¸ å‡†å¤‡çš„æ–‡ä»¶åä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾å®é™…ä¸‹è½½çš„æ–‡ä»¶...")
                    # å°è¯•æŸ¥æ‰¾å®é™…ä¸‹è½½çš„æ–‡ä»¶
                    download_path_found = self.single_video_find_downloaded_file(
                        download_path, 
                        progress_data, 
                        info.get('title', ''), 
                        url
                    )
                    if download_path_found:
                        filename = download_path_found
                        logger.info(f"âœ… æ‰¾åˆ°å®é™…ä¸‹è½½çš„æ–‡ä»¶: {filename}")
                    else:
                        raise Exception(f"æœªæ‰¾åˆ°ä¸‹è½½çš„{content_type}æ–‡ä»¶")
                else:
                    logger.info(f"âœ… ä½¿ç”¨yt-dlpå‡†å¤‡çš„æ–‡ä»¶å: {filename}")
                
                # é‡å‘½åæ–‡ä»¶ä»¥ä½¿ç”¨æ¸…ç†è¿‡çš„æ–‡ä»¶å
                try:
                    original_filename = filename
                    file_dir = os.path.dirname(filename)
                    file_ext = os.path.splitext(filename)[1]
                    
                    # è·å–åŸå§‹æ ‡é¢˜å¹¶æ¸…ç†
                    original_title = info.get('title', f'{platform_name}_{content_type}')
                    clean_title = self._sanitize_filename(original_title)
                    
                    # æ„å»ºæ–°çš„æ–‡ä»¶å
                    new_filename = os.path.join(file_dir, f"{clean_title}{file_ext}")
                    
                    # å¦‚æœæ–°æ–‡ä»¶åä¸æ—§æ–‡ä»¶åä¸åŒï¼Œåˆ™é‡å‘½å
                    if new_filename != original_filename:
                        # å¦‚æœæ–°æ–‡ä»¶åå·²å­˜åœ¨ï¼Œæ·»åŠ æ•°å­—åç¼€
                        counter = 1
                        final_filename = new_filename
                        while os.path.exists(final_filename):
                            name_without_ext = os.path.splitext(new_filename)[0]
                            final_filename = f"{name_without_ext}_{counter}{file_ext}"
                            counter += 1
                        
                        # é‡å‘½åæ–‡ä»¶
                        os.rename(original_filename, final_filename)
                        filename = final_filename
                        logger.info(f"âœ… æ–‡ä»¶å·²é‡å‘½åä¸º: {os.path.basename(filename)}")
                    else:
                        logger.info(f"âœ… æ–‡ä»¶åæ— éœ€é‡å‘½å")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ é‡å‘½åæ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶å: {e}")
                    # ç»§ç»­ä½¿ç”¨åŸå§‹æ–‡ä»¶å
                
                # è·å–æ–‡ä»¶ä¿¡æ¯
                file_size = os.path.getsize(filename)
                size_mb = file_size / 1024 / 1024
                
                logger.info(f"âœ… {platform_name} {content_type}ä¸‹è½½æˆåŠŸ: {filename} ({size_mb:.1f} MB)")
                
                # æ„å»ºè¿”å›ç»“æœ
                result = {
                    "success": True,
                    "platform": platform_name,
                    "content_type": content_type,
                    "download_path": filename,
                    "full_path": filename,
                    "size_mb": size_mb,
                    "title": info.get('title', f'{platform_name}{content_type}'),
                    "uploader": info.get('uploader', f'{platform_name}ç”¨æˆ·'),
                    "filename": os.path.basename(filename),
                }
                
                # æ ¹æ®å†…å®¹ç±»å‹æ·»åŠ ç‰¹å®šä¿¡æ¯
                if content_type == "video":
                    # è§†é¢‘ç‰¹æœ‰ä¿¡æ¯
                    duration = info.get('duration', 0)
                    width = info.get('width', 0)
                    height = info.get('height', 0)
                    resolution = f"{width}x{height}" if width and height else "æœªçŸ¥"
                    
                    # æ ¼å¼åŒ–æ—¶é•¿
                    if duration:
                        minutes, seconds = divmod(int(duration), 60)
                        hours, minutes = divmod(minutes, 60)
                        if hours > 0:
                            duration_str = f"{hours}:{minutes:02d}:{seconds:02d}"
                        else:
                            duration_str = f"{minutes}:{seconds:02d}"
                    else:
                        duration_str = "æœªçŸ¥"
                    
                    result.update({
                        "duration": duration,
                        "duration_str": duration_str,
                        "resolution": resolution,
                        "width": width,
                        "height": height,
                    })
                else:
                    # å›¾ç‰‡ç‰¹æœ‰ä¿¡æ¯
                    width = info.get('width', 0)
                    height = info.get('height', 0)
                    resolution = f"{width}x{height}" if width and height else "æœªçŸ¥"
                    
                    result.update({
                        "resolution": resolution,
                        "width": width,
                        "height": height,
                    })
                
                return result
                
        except Exception as e:
            logger.error(f"âŒ yt-dlp ä¸‹è½½ {platform_name} {content_type}å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"yt-dlp ä¸‹è½½å¤±è´¥: {str(e)}",
                "platform": platform_name,
                "content_type": content_type
            }

    def cleanup_duplicates(self):
        """æ¸…ç†é‡å¤æ–‡ä»¶"""
        try:
            cleaned_count = 0
            for directory in [self.x_download_path, self.youtube_download_path]:
                if directory.exists():
                    for file in directory.glob("*"):
                        if file.is_file() and " #" in file.name:
                            # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶
                            if any(
                                file.name.endswith(ext)
                                for ext in [".mp4", ".mkv", ".webm", ".mov", ".avi"]
                            ):
                                try:
                                    file.unlink()
                                    logger.info(f"åˆ é™¤é‡å¤æ–‡ä»¶: {file.name}")
                                    cleaned_count += 1
                                except Exception as e:
                                    logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
            return cleaned_count
        except Exception as e:
            logger.error(f"æ¸…ç†é‡å¤æ–‡ä»¶å¤±è´¥: {e}")
            return 0

    def _generate_display_filename(self, original_filename, timestamp):
        """ç”Ÿæˆç”¨æˆ·å‹å¥½çš„æ˜¾ç¤ºæ–‡ä»¶å"""
        try:
            # ç§»é™¤æ—¶é—´æˆ³å‰ç¼€
            if original_filename.startswith(f"{timestamp}_"):
                display_name = original_filename[len(f"{timestamp}_") :]
            else:
                display_name = original_filename
            # å¦‚æœæ–‡ä»¶åå¤ªé•¿ï¼Œæˆªæ–­å®ƒ
            if len(display_name) > 35:
                name, ext = os.path.splitext(display_name)
                display_name = name[:30] + "..." + ext
            return display_name
        except BaseException:
            return original_filename

    def _detect_x_content_type(self, url: str) -> str:
        """æ£€æµ‹ X é“¾æ¥çš„å†…å®¹ç±»å‹ï¼ˆå›¾ç‰‡/è§†é¢‘ï¼‰"""
        logger.info(f"ğŸ” å¼€å§‹æ£€æµ‹ X å†…å®¹ç±»å‹: {url}")
        
        # æ–¹æ³•1: ä½¿ç”¨ yt-dlp æ£€æµ‹ï¼ˆæœ€å‡†ç¡®ï¼‰
        content_type = self._detect_with_ytdlp(url)
        if content_type:
            return content_type
        
        # æ–¹æ³•2: ä½¿ç”¨ curl æ£€æµ‹ï¼ˆå¤‡ç”¨ï¼‰
        content_type = self._detect_with_curl(url)
        if content_type:
            return content_type
        
        # æ–¹æ³•3: é»˜è®¤å¤„ç† - å½“æˆè§†é¢‘ç”¨ yt-dlp ä¸‹è½½
        logger.info("ğŸ¬ æ£€æµ‹å¤±è´¥ï¼Œé»˜è®¤ä¸ºè§†é¢‘ç±»å‹ï¼Œä½¿ç”¨ yt-dlp ä¸‹è½½")
        return "video"

    def _detect_with_ytdlp(self, url: str) -> str:
        """ä½¿ç”¨ yt-dlp æ£€æµ‹å†…å®¹ç±»å‹"""
        try:
            import yt_dlp
            
            # é…ç½® yt-dlp é€‰é¡¹
            ydl_opts = {
                "quiet": True,
                "no_warnings": True,
                "extract_flat": False,  # ä¸ä½¿ç”¨ flat æ¨¡å¼ï¼Œè·å–å®Œæ•´ä¿¡æ¯
                "skip_download": True,  # ä¸ä¸‹è½½ï¼Œåªè·å–ä¿¡æ¯
                "socket_timeout": 15,   # 15ç§’è¶…æ—¶
                "retries": 2,           # å‡å°‘é‡è¯•æ¬¡æ•°
            }
            
            # æ·»åŠ  cookies æ”¯æŒ
            if self.x_cookies_path and os.path.exists(self.x_cookies_path):
                ydl_opts["cookiefile"] = self.x_cookies_path
                logger.info(f"ğŸª yt-dlp ä½¿ç”¨X cookies: {self.x_cookies_path}")
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                logger.info("ğŸ” yt-dlp å¼€å§‹æå–ä¿¡æ¯...")
                info = ydl.extract_info(url, download=False)
                
                if not info:
                    logger.warning("âš ï¸ yt-dlp æœªè·å–åˆ°ä¿¡æ¯")
                    return None
                
                # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æœ‰è§†é¢‘æ ¼å¼ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
                formats = info.get('formats', [])
                if formats:
                    # æŸ¥æ‰¾æœ‰è§†é¢‘ç¼–ç çš„æ ¼å¼
                    video_formats = [f for f in formats if f.get('vcodec') and f.get('vcodec') != 'none']
                    if video_formats:
                        logger.info(f"ğŸ¬ yt-dlp æ£€æµ‹åˆ°è§†é¢‘å†…å®¹ï¼Œæ‰¾åˆ° {len(video_formats)} ä¸ªè§†é¢‘æ ¼å¼")
                        return "video"
                
                # æ£€æŸ¥å…¶ä»–è§†é¢‘æŒ‡æ ‡
                if info.get('duration') and info.get('duration') > 0:
                    logger.info(f"ğŸ¬ yt-dlp é€šè¿‡æ—¶é•¿æ£€æµ‹åˆ°è§†é¢‘å†…å®¹: {info.get('duration')}ç§’")
                    return "video"
                
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åï¼ˆè§†é¢‘ä¼˜å…ˆï¼‰
                filename = info.get('filename', '')
                if any(ext in filename.lower() for ext in ['.mp4', '.webm', '.mov', '.avi']):
                    logger.info(f"ğŸ¬ yt-dlp é€šè¿‡æ–‡ä»¶åæ£€æµ‹åˆ°è§†é¢‘å†…å®¹: {filename}")
                    return "video"
                
                # æœ€åæ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ä¿¡æ¯
                thumbnails = info.get('thumbnails', [])
                if thumbnails:
                    logger.info(f"ğŸ“¸ yt-dlp æ£€æµ‹åˆ°å›¾ç‰‡å†…å®¹ï¼Œæ‰¾åˆ° {len(thumbnails)} ä¸ªç¼©ç•¥å›¾")
                    return "image"
                
                # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ‰©å±•å
                if any(ext in filename.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
                    logger.info(f"ğŸ“¸ yt-dlp é€šè¿‡æ–‡ä»¶åæ£€æµ‹åˆ°å›¾ç‰‡å†…å®¹: {filename}")
                    return "image"
                
                logger.info("ğŸ¬ yt-dlp æœªæ£€æµ‹åˆ°æ˜ç¡®å†…å®¹ç±»å‹ï¼Œé»˜è®¤ä¸ºè§†é¢‘ç±»å‹")
                return "video"
                
        except Exception as e:
            logger.warning(f"âš ï¸ yt-dlp æ£€æµ‹å¤±è´¥: {e}")
        return None

    def _detect_with_curl(self, url: str) -> str:
        """ä½¿ç”¨ curl æ£€æµ‹å†…å®¹ç±»å‹ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        try:
            import subprocess
            import re
            import gzip
            
            # æ„å»º curl å‘½ä»¤
            curl_cmd = [
                "curl", "-s", "-L", "-k",  # é™é»˜æ¨¡å¼ï¼Œè·Ÿéšé‡å®šå‘ï¼Œç¦ç”¨SSLéªŒè¯
                "-H", "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "-H", "Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "-H", "Accept-Language: en-US,en;q=0.5",
                "-H", "Accept-Encoding: gzip, deflate, br",
                "-H", "DNT: 1",
                "-H", "Connection: keep-alive",
                "-H", "Upgrade-Insecure-Requests: 1",
                "--max-time", "10",  # 10ç§’è¶…æ—¶
            ]
            
            # å¦‚æœæœ‰ cookiesï¼Œæ·»åŠ  cookies æ–‡ä»¶
            if self.x_cookies_path and os.path.exists(self.x_cookies_path):
                curl_cmd.extend(["-b", self.x_cookies_path])
                logger.info(f"ğŸª curl ä½¿ç”¨X cookies: {self.x_cookies_path}")
            
            curl_cmd.append(url)
            
            # æ‰§è¡Œ curl å‘½ä»¤
            logger.info("ğŸ” curl å¼€å§‹æ£€æµ‹å†…å®¹ç±»å‹...")
            result = subprocess.run(curl_cmd, capture_output=True, timeout=15)
            
            if result.returncode != 0:
                logger.warning(f"âš ï¸ curl è¯·æ±‚å¤±è´¥: {result.stderr}")
                return None
            
            # å¤„ç†å“åº”å†…å®¹
            try:
                html_content = result.stdout.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    html_content = gzip.decompress(result.stdout).decode('utf-8')
                except Exception:
                    html_content = result.stdout.decode('utf-8', errors='ignore')
            
            # æ£€æµ‹è§†é¢‘ç›¸å…³çš„ HTML å…ƒç´ 
            video_patterns = [
                r'<video[^>]*>',
                r'data-testid="videoPlayer"',
                r'data-testid="video"',
                r'aria-label="[^"]*video[^"]*"',
                r'class="[^"]*video[^"]*"',
            ]
            
            # æ£€æµ‹å›¾ç‰‡ç›¸å…³çš„ HTML å…ƒç´ 
            image_patterns = [
                r'<img[^>]*>',
                r'data-testid="tweetPhoto"',
                r'data-testid="image"',
                r'aria-label="[^"]*image[^"]*"',
                r'class="[^"]*image[^"]*"',
            ]
            
            # æ£€æŸ¥è§†é¢‘æ¨¡å¼
            for pattern in video_patterns:
                if re.search(pattern, html_content, re.IGNORECASE):
                    logger.info(f"ğŸ¬ curl æ£€æµ‹åˆ°è§†é¢‘å†…å®¹ (æ¨¡å¼: {pattern})")
                    return "video"
            
            # æ£€æŸ¥å›¾ç‰‡æ¨¡å¼
            for pattern in image_patterns:
                if re.search(pattern, html_content, re.IGNORECASE):
                    logger.info(f"ğŸ“¸ curl æ£€æµ‹åˆ°å›¾ç‰‡å†…å®¹ (æ¨¡å¼: {pattern})")
                    return "image"
            
            # æ–‡æœ¬æ£€æµ‹
            if re.search(r'video|mp4|webm|mov', html_content, re.IGNORECASE):
                logger.info("ğŸ¬ curl é€šè¿‡æ–‡æœ¬æ£€æµ‹åˆ°è§†é¢‘å†…å®¹")
                return "video"
            
            if re.search(r'image|photo|jpg|jpeg|png|gif|webp', html_content, re.IGNORECASE):
                logger.info("ğŸ“¸ curl é€šè¿‡æ–‡æœ¬æ£€æµ‹åˆ°å›¾ç‰‡å†…å®¹")
                return "image"
            
            logger.info("ğŸ“¸ curl æœªæ£€æµ‹åˆ°æ˜ç¡®å†…å®¹ç±»å‹")
            return None
                
        except subprocess.TimeoutExpired:
            logger.warning("âš ï¸ curl è¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ curl æ£€æµ‹å¤±è´¥: {e}")
            return None

    async def download_video(
        self, url: str, message_updater=None, auto_playlist=False, status_message=None, loop=None
    ) -> Dict[str, Any]:
        # è‡ªåŠ¨ä¿®æ­£å°çº¢ä¹¦çŸ­é“¾åè®®
        if url.startswith("tp://"):
            logger.info("æ£€æµ‹åˆ° tp:// åè®®ï¼Œè‡ªåŠ¨ä¿®æ­£ä¸º http://")
            url = "http://" + url[5:]
        elif url.startswith("tps://"):
            logger.info("æ£€æµ‹åˆ° tps:// åè®®ï¼Œè‡ªåŠ¨ä¿®æ­£ä¸º https://")
            url = "https://" + url[6:]

        # è‡ªåŠ¨å±•å¼€å¾®åšçŸ­é“¾æ¥
        if self.is_weibo_url(url):
            logger.info(f"ğŸ” æ£€æµ‹åˆ°å¾®åšURLï¼Œå¼€å§‹å±•å¼€çŸ­é“¾æ¥: {url}")
            expanded_url = self._expand_weibo_short_url(url)
            if expanded_url != url:
                logger.info(f"ğŸ”„ çŸ­é“¾æ¥å±•å¼€æˆåŠŸ: {url} -> {expanded_url}")
                url = expanded_url
                logger.info(f"ğŸ”„ ä½¿ç”¨å±•å¼€åçš„å¾®åšé“¾æ¥: {url}")
            else:
                logger.info(f"â„¹ï¸ URLæ— éœ€å±•å¼€æˆ–å±•å¼€å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸURL: {url}")
        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
        logger.info(f"ğŸ” download_video å¼€å§‹å¤„ç†URL: {url}")
        logger.info(f"ğŸ” è‡ªåŠ¨ä¸‹è½½å…¨é›†æ¨¡å¼: {'å¼€å¯' if auto_playlist else 'å…³é—­'}")
        # æ£€æŸ¥URLç±»å‹
        is_bilibili = self.is_bilibili_url(url)
        is_list, uid, list_id = self.is_bilibili_list_url(url)
        is_multi_part, bv_id = self.is_bilibili_multi_part_video(url)
        is_youtube_playlist, playlist_id = self.is_youtube_playlist_url(url)
        is_youtube_channel, channel_url = self.is_youtube_channel_playlists_url(url)
        is_x = self.is_x_url(url)
        is_telegraph = self.is_telegraph_url(url)
        is_douyin = self.is_douyin_url(url)
        is_kuaishou = self.is_kuaishou_url(url)
        is_facebook = self.is_facebook_url(url)
        platform = self.get_platform_name(url)
        logger.info(f"ğŸ” URLè¯†åˆ«ç»“æœ:")
        logger.info(f"  - is_bilibili_url: {is_bilibili}")
        logger.info(
            f"  - is_bilibili_list_url: {is_list}, uid: {uid}, list_id: {list_id}"
        )
        logger.info(
            f"  - is_bilibili_multi_part: {is_multi_part}, bv_id: {bv_id}"
        )
        logger.info(
            f"  - is_youtube_playlist: {is_youtube_playlist}, playlist_id: {playlist_id}"
        )
        logger.info(f"  - is_youtube_channel: {is_youtube_channel}, channel_url: {channel_url if is_youtube_channel else 'None'}")
        logger.info(f"  - is_x_url: {is_x}")
        logger.info(f"  - is_telegraph_url: {is_telegraph}")
        logger.info(f"  - platform: {platform}")
        download_path = self.get_download_path(url)
        logger.info(f"ğŸ“ è·å–åˆ°çš„ä¸‹è½½è·¯å¾„: {download_path}")
        
        # å¤„ç† X é“¾æ¥ - å¤šé›†æ£€æµ‹ä¼˜å…ˆ
        if is_x:
            is_x_playlist, playlist_info = self.is_x_playlist_url(url)
            if is_x_playlist:
                logger.info(f"ğŸ¬ æ£€æµ‹åˆ°Xå¤šé›†è§†é¢‘ï¼Œå…±{playlist_info['total_videos']}ä¸ªè§†é¢‘")
                return await self._download_x_playlist(url, download_path, message_updater, playlist_info)
            logger.info("ğŸ” æ£€æµ‹åˆ°Xé“¾æ¥ï¼Œå¼€å§‹æ£€æµ‹å†…å®¹ç±»å‹...")
            # æ£€æµ‹å†…å®¹ç±»å‹
            content_type = self._detect_x_content_type(url)
            logger.info(f"ğŸ“Š æ£€æµ‹åˆ°å†…å®¹ç±»å‹: {content_type}")
            if content_type == "video":
                # è§†é¢‘ä½¿ç”¨ç»Ÿä¸€çš„å•è§†é¢‘ä¸‹è½½å‡½æ•°
                logger.info("ğŸ¬ X è§†é¢‘ä½¿ç”¨ç»Ÿä¸€çš„å•è§†é¢‘ä¸‹è½½å‡½æ•°")
                return await self._download_single_video(url, download_path, message_updater)
            else:
                # å›¾ç‰‡ä½¿ç”¨ gallery-dl ä¸‹è½½
                logger.info("ğŸ“¸ X å›¾ç‰‡ä½¿ç”¨ gallery-dl ä¸‹è½½")
                return await self.download_with_gallery_dl(url, download_path, message_updater)
        # å¤„ç† Telegraph é“¾æ¥ï¼ˆä½¿ç”¨ gallery-dlï¼‰
        if is_telegraph:
            logger.info(f"ğŸ“¸ æ£€æµ‹åˆ°Telegraphé“¾æ¥ï¼Œä½¿ç”¨ gallery-dl ä¸‹è½½")
            return await self.download_with_gallery_dl(url, download_path, message_updater)

        # å¤„ç†æŠ–éŸ³é“¾æ¥ - ä½¿ç”¨Playwrightæ–¹æ³•
        if is_douyin:
            logger.info("ğŸ¬ æ£€æµ‹åˆ°æŠ–éŸ³é“¾æ¥ï¼Œä½¿ç”¨Playwrightæ–¹æ³•ä¸‹è½½")
            # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„messageå¯¹è±¡ç”¨äºPlaywrightæ–¹æ³•
            class MockMessage:
                def __init__(self, chat_id=0):
                    self.chat_id = chat_id
                    self.message_id = 0

            mock_message = MockMessage()
            return await self._download_douyin_with_playwright(url, mock_message, message_updater)

        # å¤„ç†å¿«æ‰‹é“¾æ¥ - ä½¿ç”¨Playwrightæ–¹æ³•
        if is_kuaishou:
            logger.info("âš¡ æ£€æµ‹åˆ°å¿«æ‰‹é“¾æ¥ï¼Œä½¿ç”¨Playwrightæ–¹æ³•ä¸‹è½½")
            # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„messageå¯¹è±¡ç”¨äºPlaywrightæ–¹æ³•
            class MockMessage:
                def __init__(self, chat_id=0):
                    self.chat_id = chat_id
                    self.message_id = 0

            mock_message = MockMessage()
            return await self._download_kuaishou_with_playwright(url, mock_message, message_updater)

        # å¤„ç†Facebooké“¾æ¥ - ä½¿ç”¨yt-dlpæ–¹æ³•ï¼ˆå‚è€ƒYouTubeå•é›†ä¸‹è½½ï¼‰
        if self.is_facebook_url(url):
            logger.info("ğŸ“˜ æ£€æµ‹åˆ°Facebooké“¾æ¥ï¼Œä½¿ç”¨yt-dlpæ–¹æ³•ä¸‹è½½")
            return await self._download_single_video(url, download_path, message_updater)

        # å¤„ç†å°çº¢ä¹¦é“¾æ¥ - ä½¿ç”¨Playwrightæ–¹æ³•
        if self.is_xiaohongshu_url(url):
            logger.info("ğŸ“– æ£€æµ‹åˆ°å°çº¢ä¹¦é“¾æ¥ï¼Œä½¿ç”¨Playwrightæ–¹æ³•ä¸‹è½½")
            # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„messageå¯¹è±¡ç”¨äºPlaywrightæ–¹æ³•
            class MockMessage:
                def __init__(self, chat_id=0):
                    self.chat_id = chat_id
                    self.message_id = 0

            mock_message = MockMessage()
            return await self._download_xiaohongshu_with_playwright(url, mock_message, message_updater)

        # å¤„ç† YouTube é¢‘é“æ’­æ”¾åˆ—è¡¨
        if is_youtube_channel:
            logger.info("âœ… æ£€æµ‹åˆ°YouTubeé¢‘é“æ’­æ”¾åˆ—è¡¨ï¼Œå¼€å§‹ä¸‹è½½æ‰€æœ‰æ’­æ”¾åˆ—è¡¨")
            # message_updaterå‚æ•°å·²æ­£ç¡®ä¼ é€’
            return await self._download_youtube_channel_playlists(
                channel_url, download_path, message_updater, status_message, loop
            )
        # å¤„ç† YouTube æ’­æ”¾åˆ—è¡¨
        if is_youtube_playlist:
            logger.info(f"âœ… æ£€æµ‹åˆ°YouTubeæ’­æ”¾åˆ—è¡¨ï¼Œæ’­æ”¾åˆ—è¡¨ID: {playlist_id}")
            return await self._download_youtube_playlist_with_progress(
                playlist_id, download_path, message_updater
            )
        # å¦‚æœæ˜¯Bç«™é“¾æ¥ï¼Œæ ¹æ®è®¾ç½®é€‰æ‹©ä¸‹è½½å™¨
        if self.is_bilibili_url(url):
            # ä¼˜å…ˆæ£€æŸ¥ï¼šå¦‚æœæ˜ç¡®æ£€æµ‹åˆ°æ˜¯å•é›†è§†é¢‘ï¼Œç›´æ¥ä½¿ç”¨é€šç”¨ä¸‹è½½å™¨
            if not is_multi_part and not is_list:
                logger.info("âœ… æ£€æµ‹åˆ°Bç«™å•é›†è§†é¢‘ï¼Œç›´æ¥ä½¿ç”¨é€šç”¨ä¸‹è½½å™¨")
                return await self._download_single_video(url, download_path, message_updater)

            # å¦‚æœæ£€æµ‹åˆ°å¤šPæˆ–åˆé›†ï¼Œä¸”å¼€å¯äº†è‡ªåŠ¨ä¸‹è½½å…¨é›†ï¼Œä½¿ç”¨ä¸“é—¨çš„Bç«™ä¸‹è½½å™¨
            elif auto_playlist and (is_multi_part or is_list):
                logger.info("âœ… æ£€æµ‹åˆ°Bç«™å¤šPè§†é¢‘æˆ–åˆé›†ï¼Œä¸”å¼€å¯å¤šPè‡ªåŠ¨ä¸‹è½½å…¨é›†ï¼Œä½¿ç”¨ä¸“é—¨çš„Bç«™ä¸‹è½½å™¨")
                return await self._download_bilibili_video(
                    url, download_path, message_updater, auto_playlist
                )

            # å…¶ä»–æƒ…å†µï¼ˆæ£€æµ‹åˆ°å¤šPä½†æœªå¼€å¯å¤šPè‡ªåŠ¨ä¸‹è½½å…¨é›†ï¼‰ä½¿ç”¨é€šç”¨ä¸‹è½½å™¨
            else:
                logger.info("âœ… æ£€æµ‹åˆ°Bç«™å¤šPè§†é¢‘æˆ–åˆé›†ï¼Œä½†æœªå¼€å¯å¤šPè‡ªåŠ¨ä¸‹è½½å…¨é›†ï¼Œä½¿ç”¨é€šç”¨ä¸‹è½½å™¨ä¸‹è½½å½“å‰é›†")
                return await self._download_single_video(url, download_path, message_updater)
        # å¤„ç†æ–°å¢çš„å¹³å°ï¼ˆå¾®åšã€Instagramã€TikTokï¼‰
        if self.is_weibo_url(url) or self.is_instagram_url(url) or self.is_tiktok_url(url):
            logger.info(f"âœ… æ£€æµ‹åˆ°{platform}è§†é¢‘ï¼Œä½¿ç”¨é€šç”¨ä¸‹è½½å™¨")
            return await self._download_single_video(url, download_path, message_updater)

        # å¤„ç†å•ä¸ªè§†é¢‘ï¼ˆåŒ…æ‹¬YouTubeå•ä¸ªè§†é¢‘ï¼‰
        logger.info(f"âœ… ä½¿ç”¨é€šç”¨ä¸‹è½½å™¨å¤„ç†å•ä¸ªè§†é¢‘ï¼Œå¹³å°: {platform}")
        return await self._download_single_video(url, download_path, message_updater)

    async def _download_bilibili_video(
        self, url: str, download_path: str, message_updater=None, auto_playlist=False
    ) -> Dict[str, Any]:
        """ä¸‹è½½Bç«™å¤šPè§†é¢‘æˆ–åˆé›†"""
        import os
        from pathlib import Path
        import time
        import re
        logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½Bç«™å¤šPè§†é¢‘æˆ–åˆé›†: {url}")

        # æ£€æŸ¥æ˜¯å¦ä¸ºBç«™ç”¨æˆ·è‡ªå®šä¹‰åˆ—è¡¨URL
        is_list, uid, list_id = self.is_bilibili_list_url(url)
        is_multi_part, bv_id = self.is_bilibili_multi_part_video(url)
        
        # è®°å½•ä¸‹è½½å¼€å§‹æ—¶é—´
        download_start_time = time.time()
        logger.info(f"â° ä¸‹è½½å¼€å§‹æ—¶é—´: {download_start_time}")
        
        logger.info(f"ğŸ” æ£€æµ‹ç»“æœ: åˆ—è¡¨={is_list}, å¤šP={is_multi_part}, BVå·={bv_id}")
        
        # ç®€åŒ–ï¼šä¸éœ€è¦è·Ÿè¸ªä¸‹è½½æ–‡ä»¶ï¼Œä½¿ç”¨ç›®å½•éå†

        # ç®€åŒ–æ–¹æ¡ˆï¼šç›´æ¥åˆ é™¤ç›®å½•éå†ï¼Œä½¿ç”¨ç°æœ‰çš„è¿›åº¦å›è°ƒæœºåˆ¶

        # é¢„å…ˆè·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼Œä»¥ä¾¿çŸ¥é“åº”è¯¥æœ‰å“ªäº›æ–‡ä»¶
        # ç®€åŒ–ï¼šä¸éœ€è¦é¢„å…ˆè·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼Œç›´æ¥ä¸‹è½½åç”¨ç›®å½•éå†

        def progress_callback(d):
            # ç®€åŒ–çš„è¿›åº¦å›è°ƒï¼Œåªå¤„ç†message_updaterï¼Œä¸è®°å½•æ–‡ä»¶
            if message_updater:
                try:
                    import asyncio
                    if asyncio.iscoroutinefunction(message_updater):
                        # å¦‚æœæ˜¯åç¨‹å‡½æ•°ï¼Œéœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
                        try:
                            loop = asyncio.get_running_loop()
                        except RuntimeError:
                            try:
                                loop = asyncio.get_event_loop()
                            except RuntimeError:
                                loop = asyncio.new_event_loop()
                                asyncio.set_event_loop(loop)
                        asyncio.run_coroutine_threadsafe(message_updater(d), loop)
                    else:
                        # åŒæ­¥å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
                        message_updater(d)
                except Exception as e:
                    logger.debug(f"ğŸ“ message_updaterè°ƒç”¨å¤±è´¥: {e}")

        try:
            loop = asyncio.get_running_loop()
            result = await loop.run_in_executor(
                None,
                self.smart_download_bilibili,
                url,
                str(download_path),
                progress_callback,
                auto_playlist,
            )

            # æ£€æŸ¥æ˜¯å¦ä¸ºå•è§†é¢‘ï¼Œå¦‚æœæ˜¯åˆ™å›é€€åˆ°é€šç”¨ä¸‹è½½å™¨
            if isinstance(result, dict) and result.get("status") == "single_video":
                logger.info("ğŸ”„ smart_download_bilibili æ£€æµ‹åˆ°å•è§†é¢‘ï¼Œå›é€€åˆ°é€šç”¨ä¸‹è½½å™¨")
                return await self._download_single_video(url, download_path, message_updater)

            if not result:
                return {'success': False, 'error': 'Bç«™ä¸‹è½½å¤±è´¥'}

            # æ£€æŸ¥æ˜¯å¦ä¸ºåŒ…å«å®Œæ•´æ–‡ä»¶ä¿¡æ¯çš„ç»“æœï¼ˆBVå·å¾ªç¯æ³•ï¼‰
            if isinstance(result, dict) and result.get("status") == "success" and "files" in result:
                logger.info("âœ… smart_download_bilibili è¿”å›äº†å®Œæ•´çš„æ–‡ä»¶ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨")
                return {
                    'success': True,
                    'is_playlist': result.get('is_playlist', True),
                    'file_count': result.get('file_count', 0),
                    'total_size_mb': result.get('total_size_mb', 0),
                    'files': result.get('files', []),
                    'platform': result.get('platform', 'bilibili'),
                    'download_path': result.get('download_path', str(download_path)),
                    'filename': result.get('filename', ''),
                    'size_mb': result.get('size_mb', 0),
                    'resolution': result.get('resolution', 'æœªçŸ¥'),
                    'episode_count': result.get('episode_count', 0),
                    'video_type': result.get('video_type', 'playlist')
                }

            await asyncio.sleep(1)
            
            # ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨ç›®å½•éå†æŸ¥æ‰¾æ–‡ä»¶
            video_files = []

            # ç®€åŒ–ï¼šç›´æ¥è·³åˆ°ç›®å½•éå†ï¼Œåˆ é™¤æ‰€æœ‰å¤æ‚çš„æ–‡ä»¶è®°å½•é€»è¾‘
            if False:  # ç¦ç”¨å¤æ‚é€»è¾‘
                logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(downloaded_files)} ä¸ªå®é™…ä¸‹è½½æ–‡ä»¶è®°å½•")
                for filename in downloaded_files:
                    file_path = Path(filename)
                    if file_path.exists():
                        try:
                            mtime = os.path.getmtime(file_path)
                            video_files.append((file_path, mtime))
                            logger.info(f"âœ… æ‰¾åˆ°æœ¬æ¬¡ä¸‹è½½æ–‡ä»¶: {file_path.name}")
                        except OSError:
                            continue
                    else:
                        logger.warning(f"âš ï¸ è®°å½•çš„æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            elif False:  # ç¦ç”¨å¤æ‚é€»è¾‘
                # æ£€æŸ¥æ˜¯å¦ä¸ºBç«™åˆé›†ä¸‹è½½ï¼ˆæœ‰fileså­—æ®µï¼‰
                if progress_data.get("files"):
                    # Bç«™åˆé›†ä¸‹è½½ï¼šç›´æ¥ä½¿ç”¨é¢„æœŸæ–‡ä»¶åæŸ¥æ‰¾
                    logger.info("ğŸ” Bç«™åˆé›†ä¸‹è½½ï¼šä½¿ç”¨é¢„æœŸæ–‡ä»¶åç›´æ¥æŸ¥æ‰¾")
                    logger.info(f"ğŸ“‹ é¢„æœŸæ–‡ä»¶æ•°é‡: {len(progress_data['files'])}")
                    logger.info(f"ğŸ“ æœç´¢ç›®å½•: {download_path}")

                    for file_info in progress_data["files"]:
                        expected_filename = file_info['filename']
                        expected_path = download_path / expected_filename

                        if expected_path.exists():
                            try:
                                mtime = os.path.getmtime(expected_path)
                                video_files.append((expected_path, mtime))
                                logger.info(f"âœ… æ‰¾åˆ°é¢„æœŸæ–‡ä»¶: {expected_filename}")
                            except OSError:
                                logger.warning(f"âš ï¸ æ— æ³•è·å–æ–‡ä»¶æ—¶é—´: {expected_filename}")
                        else:
                            logger.warning(f"âš ï¸ é¢„æœŸæ–‡ä»¶ä¸å­˜åœ¨: {expected_filename}")
                else:
                    # å…¶ä»–ç±»å‹ä¸‹è½½ï¼šç›´æ¥ä½¿ç”¨progress_dataä¸­çš„é¢„æœŸæ–‡ä»¶åˆ—è¡¨
                    expected_files_list = progress_data.get('expected_files', [])
                    logger.info("ğŸ” ä½¿ç”¨progress_dataä¸­çš„é¢„æœŸæ–‡ä»¶åˆ—è¡¨")

                    logger.info(f"ğŸ“‹ é¢„æœŸæ–‡ä»¶æ•°é‡: {len(expected_files_list)}")
                    logger.info(f"ğŸ“ æœç´¢ç›®å½•: {download_path}")

                    def clean_filename_for_matching(filename):
                        """æ¸…ç†æ–‡ä»¶åç”¨äºåŒ¹é…ï¼Œåˆ é™¤yt-dlpæ ¼å¼ä»£ç ï¼Œä¿ç•™ç‰ˆæœ¬å·ç­‰é‡è¦ä¿¡æ¯"""
                        import re
                        if not filename:
                            return ""

                        # åˆ é™¤yt-dlpçš„å„ç§æ ¼å¼ä»£ç 
                        # 1. åˆ é™¤ .f137+140 æ ¼å¼ï¼ˆåœ¨æ‰©å±•åå‰ï¼‰
                        cleaned = re.sub(r'\.[fm]\d+(\+\d+)*', '', filename)

                        # 2. åˆ é™¤ .f100026 æ ¼å¼ï¼ˆåµŒå…¥åœ¨æ–‡ä»¶åä¸­é—´ï¼‰
                        cleaned = re.sub(r'\.f\d+', '', cleaned)

                        # 3. åˆ é™¤ .m4a, .webm ç­‰ä¸´æ—¶æ ¼å¼ï¼Œæ›¿æ¢ä¸º .mp4
                        cleaned = re.sub(r'\.(webm|m4a|mp3)$', '.mp4', cleaned)

                        # ä¿®å¤å¯èƒ½çš„åŒæ‰©å±•åé—®é¢˜ï¼ˆå¦‚ .m4a.mp4 -> .mp4ï¼‰
                        cleaned = re.sub(r'\.(webm|m4a|mp3)\.mp4$', '.mp4', cleaned)

                        # 4. åˆ é™¤åºå·å‰ç¼€ï¼ˆå¦‚ "23. "ï¼‰ï¼Œå› ä¸ºé¢„æœŸæ–‡ä»¶åæ²¡æœ‰åºå·
                        cleaned = re.sub(r'^\d+\.\s*', '', cleaned)

                        # 5. å¯¹Bç«™å¤šPæ ‡é¢˜è¿›è¡Œæ™ºèƒ½å¤„ç†ï¼ˆå’Œé¢„æœŸæ–‡ä»¶åä¿æŒä¸€è‡´ï¼‰
                        # æŸ¥æ‰¾ pxx æ¨¡å¼ï¼Œå¦‚æœæ‰¾åˆ°å°±ä» pxx å¼€å§‹æˆªå–
                        pattern = r'\s+[pP](\d{1,3})\s+'
                        match = re.search(pattern, cleaned)
                        if match:
                            start_pos = match.start() + 1  # +1 æ˜¯ä¸ºäº†è·³è¿‡å‰é¢çš„ç©ºæ ¼
                            cleaned = cleaned[start_pos:]

                        # 6. ç»Ÿä¸€ç‰¹æ®Šå­—ç¬¦ï¼ˆè§£å†³å…¨è§’/åŠè§’å·®å¼‚ï¼‰
                        # å°†åŠè§’ç«–çº¿è½¬æ¢ä¸ºå…¨è§’ç«–çº¿ï¼Œä¸_basic_sanitize_filenameä¿æŒä¸€è‡´
                        cleaned = cleaned.replace('|', 'ï½œ')
                        # å°†æ™®é€šæ–œæ è½¬æ¢ä¸ºå¤§æ–œæ ç¬¦å·ï¼Œä¸_basic_sanitize_filenameä¿æŒä¸€è‡´
                        cleaned = cleaned.replace('/', 'â§¸')
                        # ä¿ç•™å…¨è§’å­—ç¬¦ï¼Œä¸è¿›è¡Œé¢å¤–è½¬æ¢
                        # cleaned = re.sub(r'[ã€ã€‘]', '_', cleaned)  # æ³¨é‡Šæ‰ï¼Œä¿ç•™åŸå§‹å­—ç¬¦

                        # ç¡®ä¿ä»¥ .mp4 ç»“å°¾
                        if not cleaned.endswith('.mp4'):
                            cleaned = cleaned.rstrip('.') + '.mp4'

                        return cleaned

                    for expected_file in expected_files_list:
                        # å°è¯•å¤šç§å¯èƒ½çš„æ–‡ä»¶åæ ¼å¼
                        base_title = expected_file.get('title', '')
                        base_filename = expected_file.get('filename', '')

                        possible_names = [
                            base_filename,  # åŸå§‹æ–‡ä»¶å
                            base_title,     # åŸå§‹æ ‡é¢˜
                            f"{base_title}.mp4",  # æ ‡é¢˜+.mp4
                            clean_filename_for_matching(base_filename),  # æ¸…ç†åçš„æ–‡ä»¶å
                            clean_filename_for_matching(base_title),     # æ¸…ç†åçš„æ ‡é¢˜
                        ]

                        # å»é‡å¹¶è¿‡æ»¤ç©ºå€¼
                        possible_names = list(dict.fromkeys([name for name in possible_names if name]))

                        found = False
                        for possible_name in possible_names:
                            # 1. å…ˆåœ¨ä¸‹è½½ç›®å½•ç›´æ¥æŸ¥æ‰¾
                            expected_path = download_path / possible_name
                            if expected_path.exists():
                                try:
                                    mtime = os.path.getmtime(expected_path)
                                    video_files.append((expected_path, mtime))
                                    logger.info(f"âœ… æ‰¾åˆ°é¢„æœŸæ–‡ä»¶: {possible_name}")
                                    found = True
                                    break
                                except OSError:
                                    continue

                            # 2. åœ¨å­ç›®å½•ä¸­æŸ¥æ‰¾ï¼ˆé€’å½’æœç´¢ï¼‰
                            for video_ext in ["*.mp4", "*.mkv", "*.webm", "*.avi", "*.mov", "*.flv"]:
                                matching_files = list(Path(download_path).rglob(video_ext))
                                for file_path in matching_files:
                                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ¹é…ï¼ˆè€ƒè™‘åºå·å‰ç¼€ï¼‰
                                    actual_filename = file_path.name
                                    cleaned_actual = clean_filename_for_matching(actual_filename)
                                    cleaned_expected = clean_filename_for_matching(possible_name)

                                    if cleaned_actual == cleaned_expected:
                                        try:
                                            mtime = os.path.getmtime(file_path)
                                            video_files.append((file_path, mtime))
                                            logger.info(f"âœ… åœ¨å­ç›®å½•æ‰¾åˆ°æ–‡ä»¶: {file_path.relative_to(download_path)}")
                                            found = True
                                            break
                                        except OSError:
                                            continue
                                if found:
                                    break
                            if found:
                                break

                        if not found:
                            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°é¢„æœŸæ–‡ä»¶: {expected_file.get('title', 'unknown')}")
                            logger.info(f"   å°è¯•çš„æ–‡ä»¶å: {possible_names}")
            else:
                # Bç«™å¤šPä¸‹è½½ï¼šæ™ºèƒ½æŸ¥æ‰¾å­ç›®å½•ä¸­çš„æ–‡ä»¶
                logger.info("ğŸ¯ Bç«™å¤šPä¸‹è½½ï¼šæ²¡æœ‰é¢„æœŸæ–‡ä»¶åˆ—è¡¨ï¼Œæ™ºèƒ½æŸ¥æ‰¾å­ç›®å½•ä¸­çš„æ–‡ä»¶")
                logger.info(f"ğŸ” æœç´¢è·¯å¾„: {download_path}")

                # æ£€æŸ¥ä¸‹è½½è·¯å¾„æ˜¯å¦å­˜åœ¨
                if not Path(download_path).exists():
                    logger.error(f"âŒ ä¸‹è½½è·¯å¾„ä¸å­˜åœ¨: {download_path}")
                    return {"success": False, "error": "ä¸‹è½½è·¯å¾„ä¸å­˜åœ¨"}

                # æ™ºèƒ½æŸ¥æ‰¾ï¼šä¼˜å…ˆæŸ¥æ‰¾æœ€æ–°åˆ›å»ºçš„å­ç›®å½•
                try:
                    all_items = list(Path(download_path).iterdir())
                    subdirs = [item for item in all_items if item.is_dir()]

                    if subdirs:
                        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæ‰¾åˆ°æœ€æ–°çš„å­ç›®å½•
                        latest_subdir = max(subdirs, key=lambda x: x.stat().st_mtime)
                        logger.info(f"ğŸ“ æ‰¾åˆ°æœ€æ–°å­ç›®å½•: {latest_subdir.name}")

                        # åœ¨å­ç›®å½•ä¸­æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
                        video_extensions = ["*.mp4", "*.mkv", "*.webm", "*.avi", "*.mov", "*.flv"]
                        for ext in video_extensions:
                            matching_files = list(latest_subdir.glob(ext))
                            if matching_files:
                                logger.info(f"âœ… åœ¨å­ç›®å½•ä¸­æ‰¾åˆ° {len(matching_files)} ä¸ª {ext} æ–‡ä»¶")
                                for file_path in matching_files:
                                    try:
                                        mtime = os.path.getmtime(file_path)
                                        video_files.append((file_path, mtime))
                                        logger.info(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_path.name}")
                                    except OSError:
                                        continue
                    else:
                        logger.warning("âš ï¸ æœªæ‰¾åˆ°å­ç›®å½•ï¼Œåœ¨æ ¹ç›®å½•æŸ¥æ‰¾")
                        # å¦‚æœæ²¡æœ‰å­ç›®å½•ï¼Œåœ¨æ ¹ç›®å½•æŸ¥æ‰¾
                        video_extensions = ["*.mp4", "*.mkv", "*.webm", "*.avi", "*.mov", "*.flv"]
                        for ext in video_extensions:
                            matching_files = list(Path(download_path).glob(ext))
                            for file_path in matching_files:
                                try:
                                    mtime = os.path.getmtime(file_path)
                                    video_files.append((file_path, mtime))
                                    logger.info(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_path.name}")
                                except OSError:
                                    continue

                except Exception as e:
                    logger.error(f"âŒ æ™ºèƒ½æŸ¥æ‰¾å¤±è´¥: {e}")
                    return {"success": False, "error": f"æ–‡ä»¶æŸ¥æ‰¾å¤±è´¥: {e}"}
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯ç”¨äºè°ƒè¯•
            if not video_files:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…æ–‡ä»¶")
                logger.info(f"ğŸ” æœç´¢è·¯å¾„: {download_path}")
                return {"success": False, "error": "ç›®å½•éå†æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶"}

            video_files.sort(key=lambda x: x[0].name)

            # æ£€æµ‹PARTæ–‡ä»¶
            part_files = self._detect_part_files(download_path)
            success_count = len(video_files)
            part_count = len(part_files)

            # åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
            logger.info(f"ğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡ï¼š")
            logger.info(f"âœ… æˆåŠŸæ–‡ä»¶ï¼š{success_count} ä¸ª")
            if part_count > 0:
                logger.warning(f"âš ï¸ æœªå®Œæˆæ–‡ä»¶ï¼š{part_count} ä¸ª")
                self._log_part_files_details(part_files)
            else:
                logger.info("âœ… æœªå‘ç°PARTæ–‡ä»¶ï¼Œæ‰€æœ‰ä¸‹è½½éƒ½å·²å®Œæˆ")

            if is_list:
                logger.info(f"ğŸ‰ Bç«™åˆé›†ä¸‹è½½å®Œæˆï¼Œç»Ÿè®¡æœ¬æ¬¡ä¸‹è½½æ–‡ä»¶")
                if video_files:
                    total_size_mb = 0
                    file_info_list = []
                    all_resolutions = set()
                    for file_path, mtime in video_files:
                        size_mb = os.path.getsize(file_path) / (1024 * 1024)
                        total_size_mb += size_mb
                        media_info = self.get_media_info(str(file_path))
                        resolution = media_info.get('resolution', 'æœªçŸ¥')
                        if resolution != 'æœªçŸ¥':
                            all_resolutions.add(resolution)
                        file_info_list.append({
                            'filename': os.path.basename(file_path),
                            'size_mb': size_mb,
                            'resolution': resolution,
                            'abr': media_info.get('bit_rate')
                        })
                    filename_list = [info['filename'] for info in file_info_list]
                    filename_display = '\n'.join([f"  {i+1:02d}. {name}" for i, name in enumerate(filename_list)])
                    resolution_display = ', '.join(sorted(all_resolutions)) if all_resolutions else 'æœªçŸ¥'
                    return {
                        'success': True,
                        'is_playlist': True,
                        'file_count': len(video_files),
                        'total_size_mb': total_size_mb,
                        'files': file_info_list,
                        'platform': 'bilibili',
                        'download_path': str(download_path),
                        'filename': filename_display,
                        'size_mb': total_size_mb,
                        'resolution': resolution_display,
                        'episode_count': len(video_files),
                        # æ·»åŠ PARTæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
                        'success_count': success_count,
                        'part_count': part_count,
                        'part_files': [str(pf) for pf in part_files] if part_files else []
                    }
                else:
                    return {'success': False, 'error': 'Bç«™åˆé›†ä¸‹è½½å®Œæˆä½†æœªæ‰¾åˆ°æœ¬æ¬¡ä¸‹è½½çš„æ–‡ä»¶'}
            else:
                # å¤šPè§†é¢‘ä¸‹è½½ï¼Œç»Ÿè®¡æœ¬æ¬¡ä¸‹è½½æ–‡ä»¶
                if video_files:
                    # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œåº”è¯¥ä½¿ç”¨æ’­æ”¾åˆ—è¡¨æ ¼å¼æ˜¾ç¤º
                    if len(video_files) > 1:
                        total_size_mb = 0
                        file_info_list = []
                        all_resolutions = set()
                        for file_path, mtime in video_files:
                            size_mb = os.path.getsize(file_path) / (1024 * 1024)
                            total_size_mb += size_mb
                            media_info = self.get_media_info(str(file_path))
                            resolution = media_info.get('resolution', 'æœªçŸ¥')
                            if resolution != 'æœªçŸ¥':
                                all_resolutions.add(resolution)
                            file_info_list.append({
                                'filename': os.path.basename(file_path),
                                'size_mb': size_mb,
                                'resolution': resolution,
                                'abr': media_info.get('bit_rate')
                            })
                        filename_list = [info['filename'] for info in file_info_list]
                        filename_display = '\n'.join([f"  {i+1:02d}. {name}" for i, name in enumerate(filename_list)])
                        resolution_display = ', '.join(sorted(all_resolutions)) if all_resolutions else 'æœªçŸ¥'
                        return {
                            'success': True,
                            'is_playlist': True,
                            'video_type': 'playlist',
                            'file_count': len(video_files),
                            'total_size_mb': total_size_mb,
                            'files': file_info_list,
                            'platform': 'bilibili',
                            'download_path': str(download_path),
                            'filename': filename_display,
                            'size_mb': total_size_mb,
                            'resolution': resolution_display,
                            'episode_count': len(video_files)
                        }
                    else:
                        # åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨å•ä¸ªè§†é¢‘æ ¼å¼
                        video_files.sort(key=lambda x: x[1], reverse=True)
                        final_file_path = str(video_files[0][0])
                        media_info = self.get_media_info(final_file_path)
                        size_mb = os.path.getsize(final_file_path) / (1024 * 1024)
                        return {
                            'success': True,
                            'filename': os.path.basename(final_file_path),
                            'full_path': final_file_path,
                            'size_mb': size_mb,
                            'platform': 'bilibili',
                            'download_path': str(download_path),
                            'resolution': media_info.get('resolution', 'æœªçŸ¥'),
                            'abr': media_info.get('bit_rate')
                        }
                else:
                    return {'success': False, 'error': 'Bç«™å¤šPä¸‹è½½å®Œæˆä½†æœªæ‰¾åˆ°æœ¬æ¬¡ä¸‹è½½çš„æ–‡ä»¶'}

        except Exception as e:
            logger.error(f"Bç«™ä¸‹è½½å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    async def _download_single_video(
        self, url: str, download_path: Path, message_updater=None
    ) -> Dict[str, Any]:
        """ä¸‹è½½å•ä¸ªè§†é¢‘ï¼ˆåŒ…æ‹¬YouTubeå•ä¸ªè§†é¢‘ï¼‰"""
        import os
        logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½å•ä¸ªè§†é¢‘: {url}")
        # 1. é¢„å…ˆè·å–ä¿¡æ¯ä»¥ç¡®å®šæ–‡ä»¶å
        try:
            logger.info("ğŸ” æ­¥éª¤1: é¢„å…ˆè·å–è§†é¢‘ä¿¡æ¯...")
            info_opts = {
                "quiet": True,
                "no_warnings": True,
                "socket_timeout": 30,  # 30ç§’è¶…æ—¶
                "retries": 3,  # å‡å°‘é‡è¯•æ¬¡æ•°
            }
            if self.proxy_host:
                info_opts["proxy"] = self.proxy_host
                logger.info(f"ğŸŒ ä½¿ç”¨ä»£ç†: {self.proxy_host}")
            if (
                self.is_x_url(url)
                and self.x_cookies_path
                and os.path.exists(self.x_cookies_path)
            ):
                info_opts["cookiefile"] = self.x_cookies_path
                logger.info(f"ğŸª ä½¿ç”¨X cookies: {self.x_cookies_path}")
            if (
                self.is_youtube_url(url)
                and self.youtube_cookies_path
                and os.path.exists(self.youtube_cookies_path)
            ):
                info_opts["cookiefile"] = self.youtube_cookies_path
                logger.info(f"ğŸª ä½¿ç”¨YouTube cookies: {self.youtube_cookies_path}")
            if (
                self.is_douyin_url(url)
                and self.douyin_cookies_path
                and os.path.exists(self.douyin_cookies_path)
            ):
                info_opts["cookiefile"] = self.douyin_cookies_path
                logger.info(f"ğŸª ä½¿ç”¨æŠ–éŸ³ cookies: {self.douyin_cookies_path}")
            logger.info("ğŸ” æ­¥éª¤2: å¼€å§‹æå–è§†é¢‘ä¿¡æ¯...")
            # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨æ¥æ·»åŠ è¶…æ—¶æ§åˆ¶
            loop = asyncio.get_running_loop()

            def extract_video_info():
                with yt_dlp.YoutubeDL(info_opts) as ydl:
                    logger.info("ğŸ“¡ æ­£åœ¨ä»å¹³å°è·å–è§†é¢‘æ•°æ®...")
                    return ydl.extract_info(url, download=False)

            # è®¾ç½®30ç§’è¶…æ—¶
            try:
                info = await asyncio.wait_for(
                    loop.run_in_executor(None, extract_video_info), timeout=60.0
                )
                logger.info(f"âœ… è§†é¢‘ä¿¡æ¯è·å–å®Œæˆï¼Œæ•°æ®ç±»å‹: {type(info)}")

                video_id = info.get("id")
                title = info.get("title")
                # æ¸…ç†æ ‡é¢˜ä¸­çš„éæ³•å­—ç¬¦
                if title:
                    title = self._sanitize_filename(title)
                else:
                    title = self._sanitize_filename(video_id)
                logger.info(f"ğŸ“ è§†é¢‘æ ‡é¢˜: {title}")
                logger.info(f"ğŸ†” è§†é¢‘ID: {video_id}")
            except asyncio.TimeoutError:
                logger.error("âŒ è·å–è§†é¢‘ä¿¡æ¯è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
                return {
                    "success": False,
                    "error": "è·å–è§†é¢‘ä¿¡æ¯è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚",
                }
        except Exception as e:
            logger.error(f"âŒ æ— æ³•é¢„å…ˆè·å–è§†é¢‘ä¿¡æ¯: {e}")
            # å¦‚æœé¢„å…ˆè·å–ä¿¡æ¯å¤±è´¥ï¼Œæä¾›ä¸€ä¸ªå›é€€æ–¹æ¡ˆ
            title = self._sanitize_filename(str(int(time.time())))
            logger.info(f"ğŸ“ ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºæ ‡é¢˜: {title}")
        # 2. æ ¹æ®å¹³å°å’Œè·å–åˆ°çš„ä¿¡æ¯æ„é€ ç²¾ç¡®çš„è¾“å‡ºæ¨¡æ¿
        if self.is_youtube_url(url):
            outtmpl = str(download_path.absolute() / f"{title}.%(ext)s")
        elif self.is_x_url(url):
            outtmpl = str(download_path.absolute() / f"{title}.%(ext)s")
        else:  # å…¶ä»–å¹³å°
            outtmpl = str(download_path.absolute() / f"{title}.%(ext)s")
        # æ·»åŠ æ˜æ˜¾çš„outtmplæ—¥å¿—
        logger.info(f"ğŸ”§ [SINGLE_VIDEO] outtmpl ç»å¯¹è·¯å¾„: {outtmpl}")
        logger.info(f"ğŸ“ ä¸‹è½½è·¯å¾„: {download_path}")
        logger.info(f"ğŸ“ è¾“å‡ºæ¨¡æ¿: {outtmpl}")
        logger.info("ğŸ” æ­¥éª¤3: é…ç½®ä¸‹è½½é€‰é¡¹...")
        ydl_opts = {
            "outtmpl": outtmpl,
            "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
            "merge_output_format": "mp4",
            "noplaylist": True,
            "nocheckcertificate": True,
            "ignoreerrors": True,
            "logtostderr": True,  # æ”¹ä¸ºTrueï¼Œç¡®ä¿è¿›åº¦å›è°ƒæ­£å¸¸å·¥ä½œ
            "quiet": False,  # æ”¹ä¸ºFalseï¼Œç¡®ä¿è¿›åº¦å›è°ƒæ­£å¸¸å·¥ä½œ
            "no_warnings": False,  # æ”¹ä¸ºFalseï¼Œç¡®ä¿èƒ½çœ‹åˆ°è­¦å‘Šä¿¡æ¯
            "default_search": "auto",
            "source_address": "0.0.0.0",
            "http_headers": {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            },
            "retries": 5,  # å‡å°‘é‡è¯•æ¬¡æ•°
            "fragment_retries": 5,
            "skip_unavailable_fragments": True,
            "keepvideo": False,
            "prefer_ffmpeg": True,
            "socket_timeout": 30,  # 30ç§’è¶…æ—¶
            "progress": True,  # æ·»åŠ è¿™ä¸ªå‚æ•°ï¼Œç¡®ä¿è¿›åº¦å›è°ƒè¢«å¯ç”¨
            # HLSä¸‹è½½ç‰¹æ®Šé…ç½®
            "hls_use_mpegts": False,  # ä½¿ç”¨mp4å®¹å™¨è€Œä¸æ˜¯ts
            "hls_prefer_native": True,  # ä¼˜å…ˆä½¿ç”¨åŸç”ŸHLSä¸‹è½½å™¨
            "concurrent_fragment_downloads": 3,  # å¹¶å‘ä¸‹è½½åˆ†ç‰‡æ•°é‡
            "buffersize": 1024,  # ç¼“å†²åŒºå¤§å°
            "http_chunk_size": 10485760,  # 10MBåˆ†å—å¤§å°
        }
        # é’ˆå¯¹æ€§åœ°æ·»åŠ  Cookies
        if (
            self.is_x_url(url)
            and self.x_cookies_path
            and os.path.exists(self.x_cookies_path)
        ):
            ydl_opts["cookiefile"] = self.x_cookies_path
            logger.info(f"ğŸª ä¸ºXé“¾æ¥æ·»åŠ cookies: {self.x_cookies_path}")
        if (
            self.is_youtube_url(url)
            and self.youtube_cookies_path
            and os.path.exists(self.youtube_cookies_path)
        ):
            ydl_opts["cookiefile"] = self.youtube_cookies_path
            logger.info(f"ğŸª ä¸ºYouTubeé“¾æ¥æ·»åŠ cookies: {self.youtube_cookies_path}")
        if (
            self.is_douyin_url(url)
            and self.douyin_cookies_path
            and os.path.exists(self.douyin_cookies_path)
        ):
            ydl_opts["cookiefile"] = self.douyin_cookies_path
            logger.info(f"ğŸª ä¸ºæŠ–éŸ³é“¾æ¥æ·»åŠ cookies: {self.douyin_cookies_path}")
        elif self.is_douyin_url(url):
            logger.warning("âš ï¸ æ£€æµ‹åˆ°æŠ–éŸ³é“¾æ¥ä½†æœªè®¾ç½®cookiesæ–‡ä»¶")
            if self.douyin_cookies_path:
                logger.warning(f"âš ï¸ æŠ–éŸ³cookiesæ–‡ä»¶ä¸å­˜åœ¨: {self.douyin_cookies_path}")
            else:
                logger.warning("âš ï¸ æœªè®¾ç½®DOUYIN_COOKIESç¯å¢ƒå˜é‡")
        # æ·»åŠ ä»£ç†
        if self.proxy_host:
            ydl_opts["proxy"] = self.proxy_host
        # 3. è®¾ç½®è¿›åº¦å›è°ƒ
        logger.info("ğŸ” æ­¥éª¤3: è®¾ç½®è¿›åº¦å›è°ƒ...")
        progress_data = {"final_filename": None, "lock": threading.Lock()}

        # ä½¿ç”¨å¢å¼ºç‰ˆçš„ single_video_progress_hookï¼ŒåŒ…å«å®Œæ•´çš„è¿›åº¦æ˜¾ç¤ºé€»è¾‘
        # æ£€æŸ¥ message_updater æ˜¯å¦æ˜¯å¢å¼ºç‰ˆè¿›åº¦å›è°ƒå‡½æ•°
        if callable(message_updater) and message_updater.__name__ == 'enhanced_progress_callback':
            # å¦‚æœæ˜¯å¢å¼ºç‰ˆè¿›åº¦å›è°ƒï¼Œç›´æ¥ä½¿ç”¨å®ƒè¿”å›çš„ progress_hook
            progress_hook = message_updater(progress_data)
        else:
            # å¦åˆ™ä½¿ç”¨æ ‡å‡†çš„ single_video_progress_hook
            progress_hook = single_video_progress_hook(message_updater, progress_data)
        
        ydl_opts['progress_hooks'] = [progress_hook]
        # 4. è¿è¡Œä¸‹è½½
        logger.info("ğŸ” æ­¥éª¤4: å¼€å§‹ä¸‹è½½è§†é¢‘ï¼ˆè®¾ç½®60ç§’è¶…æ—¶ï¼‰...")

        def run_download():
            try:
                logger.info(f"ğŸ”§ [SINGLE_VIDEO_DOWNLOAD] æœ€ç»ˆydl_opts: {ydl_opts}")
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    logger.info("ğŸš€ å¼€å§‹ä¸‹è½½è§†é¢‘...")
                    ydl.download([url])
                return True
            except Exception as e:
                error_message = str(e)
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {error_message}")
                progress_data["error"] = error_message
                return False

        # è®¾ç½®60ç§’è¶…æ—¶ç”¨äºä¸‹è½½
        try:
            success = await asyncio.wait_for(
                loop.run_in_executor(None, run_download), timeout=600.0  # å¢åŠ åˆ°10åˆ†é’Ÿ
            )
        except asyncio.TimeoutError:
            logger.error("âŒ è§†é¢‘ä¸‹è½½è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰")
            return {
                "success": False,
                "error": "è§†é¢‘ä¸‹è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚",
            }
        if not success:
            error = progress_data.get("error", "ä¸‹è½½å™¨åœ¨æ‰§è¡Œæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯")
            return {"success": False, "error": error}
        # 5. æŸ¥æ‰¾æ–‡ä»¶å¹¶è¿”å›ç»“æœ
        logger.info("ğŸ” æ­¥éª¤5: æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶...")
        time.sleep(1)  # ç­‰å¾…æ–‡ä»¶ç³»ç»ŸåŒæ­¥

        # ä½¿ç”¨å•è§†é¢‘æ–‡ä»¶æŸ¥æ‰¾æ–¹æ³•
        final_file_path = self.single_video_find_downloaded_file(download_path, progress_data, title, url)

        # å¤„ç†æœ€ç»ˆæ–‡ä»¶
        if final_file_path and os.path.exists(final_file_path):
            logger.info("ğŸ” æ­¥éª¤6: è·å–åª’ä½“ä¿¡æ¯...")
            media_info = self.get_media_info(final_file_path)

            # å®‰å…¨åœ°è·å–æ–‡ä»¶å¤§å°
            try:
                file_size_bytes = os.path.getsize(final_file_path)
                size_mb = file_size_bytes / (1024 * 1024)
            except (OSError, TypeError):
                size_mb = 0.0

            logger.info("ğŸ‰ è§†é¢‘ä¸‹è½½ä»»åŠ¡å®Œæˆ!")
            return {
                "success": True,
                "filename": os.path.basename(final_file_path),
                "full_path": final_file_path,
                "size_mb": size_mb,
                "platform": self.get_platform_name(url),
                "download_path": str(download_path),
                "resolution": media_info.get("resolution", "æœªçŸ¥"),
                "abr": media_info.get("bit_rate"),
                "title": title,
            }
        else:
            return {
                "success": False,
                "error": "ä¸‹è½½å®Œæˆä½†æ— æ³•åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æ‰¾åˆ°æœ€ç»ˆæ–‡ä»¶ã€‚",
            }



    async def _download_youtube_channel_playlists(
        self, channel_url: str, download_path: Path, message_updater=None, status_message=None, loop=None
    ) -> Dict[str, Any]:
        """ä¸‹è½½YouTubeé¢‘é“çš„æ‰€æœ‰æ’­æ”¾åˆ—è¡¨"""
        logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½YouTubeé¢‘é“æ’­æ”¾åˆ—è¡¨: {channel_url}")
        logger.info(f"ğŸ“ ä¸‹è½½è·¯å¾„: {download_path}")
        # ç§»é™¤è°ƒè¯•æ—¥å¿—

        # ç¡®ä¿äº‹ä»¶å¾ªç¯æ­£ç¡®è®¾ç½®
        try:
            import asyncio
            self._main_loop = asyncio.get_running_loop()
            logger.info(f"âœ… æˆåŠŸè®¾ç½®äº‹ä»¶å¾ªç¯: {self._main_loop}")
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•è·å–äº‹ä»¶å¾ªç¯: {e}")
            self._main_loop = None



        # YouTubeé¢‘é“æ’­æ”¾åˆ—è¿›åº¦ç®¡ç†å™¨ - ä¸“é—¨ç”¨äºè·Ÿè¸ªYouTubeé¢‘é“æ’­æ”¾åˆ—è¡¨ä¸‹è½½çš„æ€»ä½“è¿›åº¦
        global_progress = {
            "total_playlists": 0,
            "completed_playlists": 0,
            "total_videos": 0,
            "completed_videos": 0,
            "total_size_mb": 0,
            "downloaded_size_mb": 0,
            "channel_name": "",
            "start_time": time.time()
        }

        try:
            # æ›´æ–°çŠ¶æ€æ¶ˆæ¯
            if message_updater:
                try:
                    if asyncio.iscoroutinefunction(message_updater):
                        await message_updater("ğŸ” æ­£åœ¨è·å–é¢‘é“ä¿¡æ¯...")
                    else:
                        message_updater("ğŸ” æ­£åœ¨è·å–é¢‘é“ä¿¡æ¯...")
                except Exception as e:
                    logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
            logger.info("ğŸ” æ­¥éª¤1: å‡†å¤‡è·å–é¢‘é“ä¿¡æ¯...")
            # è·å–é¢‘é“ä¿¡æ¯ - æ·»åŠ è¶…æ—¶æ§åˆ¶
            info_opts = {
                "quiet": True,
                "extract_flat": True,
                "ignoreerrors": True,
                "socket_timeout": 30,  # 30ç§’è¶…æ—¶
                "retries": 3,  # å‡å°‘é‡è¯•æ¬¡æ•°
                "fragment_retries": 3,
            }
            if self.proxy_host:
                info_opts["proxy"] = self.proxy_host
                logger.info(f"ğŸŒ ä½¿ç”¨ä»£ç†: {self.proxy_host}")
            if self.youtube_cookies_path and os.path.exists(self.youtube_cookies_path):
                info_opts["cookiefile"] = self.youtube_cookies_path
                logger.info(f"ğŸª ä½¿ç”¨YouTube cookies: {self.youtube_cookies_path}")
            logger.info("ğŸ” æ­¥éª¤2: å¼€å§‹æå–é¢‘é“ä¿¡æ¯ï¼ˆè®¾ç½®30ç§’è¶…æ—¶ï¼‰...")
            # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨æ¥æ·»åŠ è¶…æ—¶æ§åˆ¶
            loop = asyncio.get_running_loop()

            def extract_channel_info():
                logger.info("ğŸ“¡ æ­£åœ¨ä»YouTubeè·å–é¢‘é“æ•°æ®...")
                with yt_dlp.YoutubeDL(info_opts) as ydl:
                    logger.info("ğŸ”— å¼€å§‹ç½‘ç»œè¯·æ±‚...")
                    result = ydl.extract_info(channel_url, download=False)
                    logger.info(f"ğŸ“Š ç½‘ç»œè¯·æ±‚å®Œæˆï¼Œç»“æœç±»å‹: {type(result)}")
                    return result

            # è®¾ç½®30ç§’è¶…æ—¶
            try:
                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater("â³ æ­£åœ¨è¿æ¥YouTubeæœåŠ¡å™¨...")
                        else:
                            message_updater("â³ æ­£åœ¨è¿æ¥YouTubeæœåŠ¡å™¨...")
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
                info = await asyncio.wait_for(
                    loop.run_in_executor(None, extract_channel_info), timeout=60.0
                )
                logger.info(f"âœ… é¢‘é“ä¿¡æ¯è·å–å®Œæˆï¼Œæ•°æ®ç±»å‹: {type(info)}")
                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater("âœ… é¢‘é“ä¿¡æ¯è·å–æˆåŠŸï¼Œæ­£åœ¨åˆ†æ...")
                        else:
                            message_updater("âœ… é¢‘é“ä¿¡æ¯è·å–æˆåŠŸï¼Œæ­£åœ¨åˆ†æ...")
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
            except asyncio.TimeoutError:
                logger.error("âŒ è·å–é¢‘é“ä¿¡æ¯è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater(
                                "âŒ è·å–é¢‘é“ä¿¡æ¯è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚"
                            )
                        else:
                            message_updater(
                                "âŒ è·å–é¢‘é“ä¿¡æ¯è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚"
                            )
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
                return {
                    "success": False,
                    "error": "è·å–é¢‘é“ä¿¡æ¯è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚",
                }
            logger.info("ğŸ” æ­¥éª¤3: æ£€æŸ¥é¢‘é“ä¿¡æ¯ç»“æ„...")
            if not info:
                logger.error("âŒ é¢‘é“ä¿¡æ¯ä¸ºç©º")
                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater("âŒ æ— æ³•è·å–é¢‘é“ä¿¡æ¯ã€‚")
                        else:
                            message_updater("âŒ æ— æ³•è·å–é¢‘é“ä¿¡æ¯ã€‚")
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
                return {"success": False, "error": "æ— æ³•è·å–é¢‘é“ä¿¡æ¯ã€‚"}
            if "entries" not in info:
                logger.warning("âŒ é¢‘é“ä¿¡æ¯ä¸­æ²¡æœ‰æ‰¾åˆ° 'entries' å­—æ®µ")
                logger.info(
                    f"ğŸ“Š é¢‘é“ä¿¡æ¯åŒ…å«çš„å­—æ®µ: {list(info.keys()) if isinstance(info, dict) else 'éå­—å…¸ç±»å‹'}"
                )
                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater("âŒ æ­¤é¢‘é“ä¸»é¡µæœªæ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚")
                        else:
                            message_updater("âŒ æ­¤é¢‘é“ä¸»é¡µæœªæ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚")
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
                return {"success": False, "error": "æ­¤é¢‘é“ä¸»é¡µæœªæ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚"}
            entries = info.get("entries", [])
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(entries)} ä¸ªæ¡ç›®")
            if not entries:
                logger.warning("âŒ é¢‘é“æ¡ç›®åˆ—è¡¨ä¸ºç©º")
                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater("âŒ æ­¤é¢‘é“ä¸»é¡µæœªæ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚")
                        else:
                            message_updater("âŒ æ­¤é¢‘é“ä¸»é¡µæœªæ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚")
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
                return {"success": False, "error": "æ­¤é¢‘é“ä¸»é¡µæœªæ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚"}
            logger.info("ğŸ” æ­¥éª¤4: åˆ†æé¢‘é“æ¡ç›®...")
            if message_updater:
                try:
                    if asyncio.iscoroutinefunction(message_updater):
                        await message_updater(f"ğŸ” æ­£åœ¨åˆ†æ {len(entries)} ä¸ªé¢‘é“æ¡ç›®...")
                    else:
                        message_updater(f"ğŸ” æ­£åœ¨åˆ†æ {len(entries)} ä¸ªé¢‘é“æ¡ç›®...")
                except Exception as e:
                    logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
            playlist_entries = []
            for i, entry in enumerate(entries):
                if entry:
                    entry_type = entry.get("_type", "unknown")
                    entry_id = entry.get("id", "no_id")
                    entry_title = entry.get("title", "no_title")
                    logger.info(
                        f"  ğŸ“‹ æ¡ç›® {i + 1}: ç±»å‹={entry_type}, ID={entry_id}, æ ‡é¢˜={entry_title}"
                    )
                    # å…¼å®¹ _type == 'playlist' æˆ– _type == 'url' ä¸” url æŒ‡å‘ playlist
                    if entry_type == "playlist":
                        playlist_entries.append(entry)
                        logger.info(f"    âœ… è¯†åˆ«ä¸ºæ’­æ”¾åˆ—è¡¨")
                    elif entry_type == "url" and "playlist?list=" in (
                        entry.get("url") or ""
                    ):
                        playlist_entries.append(entry)
                        logger.info(f"    âœ… è¯†åˆ«ä¸ºæ’­æ”¾åˆ—è¡¨URL")
                else:
                    logger.warning(f"  âš ï¸ æ¡ç›® {i + 1} ä¸ºç©º")
            logger.info(f"ğŸ“Š æ€»å…±æ‰¾åˆ° {len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨")

            if not playlist_entries:
                logger.warning("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨")
                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater("âŒ é¢‘é“ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚")
                        else:
                            message_updater("âŒ é¢‘é“ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚")
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
                return {"success": False, "error": "é¢‘é“ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨ã€‚"}

            logger.info("ğŸ” æ­¥éª¤5: åˆ›å»ºé¢‘é“ç›®å½•...")
            channel_name = re.sub(
                r'[\\/:*?"<>|]', "_", info.get("uploader", "Unknown Channel")
            ).strip()
            channel_path = download_path / channel_name
            channel_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ é¢‘é“ç›®å½•: {channel_path}")

            logger.info("ğŸ” æ­¥éª¤6: å¼€å§‹ä¸‹è½½æ’­æ”¾åˆ—è¡¨...")
            if message_updater:
                try:
                    if asyncio.iscoroutinefunction(message_updater):
                        await message_updater(
                            f"ğŸ¬ å¼€å§‹ä¸‹è½½ {len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨..."
                        )
                    else:
                        message_updater(
                            f"ğŸ¬ å¼€å§‹ä¸‹è½½ {len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨..."
                        )
                except Exception as e:
                    logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")

            # åˆå§‹åŒ–å…¨å±€è¿›åº¦æ•°æ®
            global_progress["total_playlists"] = len(playlist_entries)
            global_progress["channel_name"] = channel_name
            
            # è®¡ç®—æ€»è§†é¢‘æ•°ï¼ˆå¦‚æœå¯èƒ½çš„è¯ï¼‰
            total_video_count = 0
            for entry in playlist_entries:
                if entry and "video_count" in entry:
                    total_video_count += entry.get("video_count", 0)
            
            # å¦‚æœæ— æ³•ä»APIè·å–è§†é¢‘æ•°é‡ï¼Œè®¾ç½®ä¸º-1è¡¨ç¤ºéœ€è¦åŠ¨æ€è®¡ç®—
            if total_video_count == 0:
                logger.info("ğŸ“Š æ— æ³•ä»APIè·å–è§†é¢‘æ•°é‡ï¼Œå°†åœ¨ä¸‹è½½è¿‡ç¨‹ä¸­åŠ¨æ€è®¡ç®—")
                global_progress["total_videos"] = -1  # ä½¿ç”¨-1è¡¨ç¤ºéœ€è¦åŠ¨æ€è®¡ç®—
            else:
                global_progress["total_videos"] = total_video_count
            
            logger.info(f"ğŸ“Š å…¨å±€è¿›åº¦åˆå§‹åŒ–: {global_progress['total_playlists']} ä¸ªæ’­æ”¾åˆ—è¡¨, {global_progress['total_videos']} ä¸ªè§†é¢‘")

            downloaded_playlists = []
            playlist_stats = []  # å­˜å‚¨æ¯ä¸ªæ’­æ”¾åˆ—è¡¨çš„ç»Ÿè®¡ä¿¡æ¯

            for i, entry in enumerate(playlist_entries, 1):
                playlist_id = entry.get("id")
                playlist_title = entry.get("title", f"Playlist_{playlist_id}")
                logger.info(
                    f"ğŸ¬ å¼€å§‹ä¸‹è½½ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨: {playlist_title}"
                )
                logger.info(f"    ğŸ“‹ æ’­æ”¾åˆ—è¡¨ID: {playlist_id}")

                # å…ˆæ£€æŸ¥æ’­æ”¾åˆ—è¡¨æ˜¯å¦å·²å®Œæ•´ä¸‹è½½
                check_result = self._check_playlist_already_downloaded(playlist_id, channel_path)

                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            if check_result.get("already_downloaded", False):
                                await message_updater(
                                    f"âœ… æ£€æŸ¥ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{playlist_title} (å·²å®Œæ•´ä¸‹è½½)"
                                )
                            else:
                                await message_updater(
                                    f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{playlist_title}"
                                )
                        else:
                            if check_result.get("already_downloaded", False):
                                message_updater(
                                    f"âœ… æ£€æŸ¥ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{playlist_title} (å·²å®Œæ•´ä¸‹è½½)"
                                )
                            else:
                                message_updater(
                                    f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{playlist_title}"
                                )
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")

                # åˆ›å»ºæ’­æ”¾åˆ—è¡¨ä¸“ç”¨çš„è¿›åº¦å›è°ƒ
                playlist_progress_data = {
                    "playlist_index": i,
                    "total_playlists": len(playlist_entries),
                    "playlist_title": playlist_title,
                    "current_video": 0,
                    "total_videos": 0,
                    "downloaded_videos": 0,
                }

                def create_playlist_progress_callback(progress_data):
                    last_update = {"percent": -1, "time": 0, "text": ""}
                    import time as _time

                    def escape_num(text):
                        # è½¬ä¹‰MarkdownV2ç‰¹æ®Šå­—ç¬¦ï¼ŒåŒ…æ‹¬å°æ•°ç‚¹
                        if not isinstance(text, str):
                            text = str(text)
                        escape_chars = [
                            "_",
                            "*",
                            "[",
                            "]",
                            "(",
                            ")",
                            "~",
                            "`",
                            ">",
                            "#",
                            "+",
                            "-",
                            "=",
                            "|",
                            "{",
                            "}",
                            ".",
                            "!",
                        ]
                        for char in escape_chars:
                            text = text.replace(char, "\\" + char)
                        return text

                    def progress_callback(d):
                        if d.get("status") == "downloading":
                            # ä¿®æ­£å½“å‰è§†é¢‘åºå·ä¸ºæœ¬æ’­æ”¾åˆ—è¡¨çš„å½“å‰ä¸‹è½½è§†é¢‘åºå·/æ€»æ•°
                            cur_idx = (
                                d.get("playlist_index")
                                or d.get("info_dict", {}).get("playlist_index")
                                or 1
                            )
                            total_idx = (
                                d.get("playlist_count")
                                or d.get("info_dict", {}).get("n_entries")
                                or progress_data.get("total_videos")
                                or 1
                            )
                            progress_text = (
                                f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ç¬¬{escape_num(progress_data['playlist_index'])}/{escape_num(progress_data['total_playlists'])}ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{escape_num(progress_data['playlist_title'])}\n\n"
                                f"ğŸ“º å½“å‰è§†é¢‘: {escape_num(cur_idx)}/{escape_num(total_idx)}\n"
                            )
                            percent = 0
                            if d.get("filename"):
                                filename = os.path.basename(d.get("filename", ""))
                                total_bytes = d.get("total_bytes") or d.get(
                                    "total_bytes_estimate", 0
                                )
                                downloaded_bytes = d.get("downloaded_bytes", 0)
                                speed_bytes_s = d.get("speed", 0)
                                eta_seconds = d.get("eta", 0)
                                if total_bytes and total_bytes > 0:
                                    downloaded_mb = downloaded_bytes / (1024 * 1024)
                                    total_mb = total_bytes / (1024 * 1024)
                                    speed_mb_s = (
                                        speed_bytes_s / (1024 * 1024)
                                        if speed_bytes_s
                                        else 0
                                    )
                                    percent = int(downloaded_bytes * 100 / total_bytes)
                                    bar = self._make_progress_bar(percent)
                                    try:
                                        minutes, seconds = divmod(int(eta_seconds), 60)
                                        eta_str = f"{minutes:02d}:{seconds:02d}"
                                    except (ValueError, TypeError):
                                        eta_str = "æœªçŸ¥"
                                    downloaded_mb_str = f"{downloaded_mb:.2f}"
                                    total_mb_str = f"{total_mb:.2f}"
                                    speed_mb_s_str = f"{speed_mb_s:.2f}"
                                    percent_str = f"{percent:.1f}"
                                    progress_text += (
                                        f"ğŸ“ æ–‡ä»¶: `{escape_num(filename)}`\n"
                                        f"ğŸ’¾ å¤§å°: `{escape_num(downloaded_mb_str)}MB / {escape_num(total_mb_str)}MB`\n"
                                        f"âš¡ é€Ÿåº¦: `{escape_num(speed_mb_s_str)}MB/s`\n"
                                        f"â³ é¢„è®¡å‰©ä½™: `{escape_num(eta_str)}`\n"
                                        f"ğŸ“Š è¿›åº¦: {bar} `{escape_num(percent_str)}%`"
                                    )
                                else:
                                    downloaded_mb = (
                                        downloaded_bytes / (1024 * 1024)
                                        if downloaded_bytes > 0
                                        else 0
                                    )
                                    speed_mb_s = (
                                        speed_bytes_s / (1024 * 1024)
                                        if speed_bytes_s
                                        else 0
                                    )
                                    downloaded_mb_str = f"{downloaded_mb:.2f}"
                                    speed_mb_s_str = f"{speed_mb_s:.2f}"
                                    progress_text += (
                                        f"ğŸ“ æ–‡ä»¶: `{escape_num(filename)}`\n"
                                        f"ğŸ’¾ å¤§å°: `{escape_num(downloaded_mb_str)}MB`\n"
                                        f"âš¡ é€Ÿåº¦: `{escape_num(speed_mb_s_str)}MB/s`\n"
                                        f"ğŸ“Š è¿›åº¦: ä¸‹è½½ä¸­..."
                                    )
                            now = _time.time()
                            # æ›´é¢‘ç¹çš„è¿›åº¦æ›´æ–°ï¼šæ¯5%è¿›åº¦å˜åŒ–æˆ–æ¯1ç§’æ›´æ–°ä¸€æ¬¡
                            if (
                                abs(percent - last_update["percent"]) >= 5
                            ) or (now - last_update["time"] > 1):
                                if progress_text != last_update["text"]:
                                    last_update["percent"] = percent
                                    last_update["time"] = now
                                    last_update["text"] = progress_text
                                    import asyncio

                                    # ç§»é™¤è°ƒè¯•æ—¥å¿—ï¼Œç›´æ¥å¤„ç†è¿›åº¦æ›´æ–°

                                    # ğŸ¯ æ™ºèƒ½ TG æ¶ˆæ¯æ›´æ–°ï¼šä» message_updater ä¸­æå– TG å¯¹è±¡
                                    tg_updated = False

                                    # æ–¹æ³•1ï¼šå¦‚æœç›´æ¥ä¼ é€’äº† TG å¯¹è±¡ï¼Œä¼˜å…ˆä½¿ç”¨
                                    if status_message and loop:
                                        try:
                                            def fix_markdown_v2(text):
                                                # ç®€åŒ–ç‰ˆæœ¬ï¼šç§»é™¤äº†ç²—ä½“æ ‡è®°ï¼Œç›´æ¥è½¬ä¹‰æ‰€æœ‰ç‰¹æ®Šå­—ç¬¦
                                                text = text.replace('\\', '')
                                                special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
                                                for char in special_chars:
                                                    text = text.replace(char, f'\\{char}')
                                                return text

                                            fixed_text = fix_markdown_v2(progress_text)
                                            future = asyncio.run_coroutine_threadsafe(
                                                status_message.edit_text(fixed_text, parse_mode="MarkdownV2"),
                                                loop
                                            )
                                            future.result(timeout=3.0)
                                            tg_updated = True
                                        except:
                                            try:
                                                clean_text = progress_text.replace('\\', '')
                                                future = asyncio.run_coroutine_threadsafe(
                                                    status_message.edit_text(clean_text),
                                                    loop
                                                )
                                                future.result(timeout=3.0)
                                                tg_updated = True
                                            except:
                                                tg_updated = False
                                    else:
                                        tg_updated = False

                                    # æ–¹æ³•3ï¼šä¿®å¤ message_updater è°ƒç”¨
                                    if not tg_updated and message_updater:
                                        try:
                                            # ğŸ”§ ä¿®å¤ï¼šåˆ›å»ºä¸€ä¸ªåŒ…è£…å‡½æ•°ï¼Œè®© message_updater èƒ½å¤„ç†å­—ç¬¦ä¸²
                                            def fixed_message_updater(text):
                                                """ä¿®å¤çš„æ¶ˆæ¯æ›´æ–°å™¨ï¼Œèƒ½å¤„ç†å­—ç¬¦ä¸²ç±»å‹çš„è¿›åº¦"""
                                                # ä» message_updater çš„é—­åŒ…ä¸­æå–å¿…è¦çš„å¯¹è±¡
                                                if hasattr(message_updater, '__closure__') and message_updater.__closure__:
                                                    for cell in message_updater.__closure__:
                                                        try:
                                                            value = cell.cell_contents
                                                            # æ‰¾åˆ° TG æ¶ˆæ¯å¯¹è±¡
                                                            if hasattr(value, 'edit_text') and hasattr(value, 'chat_id'):
                                                                status_msg = value
                                                                # æ‰¾åˆ°äº‹ä»¶å¾ªç¯
                                                                for cell2 in message_updater.__closure__:
                                                                    try:
                                                                        value2 = cell2.cell_contents
                                                                        if hasattr(value2, 'run_until_complete'):
                                                                            event_loop = value2
                                                                            # ç›´æ¥æ›´æ–° TG æ¶ˆæ¯
                                                                            def fix_markdown_v2(text):
                                                                                text = text.replace('\\', '')
                                                                                special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
                                                                                for char in special_chars:
                                                                                    text = text.replace(char, f'\\{char}')
                                                                                return text

                                                                            try:
                                                                                fixed_text = fix_markdown_v2(text)
                                                                                future = asyncio.run_coroutine_threadsafe(
                                                                                    status_msg.edit_text(fixed_text, parse_mode="MarkdownV2"),
                                                                                    event_loop
                                                                                )
                                                                                future.result(timeout=3.0)
                                                                                return True
                                                                            except:
                                                                                # é™çº§åˆ°æ™®é€šæ–‡æœ¬
                                                                                clean_text = text.replace('\\', '')
                                                                                future = asyncio.run_coroutine_threadsafe(
                                                                                    status_msg.edit_text(clean_text),
                                                                                    event_loop
                                                                                )
                                                                                future.result(timeout=3.0)
                                                                                return True
                                                                    except:
                                                                        continue
                                                        except:
                                                            continue

                                                # å¦‚æœæå–å¤±è´¥ï¼Œè°ƒç”¨åŸå‡½æ•°ï¼ˆä½†è¿™ä¼šå¤±è´¥ï¼‰
                                                logger.warning(f"âš ï¸ æ— æ³•ä» message_updater æå– TG å¯¹è±¡ï¼Œå°è¯•åŸè°ƒç”¨")
                                                return False

                                            # ä½¿ç”¨ä¿®å¤çš„å‡½æ•°
                                            if not fixed_message_updater(progress_text):
                                                logger.warning(f"âš ï¸ ä¿®å¤çš„ message_updater å¤±è´¥")

                                        except Exception as e:
                                            logger.error(f"âŒ è°ƒç”¨ä¿®å¤çš„ message_updater å¤±è´¥: {e}")

                                    if not tg_updated and not message_updater:
                                        logger.warning(f"âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ¶ˆæ¯æ›´æ–°æ–¹æ³•")
                        elif d.get("status") == "finished":
                            progress_data["downloaded_videos"] += 1
                            logger.info(
                                f"âœ… æ’­æ”¾åˆ—è¡¨ {progress_data['playlist_title']} ç¬¬ {progress_data['downloaded_videos']} ä¸ªè§†é¢‘ä¸‹è½½å®Œæˆ"
                            )

                            # ç›‘æ§æ–‡ä»¶åˆå¹¶çŠ¶æ€
                            if 'filename' in d:
                                filename = d['filename']
                                if filename.endswith('.part'):
                                    logger.warning(f"âš ï¸ æ–‡ä»¶åˆå¹¶å¯èƒ½å¤±è´¥: {filename}")
                                else:
                                    logger.info(f"âœ… æ–‡ä»¶ä¸‹è½½å¹¶åˆå¹¶æˆåŠŸ: {filename}")

                    return progress_callback

                # ä¸‹è½½æ’­æ”¾åˆ—è¡¨
                result = await self._download_youtube_playlist_with_progress(
                    playlist_id,
                    channel_path,
                    create_playlist_progress_callback(playlist_progress_data),
                )

                if result.get("success"):
                    downloaded_playlists.append(
                        result.get("playlist_title", playlist_title)
                    )

                    # æ›´æ–°å®ŒæˆçŠ¶æ€æ¶ˆæ¯
                    if message_updater:
                        try:
                            if asyncio.iscoroutinefunction(message_updater):
                                if result.get("already_downloaded", False):
                                    await message_updater(
                                        f"âœ… ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{playlist_title} (å·²å­˜åœ¨)"
                                    )
                                else:
                                    await message_updater(
                                        f"âœ… ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{playlist_title} (ä¸‹è½½å®Œæˆ)"
                                    )
                            else:
                                if result.get("already_downloaded", False):
                                    message_updater(
                                        f"âœ… ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{playlist_title} (å·²å­˜åœ¨)"
                                    )
                                else:
                                    message_updater(
                                        f"âœ… ç¬¬ {i}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼š{playlist_title} (ä¸‹è½½å®Œæˆ)"
                                    )
                        except Exception as e:
                            logger.warning(f"æ›´æ–°å®ŒæˆçŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")

                    # è·å–è§†é¢‘æ•°é‡ï¼Œå¦‚æœresultä¸­æ²¡æœ‰ï¼Œåˆ™é€šè¿‡æ‰«æç›®å½•è®¡ç®—
                    video_count = result.get("video_count", 0)
                    if video_count == 0:
                        # å¤‡ç”¨æ–¹æ³•ï¼šæ‰«ææ’­æ”¾åˆ—è¡¨ç›®å½•è®¡ç®—å®é™…æ–‡ä»¶æ•°é‡
                        playlist_path = Path(result.get("download_path", ""))
                        if playlist_path.exists():
                            video_files = (
                                list(playlist_path.glob("*.mp4"))
                                + list(playlist_path.glob("*.mkv"))
                                + list(playlist_path.glob("*.webm"))
                            )
                            video_count = len(video_files)
                            logger.info(f"ğŸ“Š é€šè¿‡æ‰«æç›®å½•è®¡ç®—æ’­æ”¾åˆ—è¡¨ '{playlist_title}' çš„é›†æ•°: {video_count}")
                    
                    playlist_stats.append(
                        {
                            "title": result.get("playlist_title", playlist_title),
                            "video_count": video_count,
                            "download_path": result.get("download_path", ""),
                            "total_size_mb": result.get("total_size_mb", 0),
                            "resolution": result.get("resolution", "æœªçŸ¥"),
                            # æ·»åŠ PARTæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
                            "success_count": result.get("success_count", video_count),
                            "part_count": result.get("part_count", 0),
                        }
                    )
                    # æ›´æ–°å…¨å±€è¿›åº¦
                    global_progress["completed_playlists"] += 1
                    logger.info(f"    âœ… æ’­æ”¾åˆ—è¡¨ '{playlist_title}' ä¸‹è½½æˆåŠŸï¼Œé›†æ•°: {video_count}")
                else:
                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                    logger.error(
                        f"    âŒ æ’­æ”¾åˆ—è¡¨ '{playlist_title}' ä¸‹è½½å¤±è´¥: {error_msg}"
                    )

            logger.info(
                f"ğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡: {len(downloaded_playlists)}/{len(playlist_entries)} ä¸ªæ’­æ”¾åˆ—è¡¨æˆåŠŸ"
            )
            if not downloaded_playlists:
                logger.error("âŒ æ‰€æœ‰æ’­æ”¾åˆ—è¡¨éƒ½ä¸‹è½½å¤±è´¥äº†")
                if message_updater:
                    try:
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater("âŒ é¢‘é“ä¸­çš„æ‰€æœ‰æ’­æ”¾åˆ—è¡¨éƒ½ä¸‹è½½å¤±è´¥äº†ã€‚")
                        else:
                            message_updater("âŒ é¢‘é“ä¸­çš„æ‰€æœ‰æ’­æ”¾åˆ—è¡¨éƒ½ä¸‹è½½å¤±è´¥äº†ã€‚")
                    except Exception as e:
                        logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
                return {"success": False, "error": "é¢‘é“ä¸­çš„æ‰€æœ‰æ’­æ”¾åˆ—è¡¨éƒ½ä¸‹è½½å¤±è´¥äº†ã€‚"}
            logger.info("ğŸ‰ é¢‘é“æ’­æ”¾åˆ—è¡¨ä¸‹è½½ä»»åŠ¡å®Œæˆ!")

            # æ„å»ºè¯¦ç»†çš„å®Œæˆç»Ÿè®¡ä¿¡æ¯
            total_videos = sum(stat["video_count"] for stat in playlist_stats)
            total_size_mb = sum(stat["total_size_mb"] for stat in playlist_stats)

            # æŒ‰å…ˆè·å–ä¸‹è½½åˆ—è¡¨çš„æ–‡ä»¶æŸ¥æ‰¾é€»è¾‘ï¼šæ ¹æ®ä¸‹è½½åˆ—è¡¨ä¸­çš„æ–‡ä»¶åç²¾ç¡®æŸ¥æ‰¾
            downloaded_files = []
            for stat in playlist_stats:
                playlist_path = Path(stat["download_path"])
                if playlist_path.exists():
                    # å…ˆè·å–è¯¥æ’­æ”¾åˆ—è¡¨çš„ä¸‹è½½ä¿¡æ¯ï¼Œç„¶åæ ¹æ®æ–‡ä»¶åç²¾ç¡®æŸ¥æ‰¾
                    try:
                        # è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ä»¥è·å–é¢„æœŸçš„æ–‡ä»¶ååˆ—è¡¨
                        info_opts = {
                            "quiet": True,
                            "extract_flat": True,
                            "ignoreerrors": True,
                        }
                        if self.proxy_host:
                            info_opts["proxy"] = self.proxy_host
                        if self.youtube_cookies_path and os.path.exists(
                            self.youtube_cookies_path
                        ):
                            info_opts["cookiefile"] = self.youtube_cookies_path

                        # ä»æ’­æ”¾åˆ—è¡¨è·¯å¾„ä¸­æå–playlist_id
                        playlist_id = (
                            playlist_path.name.split("_")[-1]
                            if "_" in playlist_path.name
                            else ""
                        )
                        if not playlist_id:
                            # å¦‚æœæ— æ³•ä»è·¯å¾„æå–ï¼Œå°è¯•ä»statä¸­è·å–
                            playlist_id = stat.get("playlist_id", "")

                        if playlist_id:
                            with yt_dlp.YoutubeDL(info_opts) as ydl:
                                playlist_info = ydl.extract_info(
                                    f"https://www.youtube.com/playlist?list={playlist_id}",
                                    download=False,
                                )
                                entries = playlist_info.get("entries", [])

                                # æ ¹æ®ä¸‹è½½åˆ—è¡¨ä¸­çš„æ¡ç›®æŸ¥æ‰¾å¯¹åº”çš„æ–‡ä»¶
                                for i, entry in enumerate(entries, 1):
                                    if entry:
                                        # æ„é€ é¢„æœŸçš„æ–‡ä»¶å
                                        title = entry.get("title", f"Video_{i}")
                                        safe_title = re.sub(r'[\\/:*?"<>|]', "", title)[
                                            :60
                                        ]
                                        expected_filename = f"{i}. {safe_title}.mp4"

                                        # ç²¾ç¡®æŸ¥æ‰¾è¯¥æ–‡ä»¶
                                        expected_file_path = (
                                            playlist_path / expected_filename
                                        )
                                        if expected_file_path.exists():
                                            file_size = (
                                                expected_file_path.stat().st_size
                                                / (1024 * 1024)
                                            )  # MB
                                            downloaded_files.append(
                                                {
                                                    "filename": expected_filename,
                                                    "path": str(expected_file_path),
                                                    "size_mb": file_size,
                                                    "playlist": stat["title"],
                                                    "video_title": title,
                                                }
                                            )
                                            logger.info(
                                                f"âœ… æ‰¾åˆ°æ–‡ä»¶: {expected_filename} ({file_size:.2f}MB)")
                                        else:
                                            # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
                                            logger.warning(
                                                f"âš ï¸ æœªæ‰¾åˆ°é¢„æœŸæ–‡ä»¶: {expected_filename}"
                                            )
                                            logger.info(f"ğŸ” å°è¯•æ¨¡ç³ŠåŒ¹é…æŸ¥æ‰¾æ–‡ä»¶...")

                                            # æŸ¥æ‰¾åŒ…å«ç¼–å·å’Œéƒ¨åˆ†æ ‡é¢˜çš„æ–‡ä»¶
                                            # ä½¿ç”¨å‰20ä¸ªå­—ç¬¦è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
                                            pattern = f"{i:02d}.*{safe_title[:20]}*"
                                            matching_files = list(
                                                playlist_path.glob(f"{i:02d}.*")
                                            )

                                            if matching_files:
                                                # æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶
                                                actual_file = matching_files[0]
                                                file_size = (
                                                    actual_file.stat().st_size
                                                    / (1024 * 1024)
                                                )  # MB
                                                downloaded_files.append(
                                                    {
                                                        "filename": actual_file.name,
                                                        "path": str(actual_file),
                                                        "size_mb": file_size,
                                                        "playlist": stat["title"],
                                                        "video_title": title,
                                                    }
                                                )
                                                logger.info(
                                                    f"âœ… é€šè¿‡æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°æ–‡ä»¶: {actual_file.name}"
                                                )
                                            else:
                                                logger.warning(
                                                    f"âš ï¸ æ¨¡ç³ŠåŒ¹é…ä¹Ÿæœªæ‰¾åˆ°æ–‡ä»¶ï¼Œç¼–å·: {i}, æ ‡é¢˜: {safe_title}"
                                                )
                    except Exception as e:
                        logger.warning(f"è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯å¤±è´¥: {e}")
                        # å¦‚æœè·å–åˆ—è¡¨å¤±è´¥ï¼Œå›é€€åˆ°æ‰«æç›®å½•
                        video_files = (
                            list(playlist_path.glob("*.mp4"))
                            + list(playlist_path.glob("*.mkv"))
                            + list(playlist_path.glob("*.webm"))
                        )
                        for video_file in video_files:
                            file_size = video_file.stat().st_size / (1024 * 1024)  # MB
                            downloaded_files.append(
                                {
                                    "filename": video_file.name,
                                    "path": str(video_file),
                                    "size_mb": file_size,
                                    "playlist": stat["title"],
                                }
                            )

            # è®¡ç®—æ€»æ–‡ä»¶å¤§å°å’ŒPARTæ–‡ä»¶ç»Ÿè®¡
            total_size_mb = sum(stat['total_size_mb'] for stat in playlist_stats)
            total_size_gb = total_size_mb / 1024

            # è®¡ç®—æ€»çš„æˆåŠŸå’Œæœªå®Œæˆæ–‡ä»¶æ•°é‡
            total_success_count = sum(stat.get('success_count', stat.get('video_count', 0)) for stat in playlist_stats)
            total_part_count = sum(stat.get('part_count', 0) for stat in playlist_stats)

            # æ ¼å¼åŒ–æ€»å¤§å°æ˜¾ç¤º - åªæ˜¾ç¤ºä¸€ä¸ªå•ä½
            if total_size_gb >= 1.0:
                total_size_str = f"{total_size_gb:.2f}GB"
            else:
                total_size_str = f"{total_size_mb:.2f}MB"

            # æ„å»ºå®Œæˆæ¶ˆæ¯
            completion_text = (
                f"ğŸ“º YouTubeé¢‘é“æ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆ\n\n"
                f"ğŸ“º é¢‘é“: `{self._escape_markdown(channel_name)}`\n"
                f"ğŸ“Š æ’­æ”¾åˆ—è¡¨æ•°é‡: `{self._escape_markdown(str(len(downloaded_playlists)))}`\n\n"
                f"å·²ä¸‹è½½çš„æ’­æ”¾åˆ—è¡¨:\n"
            )

            for i, stat in enumerate(playlist_stats, 1):
                completion_text += (
                    f"  {self._escape_markdown(str(i))}. {self._escape_markdown(stat['title'])} ({self._escape_markdown(str(stat['video_count']))} é›†)\n"
                )

            # æ„å»ºä¸‹è½½ç»Ÿè®¡ä¿¡æ¯
            stats_text = f"âœ… æˆåŠŸ: `{total_success_count} ä¸ª`"
            if total_part_count > 0:
                stats_text += f"\nâš ï¸ æœªå®Œæˆ: `{total_part_count} ä¸ª`"
                stats_text += f"\nğŸ’¡ æç¤º: å‘ç°æœªå®Œæˆæ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦é‡æ–°ä¸‹è½½"

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ã€æ€»å¤§å°å’Œä¿å­˜ä½ç½®ï¼ˆæ”¾åœ¨æœ€åï¼‰
            completion_text += (
                f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:\n{stats_text}\n"
                f"ğŸ’¾ æ–‡ä»¶æ€»å¤§å°: `{self._escape_markdown(total_size_str)}`\n"
                f"ğŸ“‚ ä¿å­˜ä½ç½®: `{self._escape_markdown(str(channel_path))}`"
            )

            if message_updater:
                try:
                    if asyncio.iscoroutinefunction(message_updater):
                        await message_updater(completion_text)
                    else:
                        message_updater(completion_text)
                except Exception as e:
                    logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")

            return {
                "success": True,
                "is_channel": True,
                "channel_title": channel_name,
                    "download_path": str(channel_path),
                    "playlists_downloaded": downloaded_playlists,
                    "playlist_stats": playlist_stats,
                    "total_videos": total_videos,
                    "total_size_mb": total_size_mb,
                    "downloaded_files": downloaded_files,
                }

        except Exception as e:
            logger.error(f"âŒ YouTubeé¢‘é“æ’­æ”¾åˆ—è¡¨ä¸‹è½½å¤±è´¥: {e}")
            import traceback

            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            if message_updater:
                try:
                    if asyncio.iscoroutinefunction(message_updater):
                        await message_updater(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
                    else:
                        message_updater(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
                except Exception as e2:
                    logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e2}")
            return {"success": False, "error": str(e)}

    def smart_download_bilibili(
        self, url: str, download_path: str, progress_callback=None, auto_playlist=False
    ):
        """æ™ºèƒ½ä¸‹è½½Bç«™è§†é¢‘ï¼Œæ”¯æŒå•è§†é¢‘ã€åˆ†é›†ã€åˆé›†"""
        import re
        import subprocess
        import os
        import threading
        from pathlib import Path

        logger.info(f"ğŸ¬ å¼€å§‹æ™ºèƒ½ä¸‹è½½Bç«™è§†é¢‘: {url}")
        logger.info(f"ğŸ“ ä¸‹è½½è·¯å¾„: {download_path}")
        logger.info(f"ğŸ”„ è‡ªåŠ¨ä¸‹è½½å…¨é›†: {auto_playlist}")

        # ä¿å­˜åŸå§‹å·¥ä½œç›®å½•
        original_cwd = os.getcwd()
        logger.info(f"ğŸ“ åŸå§‹å·¥ä½œç›®å½•: {original_cwd}")

        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºBç«™ç”¨æˆ·åˆ—è¡¨URL
            is_list, uid, list_id = self.is_bilibili_list_url(url)
            if is_list:
                logger.info(f"ğŸ“‹ æ£€æµ‹åˆ°Bç«™ç”¨æˆ·åˆ—è¡¨: UID={uid}, ListID={list_id}")

                # ä½¿ç”¨BVå·å¾ªç¯æ³•ä¸‹è½½ç”¨æˆ·åˆ—è¡¨
                bv_list = self.get_bilibili_list_videos(uid, list_id)
                if not bv_list:
                    return {"status": "failure", "error": "æ— æ³•è·å–ç”¨æˆ·åˆ—è¡¨è§†é¢‘ä¿¡æ¯"}

                logger.info(f"ğŸ“‹ è·å–åˆ° {len(bv_list)} ä¸ªè§†é¢‘")

                # è·å–åˆ—è¡¨æ ‡é¢˜
                try:
                    list_info = self.get_bilibili_list_info(uid, list_id)
                    playlist_title = list_info.get("title", f"BilibiliList-{list_id}")
                except BaseException:
                    playlist_title = f"BilibiliList-{list_id}"
                safe_playlist_title = re.sub(
                    r'[\\/:*?"<>|]', "_", playlist_title
                ).strip()
                final_download_path = Path(download_path) / safe_playlist_title
                final_download_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"ğŸ“ ä¸ºåˆé›†åˆ›å»ºä¸‹è½½ç›®å½•: {final_download_path}")
                # ä½¿ç”¨yt-dlp printè®°å½•æ–‡ä»¶åçš„æ–¹æ¡ˆï¼ˆä¸å¤šPä¸‹è½½ä¿æŒä¸€è‡´ï¼‰
                success_count = 0
                downloaded_files = []  # è®°å½•å®é™…ä¸‹è½½çš„æ–‡ä»¶ä¿¡æ¯

                for idx, (bv, title) in enumerate(bv_list, 1):
                    safe_title = re.sub(r'[\\/:*?"<>|]', "", title)[:60]
                    # ä½¿ç”¨ç»å¯¹è·¯å¾„æ„å»ºè¾“å‡ºæ¨¡æ¿
                    outtmpl = str(
                        final_download_path / f"{idx:02d}. {safe_title}.%(ext)s"
                    )

                    # æ›´æ–°ä¸‹è½½è¿›åº¦æ˜¾ç¤º
                    if progress_callback:
                        progress_callback({
                            'status': 'downloading',
                            'filename': f'{idx:02d}. {safe_title}',
                            '_percent_str': f'{idx}/{len(bv_list)}',
                            '_eta_str': f'ç¬¬{idx}ä¸ªï¼Œå…±{len(bv_list)}ä¸ª',
                            'info_dict': {'title': title}
                        })

                    # 1. å…ˆç”¨yt-dlp printè·å–å®é™…æ–‡ä»¶å
                    video_url = f"https://www.bilibili.com/video/{bv}"
                    cmd_print = [
                        "yt-dlp", "--print", "filename", "-o", outtmpl, video_url
                    ]

                    try:
                        print_result = subprocess.run(cmd_print, capture_output=True, text=True, cwd=str(final_download_path))
                        if print_result.returncode == 0:
                            full_expected_path = print_result.stdout.strip()
                            # åªä¿ç•™æ–‡ä»¶åéƒ¨åˆ†ï¼Œä¸åŒ…å«è·¯å¾„
                            expected_filename = os.path.basename(full_expected_path)
                            logger.info(f"ğŸ“ é¢„æœŸæ–‡ä»¶å: {expected_filename}")
                        else:
                            # å¦‚æœprintå¤±è´¥ï¼Œä½¿ç”¨æ„é€ çš„æ–‡ä»¶å
                            expected_filename = f"{idx:02d}. {safe_title}.mp4"
                            logger.warning(f"âš ï¸ printæ–‡ä»¶åå¤±è´¥ï¼Œä½¿ç”¨æ„é€ æ–‡ä»¶å: {expected_filename}")
                    except Exception as e:
                        expected_filename = f"{idx:02d}. {safe_title}.mp4"
                        logger.warning(f"âš ï¸ printæ–‡ä»¶åå¼‚å¸¸: {e}ï¼Œä½¿ç”¨æ„é€ æ–‡ä»¶å: {expected_filename}")

                    # 2. æ‰§è¡Œä¸‹è½½ï¼ˆä½¿ç”¨yt-dlp Python APIæ”¯æŒè¿›åº¦å›è°ƒï¼‰
                    ydl_opts_single = {
                        'outtmpl': outtmpl,
                        'merge_output_format': 'mp4',
                        'quiet': False,
                        'no_warnings': False,
                        'progress_hooks': [
                            lambda d: progress_callback(d) if progress_callback else None
                        ],
                    }

                    # æ·»åŠ ä»£ç†å’Œcookiesé…ç½®
                    if self.proxy_host:
                        ydl_opts_single['proxy'] = self.proxy_host
                    if self.b_cookies_path and os.path.exists(self.b_cookies_path):
                        ydl_opts_single['cookiefile'] = self.b_cookies_path

                    logger.info(f"ğŸš€ ä¸‹è½½ç¬¬{idx}ä¸ª: {bv} - {title}")
                    logger.info(f"ğŸ“ æ–‡ä»¶åæ¨¡æ¿: {outtmpl}")

                    try:
                        # ä½¿ç”¨yt-dlp Python APIï¼Œæ”¯æŒè¿›åº¦å›è°ƒ
                        with yt_dlp.YoutubeDL(ydl_opts_single) as ydl:
                            ydl.download([video_url])
                        success_count += 1
                        logger.info(f"âœ… ç¬¬{idx}ä¸ªä¸‹è½½æˆåŠŸ")

                        # 3. æ ¹æ®é¢„æœŸæ–‡ä»¶åæŸ¥æ‰¾å®é™…æ–‡ä»¶
                        expected_path = final_download_path / expected_filename
                        if expected_path.exists():
                            size_mb = os.path.getsize(expected_path) / (1024 * 1024)
                            media_info = self.get_media_info(str(expected_path))
                            downloaded_files.append({
                                'filename': expected_filename,
                                'size_mb': size_mb,
                                'resolution': media_info.get('resolution', 'æœªçŸ¥'),
                                'abr': media_info.get('bit_rate')
                            })
                            logger.info(f"ğŸ“ è®°å½•æ–‡ä»¶: {expected_filename} ({size_mb:.1f}MB)")
                        else:
                            logger.warning(f"âš ï¸ é¢„æœŸæ–‡ä»¶ä¸å­˜åœ¨: {expected_filename}")
                    except Exception as e:
                        logger.error(f"âŒ ç¬¬{idx}ä¸ªä¸‹è½½å¤±è´¥: {e}")

                logger.info(
                    f"ğŸ‰ BVå·å¾ªç¯æ³•ä¸‹è½½å®Œæˆ: {success_count}/{len(bv_list)} ä¸ªæˆåŠŸ"
                )

                if success_count > 0:
                    # ä½¿ç”¨å·²è®°å½•çš„æ–‡ä»¶ä¿¡æ¯ï¼ˆä¸éå†ç›®å½•ï¼‰
                    total_size_mb = sum(file_info['size_mb'] for file_info in downloaded_files)
                    all_resolutions = {file_info['resolution'] for file_info in downloaded_files if file_info['resolution'] != 'æœªçŸ¥'}

                    filename_list = [info['filename'] for info in downloaded_files]
                    filename_display = '\n'.join([f"  {i+1:02d}. {name}" for i, name in enumerate(filename_list)])
                    resolution_display = ', '.join(sorted(all_resolutions)) if all_resolutions else 'æœªçŸ¥'

                    logger.info(f"ğŸ“Š ç”¨æˆ·åˆ—è¡¨ä¸‹è½½ç»Ÿè®¡: {len(downloaded_files)}ä¸ªæ–‡ä»¶, æ€»å¤§å°{total_size_mb:.1f}MB")

                    return {
                        "status": "success",
                        "video_type": "playlist",
                        "count": success_count,
                        "playlist_title": safe_playlist_title,
                        "download_path": str(final_download_path),
                        # ä½¿ç”¨é¢„æœŸæ–‡ä»¶ä¿¡æ¯ï¼Œé¿å…ç›®å½•éå†
                        "is_playlist": True,
                        "file_count": len(downloaded_files),
                        "total_size_mb": total_size_mb,
                        "files": downloaded_files,
                        "platform": "bilibili",
                        "filename": filename_display,
                        "size_mb": total_size_mb,
                        "resolution": resolution_display,
                        "episode_count": len(downloaded_files)
                    }
                else:
                    return {"status": "failure", "error": "ç”¨æˆ·åˆ—è¡¨è§†é¢‘å…¨éƒ¨ä¸‹è½½å¤±è´¥"}
            # ä¸‹é¢æ˜¯åŸæœ‰çš„Bç«™å•è§†é¢‘/åˆé›†/åˆ†é›†ä¸‹è½½é€»è¾‘
            logger.info(f"ğŸ” æ­£åœ¨æ£€æŸ¥è§†é¢‘ç±»å‹: {url}")

            # å¤„ç†çŸ­é“¾æ¥ï¼Œæå–BVå·
            original_url = url
            if "b23.tv" in url or "b23.wtf" in url:
                logger.info("ğŸ”„ æ£€æµ‹åˆ°Bç«™çŸ­é“¾æ¥ï¼Œå°è¯•æå–BVå·...")
                try:
                    # å…ˆè·å–é‡å®šå‘åçš„URL
                    temp_opts = {
                        "quiet": True,
                        "no_warnings": True,
                    }
                    with yt_dlp.YoutubeDL(temp_opts) as ydl:
                        temp_info = ydl.extract_info(url, download=False)

                    if temp_info.get("webpage_url"):
                        redirected_url = temp_info["webpage_url"]
                        logger.info(f"ğŸ”„ çŸ­é“¾æ¥é‡å®šå‘åˆ°: {redirected_url}")

                        # ä»é‡å®šå‘URLä¸­æå–BVå·
                        bv_match = re.search(r"BV[0-9A-Za-z]+", redirected_url)
                        if bv_match:
                            bv_id = bv_match.group()
                            # æ„é€ åŸå§‹é“¾æ¥ï¼ˆä¸å¸¦åˆ†Pæ ‡è¯†ï¼‰
                            original_url = f"https://www.bilibili.com/video/{bv_id}/"
                            logger.info(f"ğŸ”„ æå–åˆ°BVå·: {bv_id}")
                            logger.info(f"ğŸ”„ ä½¿ç”¨åŸå§‹é“¾æ¥: {original_url}")
                        else:
                            logger.warning("âš ï¸ æ— æ³•ä»é‡å®šå‘URLä¸­æå–BVå·")
                    else:
                        logger.warning("âš ï¸ çŸ­é“¾æ¥é‡å®šå‘å¤±è´¥")
                except Exception as e:
                    logger.warning(f"âš ï¸ å¤„ç†çŸ­é“¾æ¥æ—¶å‡ºé”™: {e}")

            # ä¿®æ”¹æ£€æµ‹é€»è¾‘ï¼Œç¡®ä¿èƒ½æ­£ç¡®è¯†åˆ«å¤šPè§†é¢‘
            if auto_playlist:
                # å¼€å¯è‡ªåŠ¨ä¸‹è½½å…¨é›†æ—¶ï¼Œå¼ºåˆ¶æ£€æµ‹playlist
                check_opts = {
                    "quiet": True,
                    "flat_playlist": True,
                    "extract_flat": True,
                    "print": "%(id)s %(title)s",
                    "noplaylist": False,  # å…³é”®ï¼šä¸é˜»æ­¢playlistæ£€æµ‹
                    "yes_playlist": True,  # å…³é”®ï¼šå…è®¸playlistæ£€æµ‹
                    "extract_flat": True,  # ç¡®ä¿æå–æ‰€æœ‰æ¡ç›®
                }
            else:
                # å…³é—­è‡ªåŠ¨ä¸‹è½½å…¨é›†æ—¶ï¼Œé˜»æ­¢playlistæ£€æµ‹
                check_opts = {
                    "quiet": True,
                    "flat_playlist": True,
                    "extract_flat": True,
                    "print": "%(id)s %(title)s",
                    "noplaylist": True,  # é˜»æ­¢playlistæ£€æµ‹
                }

            # ä½¿ç”¨å¤„ç†åçš„URLè¿›è¡Œæ£€æµ‹
            with yt_dlp.YoutubeDL(check_opts) as ydl:
                info = ydl.extract_info(original_url, download=False)

            entries = info.get("entries", [])
            count = len(entries) if entries else 1
            logger.info(f"ğŸ“‹ æ£€æµ‹åˆ° {count} ä¸ªè§†é¢‘")

            # å¦‚æœåªæœ‰ä¸€ä¸ªè§†é¢‘ï¼Œå°è¯•anthologyæ£€æµ‹å’Œå¼ºåˆ¶playlistæ£€æµ‹
            if count == 1:
                # ç‰¹æ®Šæ£€æµ‹ï¼šä½¿ç”¨æ¨¡æ‹Ÿä¸‹è½½æ£€æµ‹anthology
                logger.info("ğŸ” ä½¿ç”¨æ¨¡æ‹Ÿä¸‹è½½æ£€æµ‹anthology...")
                anthology_detected = False
                try:
                    # æ•è·yt-dlpçš„è¾“å‡ºæ¥æ£€æµ‹anthology
                    cmd_simulate = ['yt-dlp', '--simulate', '--verbose', original_url]
                    result = subprocess.run(cmd_simulate, capture_output=True, text=True)
                    output = result.stdout + result.stderr

                    if 'extracting videos in anthology' in output.lower():
                        anthology_detected = True
                        logger.info("âœ… æ£€æµ‹åˆ°anthologyå…³é”®è¯ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆé›†")
                    else:
                        logger.info("âŒ æœªæ£€æµ‹åˆ°anthologyå…³é”®è¯")

                except Exception as e:
                    logger.warning(f"âš ï¸ anthologyæ£€æµ‹å¤±è´¥: {e}")

                # å¦‚æœæ£€æµ‹åˆ°anthologyæˆ–å¼€å¯äº†auto_playlistï¼Œå°è¯•å¼ºåˆ¶æ£€æµ‹playlist
                if anthology_detected or auto_playlist:
                    if anthology_detected:
                        logger.info("ğŸ”„ æ£€æµ‹åˆ°anthologyï¼Œå¼ºåˆ¶ä½¿ç”¨åˆé›†æ¨¡å¼")
                    else:
                        logger.info("ğŸ”„ å¼€å¯è‡ªåŠ¨ä¸‹è½½å…¨é›†ï¼Œå°è¯•å¼ºåˆ¶æ£€æµ‹playlist...")

                    force_check_opts = {
                        "quiet": True,
                        "flat_playlist": True,
                        "extract_flat": True,
                        "print": "%(id)s %(title)s",
                        "noplaylist": False,
                        "yes_playlist": True,
                    }

                    try:
                        with yt_dlp.YoutubeDL(force_check_opts) as ydl:
                            force_info = ydl.extract_info(original_url, download=False)
                        force_entries = force_info.get("entries", [])
                        force_count = len(force_entries) if force_entries else 1

                        if force_count > count:
                            logger.info(f"ğŸ”„ å¼ºåˆ¶æ£€æµ‹æˆåŠŸï¼æ£€æµ‹åˆ° {force_count} ä¸ªè§†é¢‘")
                            entries = force_entries
                            count = force_count
                            info = force_info
                        elif anthology_detected:
                            # æ£€æµ‹åˆ°anthologyï¼Œä½†éœ€è¦è¿›ä¸€æ­¥ç¡®è®¤æ˜¯å¦çœŸçš„æ˜¯å¤šé›†
                            logger.info("ğŸ”„ anthologyæ£€æµ‹æˆåŠŸï¼Œä½†éœ€è¦ç¡®è®¤æ˜¯å¦çœŸçš„æ˜¯å¤šé›†")
                            # ä¸å¼ºåˆ¶è®¾ç½®countï¼Œä¿æŒåŸæœ‰çš„æ£€æµ‹ç»“æœ
                            if count <= 1:
                                logger.info("ğŸ” anthologyæ£€æµ‹åˆ°ï¼Œä½†å®é™…åªæœ‰1é›†ï¼ŒæŒ‰å•é›†å¤„ç†")
                            else:
                                logger.info(f"ğŸ” anthologyæ£€æµ‹åˆ°ï¼Œç¡®è®¤æœ‰{count}é›†ï¼ŒæŒ‰åˆé›†å¤„ç†")
                    except Exception as e:
                        logger.warning(f"âš ï¸ å¼ºåˆ¶æ£€æµ‹å¤±è´¥: {e}")
                        if anthology_detected:
                            # å¦‚æœanthologyæ£€æµ‹æˆåŠŸä½†å¼ºåˆ¶æ£€æµ‹å¤±è´¥ï¼Œéœ€è¦è°¨æ…å¤„ç†
                            logger.info("ğŸ”„ anthologyæ£€æµ‹æˆåŠŸï¼Œä½†å¼ºåˆ¶æ£€æµ‹å¤±è´¥ï¼ŒæŒ‰å®é™…æ£€æµ‹ç»“æœå¤„ç†")
                            # ä¸å¼ºåˆ¶è®¾ç½®countï¼Œä¿æŒåŸæœ‰çš„æ£€æµ‹ç»“æœ
                            if count <= 1:
                                logger.info("ğŸ” anthologyæ£€æµ‹åˆ°ä½†å¼ºåˆ¶æ£€æµ‹å¤±è´¥ï¼Œä¸”å®é™…åªæœ‰1é›†ï¼ŒæŒ‰å•é›†å¤„ç†")
                            else:
                                logger.info(f"ğŸ” anthologyæ£€æµ‹åˆ°ï¼Œå®é™…æœ‰{count}é›†ï¼ŒæŒ‰åˆé›†å¤„ç†")
            playlist_title = info.get("title", "Unknown Playlist")
            safe_playlist_title = re.sub(r'[\\/:*?"<>|]', "_", playlist_title).strip()

            if count > 1 and auto_playlist:
                final_download_path = Path(download_path) / safe_playlist_title
                final_download_path.mkdir(parents=True, exist_ok=True)
                logger.info(
                    f"ğŸ“ ä¸ºåˆé›† '{safe_playlist_title}' åˆ›å»ºä¸‹è½½ç›®å½•: {final_download_path}"
                )
            else:
                final_download_path = Path(download_path)
                logger.info(f"ğŸ“ ä½¿ç”¨é»˜è®¤ä¸‹è½½ç›®å½•: {final_download_path}")
            # ç§»é™¤ os.chdir() è°ƒç”¨ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„

            if count == 1:
                video_type = "single"
                logger.info("ğŸ¬ æ£€æµ‹åˆ°å•è§†é¢‘")
            else:
                first_id = entries[0].get("id", "") if entries else ""
                all_same_id = all(
                    entry.get("id", "") == first_id for entry in entries if entry
                )
                if all_same_id:
                    video_type = "episodes"
                    logger.info(f"ğŸ“º æ£€æµ‹åˆ°åˆ†é›†è§†é¢‘ï¼Œå…± {count} é›†")
                    logger.info("ğŸ“‹ åˆ†é›†è¯¦æƒ…:")
                    for i, entry in enumerate(entries, 1):
                        if entry:
                            episode_title = entry.get("title", "unknown")
                            episode_id = entry.get("id", "unknown")
                            logger.info(
                                f"  {i:02d}. {episode_title} (ID: {episode_id})"
                            )
                else:
                    video_type = "playlist"
                    logger.info(f"ğŸ“š æ£€æµ‹åˆ°åˆé›†ï¼Œå…± {count} ä¸ªè§†é¢‘")
                    logger.info("ğŸ“‹ åˆé›†è¯¦æƒ…:")
                    for i, entry in enumerate(entries, 1):
                        if entry:
                            video_title = entry.get("title", "unknown")
                            video_id = entry.get("id", "unknown")
                            logger.info(f"  {i:02d}. {video_title} (ID: {video_id})")

            # æ ¹æ®è§†é¢‘ç±»å‹å†³å®šä¸‹è½½ç­–ç•¥
            if video_type == "single":
                # smart_download_bilibili ä¸“é—¨å¤„ç†å¤šPå’Œåˆé›†ï¼Œå•è§†é¢‘åº”è¯¥ç”±é€šç”¨ä¸‹è½½å™¨å¤„ç†
                logger.info("âš ï¸ smart_download_bilibili æ£€æµ‹åˆ°å•è§†é¢‘")
                if auto_playlist:
                    logger.info("ğŸ’¡ è™½ç„¶å¼€å¯äº†è‡ªåŠ¨ä¸‹è½½å…¨é›†ï¼Œä½†è¿™ç¡®å®æ˜¯å•è§†é¢‘ï¼Œå»ºè®®ä½¿ç”¨é€šç”¨ä¸‹è½½å™¨")
                else:
                    logger.info("ğŸ’¡ è¿™æ˜¯å•è§†é¢‘ï¼Œå»ºè®®ä½¿ç”¨é€šç”¨ä¸‹è½½å™¨")

                # è¿”å›ç‰¹æ®ŠçŠ¶æ€ï¼Œè®©è°ƒç”¨æ–¹çŸ¥é“è¿™æ˜¯å•è§†é¢‘
                return {
                    "status": "single_video",
                    "message": "è¿™æ˜¯å•è§†é¢‘ï¼Œå»ºè®®ä½¿ç”¨é€šç”¨ä¸‹è½½å™¨",
                    "video_type": "single"
                }
            elif video_type == "episodes":
                if auto_playlist:
                    # è‡ªåŠ¨ä¸‹è½½å…¨é›† - ç›´æ¥ä½¿ç”¨å®Œæ•´æ ‡é¢˜ï¼Œä¸åšå¤æ‚å¤„ç†
                    output_template = str(
                        final_download_path / "%(title)s.%(ext)s"
                    )
                    # æ·»åŠ æ˜æ˜¾çš„outtmplæ—¥å¿—
                    logger.info(
                        f"ğŸ”§ [BILIBILI_EPISODES] outtmpl ä½¿ç”¨å®Œæ•´æ ‡é¢˜: {output_template}"
                    )

                    # åˆ›å»ºç®€å•çš„è¿›åº¦å›è°ƒï¼Œä¸éœ€è¦é‡å‘½å
                    def enhanced_progress_callback(d):
                        # æ‰§è¡ŒåŸæœ‰çš„è¿›åº¦å›è°ƒé€»è¾‘ï¼ˆæ˜¾ç¤ºå®Œæ•´æ ‡é¢˜ï¼‰
                        if progress_callback:
                            progress_callback(d)

                    ydl_opts = {
                        "outtmpl": output_template,
                        "merge_output_format": "mp4",
                        "quiet": False,
                        "yes_playlist": True,
                        "extract_flat": False,
                        "progress_hooks": [enhanced_progress_callback],
                    }
                    logger.info("ğŸ”„ è‡ªåŠ¨ä¸‹è½½å…¨é›†æ¨¡å¼ï¼šå°†ä¸‹è½½æ‰€æœ‰åˆ†Pè§†é¢‘")
                else:
                    # åªä¸‹è½½å½“å‰åˆ†P
                    output_template = str(final_download_path / "%(title)s.%(ext)s")
                    # æ·»åŠ æ˜æ˜¾çš„outtmplæ—¥å¿—
                    logger.info(
                        f"ğŸ”§ [BILIBILI_SINGLE_EPISODE] outtmpl ç»å¯¹è·¯å¾„: {output_template}"
                    )
                    ydl_opts = {
                        "outtmpl": output_template,
                        "merge_output_format": "mp4",
                        "quiet": False,
                        "noplaylist": True,
                        "progress_hooks": [
                            lambda d: (
                                progress_callback(d) if progress_callback else None
                            )
                        ],
                    }
                    logger.info("ğŸ”„ å•Pæ¨¡å¼ï¼šåªä¸‹è½½å½“å‰åˆ†Pè§†é¢‘")
            else:  # playlist - å’Œå¤šPä¸‹è½½ä¸€æ ·ç®€å•
                # å¯¹äºåˆé›†ï¼Œç›´æ¥ä½¿ç”¨yt-dlpæ’­æ”¾åˆ—è¡¨åŠŸèƒ½ï¼ˆå’Œå¤šPä¸‹è½½ä¸€æ ·ï¼‰
                logger.info(f"ğŸ”§ æ£€æµ‹åˆ°åˆé›†ï¼Œä½¿ç”¨yt-dlpæ’­æ”¾åˆ—è¡¨åŠŸèƒ½ä¸‹è½½")
                logger.info(f"   - è§†é¢‘æ•°é‡: {count}")

                # ä½¿ç”¨å’Œå¤šPä¸‹è½½å®Œå…¨ç›¸åŒçš„é€»è¾‘
                output_template = str(
                    final_download_path / "%(playlist_index)s. %(title)s.%(ext)s"
                )
                logger.info(f"ğŸ”§ [BILIBILI_PLAYLIST] outtmpl ç»å¯¹è·¯å¾„: {output_template}")

                # ä½¿ç”¨å¢å¼ºç‰ˆè¿›åº¦å›è°ƒæ¥ç”Ÿæˆè¯¦ç»†çš„è¿›åº¦æ˜¾ç¤ºæ ¼å¼
                progress_data = {
                    "final_filename": None,
                    "lock": threading.Lock(),
                    "downloaded_files": [],  # æ·»åŠ ä¸‹è½½æ–‡ä»¶åˆ—è¡¨
                    "expected_files": []     # æ·»åŠ é¢„æœŸæ–‡ä»¶åˆ—è¡¨
                }

                # æ£€æŸ¥ progress_callback æ˜¯å¦æ˜¯å¢å¼ºç‰ˆè¿›åº¦å›è°ƒå‡½æ•°
                if callable(progress_callback) and progress_callback.__name__ == 'enhanced_progress_callback':
                    # å¦‚æœæ˜¯å¢å¼ºç‰ˆè¿›åº¦å›è°ƒï¼Œç›´æ¥ä½¿ç”¨å®ƒè¿”å›çš„ progress_hook
                    progress_hook = progress_callback(progress_data)
                else:
                    # å¦åˆ™ä½¿ç”¨æ ‡å‡†çš„ single_video_progress_hook
                    progress_hook = single_video_progress_hook(progress_callback, progress_data)

                ydl_opts = {
                    "outtmpl": output_template,
                    "merge_output_format": "mp4",
                    "quiet": False,
                    "yes_playlist": True,
                    "extract_flat": False,
                    "progress_hooks": [progress_hook],
                }
                logger.info("ğŸ”„ åˆé›†æ¨¡å¼ï¼šå°†ä¸‹è½½æ‰€æœ‰åˆé›†è§†é¢‘")

            # å¯¹äºå•è§†é¢‘å’Œåˆ†é›†è§†é¢‘ï¼Œä½¿ç”¨yt-dlpä¸‹è½½
            if video_type in ["single", "episodes"]:
                # æ·»åŠ ä»£ç†å’Œcookiesé…ç½®
                if self.proxy_host:
                    ydl_opts["proxy"] = self.proxy_host
                if self.b_cookies_path and os.path.exists(self.b_cookies_path):
                    ydl_opts["cookiefile"] = self.b_cookies_path
                logger.info(f"ğŸ”§ [BILIBILI_DOWNLOAD] æœ€ç»ˆydl_opts: {ydl_opts}")
                logger.info(f"ğŸ“ æœ€ç»ˆè¾“å‡ºæ¨¡æ¿: {output_template}")
                logger.info(f"ğŸ“ ä¸‹è½½ç›®å½•: {final_download_path}")

                # æ‰§è¡Œä¸‹è½½
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    ydl.download([original_url])

                logger.info("âœ… Bç«™è§†é¢‘ä¸‹è½½å®Œæˆ")
                logger.info("ğŸ¯ ä½¿ç”¨postprocessoræ™ºèƒ½æ–‡ä»¶åï¼Œæ— éœ€é‡å‘½å")

                # ç®€åŒ–ï¼šBç«™å¤šPä¸‹è½½å®Œæˆï¼Œç›´æ¥è¿”å›æˆåŠŸï¼Œæ–‡ä»¶æŸ¥æ‰¾äº¤ç»™ç›®å½•éå†
                logger.info("ğŸ¯ Bç«™å¤šPä¸‹è½½å®Œæˆï¼Œä½¿ç”¨ç›®å½•éå†æŸ¥æ‰¾æ–‡ä»¶")

                return {
                    "status": "success",
                    "video_type": video_type,
                    "count": count,
                    "playlist_title": safe_playlist_title if count > 1 else None,
                    "download_path": str(final_download_path),
                    # ç®€åŒ–ï¼šä¸ä¼ é€’é¢„æœŸæ–‡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ç›®å½•éå†
                }

        except Exception as e:
            logger.error(f"âŒ Bç«™è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")
            return {"status": "failure", "error": str(e)}
        finally:
            # æ¢å¤åŸå§‹å·¥ä½œç›®å½•
            try:
                os.chdir(original_cwd)
                logger.info(f"ğŸ“ å·²æ¢å¤å·¥ä½œç›®å½•: {original_cwd}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¢å¤å·¥ä½œç›®å½•å¤±è´¥: {e}")

    def get_bilibili_list_videos(self, uid: str, list_id: str) -> list:
        """
        é€šè¿‡Bç«™APIè·å–ç”¨æˆ·è‡ªå®šä¹‰åˆ—è¡¨ä¸­çš„è§†é¢‘

        Args:
            uid: ç”¨æˆ·ID (å¦‚ 477348669)
            list_id: åˆ—è¡¨ID (å¦‚ 2111173)

        Returns:
            list: [(bv, title), ...]
        """
        try:
            # Bç«™ç”¨æˆ·åˆ—è¡¨API
            api_url = f"https://api.bilibili.com/x/space/fav/season/list"
            params = {
                "season_id": list_id,
                "pn": 1,
                "ps": 20,  # æ¯é¡µ20ä¸ª
                "jsonp": "jsonp",
            }

            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                "Referer": f"https://space.bilibili.com/{uid}/lists/{list_id}",
            }

            logger.info(f"ğŸ” è·å–Bç«™åˆ—è¡¨API: {api_url}")
            response = requests.get(api_url, params=params, headers=headers, timeout=10, verify=False)
            response.raise_for_status()

            data = response.json()
            if data.get("code") != 0:
                logger.error(f"âŒ APIè¿”å›é”™è¯¯: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return []

            # è§£æè§†é¢‘åˆ—è¡¨
            videos = []
            archives = data.get("data", {}).get("medias", [])

            for archive in archives:
                bv = archive.get("bvid", "")
                title = archive.get("title", "")
                if bv and title:
                    videos.append((bv, title))
                    logger.info(f"  ğŸ“º {bv}: {title}")

            logger.info(f"ğŸ“¦ ä»APIè·å–åˆ° {len(videos)} ä¸ªè§†é¢‘")
            return videos

        except Exception as e:
            logger.error(f"âŒ è·å–Bç«™åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def download_bilibili_list_bv_method(
        self, uid: str, list_id: str, download_path: str
    ) -> bool:
        """
        ä½¿ç”¨BVå·å¾ªç¯æ³•ä¸‹è½½Bç«™ç”¨æˆ·è‡ªå®šä¹‰åˆ—è¡¨

        Args:
            uid: ç”¨æˆ·ID
            list_id: åˆ—è¡¨ID
            download_path: ä¸‹è½½è·¯å¾„

        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        import subprocess
        import re

        logger.info(f"ğŸ”§ ä½¿ç”¨BVå·å¾ªç¯æ³•ä¸‹è½½Bç«™åˆ—è¡¨:")
        logger.info(f"   - ç”¨æˆ·ID: {uid}")
        logger.info(f"   - åˆ—è¡¨ID: {list_id}")

        # 1. é€šè¿‡APIè·å–è§†é¢‘åˆ—è¡¨
        bv_list = self.get_bilibili_list_videos(uid, list_id)

        if not bv_list:
            logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘")
            return False

        logger.info(f"ğŸ“¦ æ‰¾åˆ° {len(bv_list)} ä¸ªè§†é¢‘ï¼Œå¼€å§‹é€ä¸ªä¸‹è½½")

        # 2. ä¾æ¬¡ä¸‹è½½æ¯ä¸ªBVå·
        success_count = 0
        for idx, (bv, title) in enumerate(bv_list, 1):
            # æ¸…ç†æ ‡é¢˜ä¸­çš„éæ³•å­—ç¬¦
            safe_title = re.sub(r'[\\/:*?"<>|]', "", title)[:60]
            outtmpl = f"{idx:02d}. {safe_title}.%(ext)s"
            cmd_dl = [
                "yt-dlp",
                "-o",
                outtmpl,
                "--merge-output-format",
                "mp4",
                f"https://www.bilibili.com/video/{bv}",
            ]
            logger.info(f"ğŸš€ ä¸‹è½½ç¬¬{idx}ä¸ª: {bv} - {title}")
            logger.info(f"ğŸ“ æ–‡ä»¶åæ¨¡æ¿: {outtmpl}")

            result = subprocess.run(cmd_dl, cwd=download_path)
            if result.returncode == 0:
                success_count += 1
                logger.info(f"âœ… ç¬¬{idx}ä¸ªä¸‹è½½æˆåŠŸ")
            else:
                logger.error(f"âŒ ç¬¬{idx}ä¸ªä¸‹è½½å¤±è´¥")

        logger.info(f"ğŸ‰ BVå·å¾ªç¯æ³•ä¸‹è½½å®Œæˆ: {success_count}/{len(bv_list)} ä¸ªæˆåŠŸ")
        return success_count > 0

    async def _download_bilibili_list(
        self, uid: str, list_id: str, download_path: Path, message_updater=None
    ) -> Dict[str, Any]:
        """ä¸‹è½½Bilibiliæ’­æ”¾åˆ—è¡¨"""
        logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½Bilibiliæ’­æ”¾åˆ—è¡¨: UID={uid}, ListID={list_id}")

        try:
            logger.info("ğŸ” æ­¥éª¤1: å‡†å¤‡è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯...")
            # è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ - æ·»åŠ è¶…æ—¶æ§åˆ¶
            info_opts = {
                "quiet": True,
                "extract_flat": True,
                "ignoreerrors": True,
                "socket_timeout": 30,  # 30ç§’è¶…æ—¶
                "retries": 3,  # å‡å°‘é‡è¯•æ¬¡æ•°
                "fragment_retries": 3,
            }
            if self.proxy_host:
                info_opts["proxy"] = self.proxy_host
                logger.info(f"ğŸŒ ä½¿ç”¨ä»£ç†: {self.proxy_host}")

            logger.info("ğŸ” æ­¥éª¤2: å¼€å§‹æå–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆè®¾ç½®30ç§’è¶…æ—¶ï¼‰...")

            # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨æ¥æ·»åŠ è¶…æ—¶æ§åˆ¶
            loop = asyncio.get_running_loop()

            def extract_playlist_info():
                with yt_dlp.YoutubeDL(info_opts) as ydl:
                    logger.info("ğŸ“¡ æ­£åœ¨ä»Bilibiliè·å–æ’­æ”¾åˆ—è¡¨æ•°æ®...")
                    return ydl.extract_info(
                        f"https://www.bilibili.com/medialist/play/{uid}?business=space_series&business_id={list_id}",
                        download=False,
                    )

            # è®¾ç½®30ç§’è¶…æ—¶
            try:
                info = await asyncio.wait_for(
                    loop.run_in_executor(None, extract_playlist_info), timeout=60.0
                )
                logger.info(f"âœ… æ’­æ”¾åˆ—è¡¨ä¿¡æ¯è·å–å®Œæˆï¼Œæ•°æ®ç±»å‹: {type(info)}")
            except asyncio.TimeoutError:
                logger.error("âŒ è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
                return {
                    "success": False,
                    "error": "è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚",
                }

            if not info:
                logger.error("âŒ æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ä¸ºç©º")
                return {"success": False, "error": "æ— æ³•è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯"}

            if "entries" not in info:
                logger.error("âŒ æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ä¸­æ²¡æœ‰æ‰¾åˆ° 'entries' å­—æ®µ")
                return {"success": False, "error": "æ— æ³•è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯"}

            entries = info.get("entries", [])
            logger.info(f"ğŸ“Š æ’­æ”¾åˆ—è¡¨åŒ…å« {len(entries)} ä¸ªè§†é¢‘")

            if not entries:
                logger.warning("âš ï¸ æ’­æ”¾åˆ—è¡¨ä¸ºç©º")
                return {"success": False, "error": "æ’­æ”¾åˆ—è¡¨ä¸ºç©º"}

            logger.info("ğŸ” æ­¥éª¤3: åˆ›å»ºæ’­æ”¾åˆ—è¡¨ç›®å½•...")
            playlist_title = re.sub(
                r'[\\/:*?"<>|]', "_", info.get("title", "Bilibili_Playlist")
            ).strip()
            playlist_path = download_path / playlist_title
            playlist_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ æ’­æ”¾åˆ—è¡¨ç›®å½•: {playlist_path}")

            logger.info("ğŸ” æ­¥éª¤4: é…ç½®ä¸‹è½½é€‰é¡¹...")
            # è®¾ç½®è¾“å‡ºæ¨¡æ¿
            outtmpl = str(
                playlist_path.absolute()
                / "%(playlist_index)02d - %(title)s [%(id)s].%(ext)s"
            )
            # æ·»åŠ æ˜æ˜¾çš„outtmplæ—¥å¿—
            logger.info(f"ğŸ”§ [BILIBILI_PLAYLIST] outtmpl ç»å¯¹è·¯å¾„: {outtmpl}")

            # é…ç½®ä¸‹è½½é€‰é¡¹ - ä¼˜åŒ–æ€§èƒ½
            ydl_opts = {
                "outtmpl": outtmpl,
                "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
                "merge_output_format": "mp4",
                "ignoreerrors": True,
                "retries": 5,  # å‡å°‘é‡è¯•æ¬¡æ•°
                "fragment_retries": 5,
                "skip_unavailable_fragments": True,
                "quiet": True,
                "no_warnings": True,
                "socket_timeout": 30,  # 30ç§’è¶…æ—¶
                "extract_flat": False,  # å®Œæ•´æå–
            }

            if self.proxy_host:
                ydl_opts["proxy"] = self.proxy_host

            if message_updater:
                ydl_opts["progress_hooks"] = [message_updater]

            logger.info("ğŸ” æ­¥éª¤5: å¼€å§‹ä¸‹è½½æ’­æ”¾åˆ—è¡¨ï¼ˆè®¾ç½®60ç§’è¶…æ—¶ï¼‰...")

            def download_playlist():
                logger.info(f"ğŸ”§ [BILIBILI_PLAYLIST_DOWNLOAD] æœ€ç»ˆydl_opts: {ydl_opts}")
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    logger.info("ğŸš€ å¼€å§‹ä¸‹è½½Bilibiliæ’­æ”¾åˆ—è¡¨è§†é¢‘...")
                    return ydl.download(
                        [
                            f"https://www.bilibili.com/medialist/play/{uid}?business=space_series&business_id={list_id}"
                        ]
                    )

            # è®¾ç½®60ç§’è¶…æ—¶ç”¨äºä¸‹è½½
            try:
                await asyncio.wait_for(
                    loop.run_in_executor(None, download_playlist), timeout=120.0
                )
                logger.info("âœ… Bilibiliæ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆ")
            except asyncio.TimeoutError:
                logger.error("âŒ Bilibiliæ’­æ”¾åˆ—è¡¨ä¸‹è½½è¶…æ—¶ï¼ˆ60ç§’ï¼‰")
                return {
                    "success": False,
                    "error": "Bilibiliæ’­æ”¾åˆ—è¡¨ä¸‹è½½è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚",
                }

            return {
                "success": True,
                "is_playlist": True,
                "playlist_title": playlist_title,
                "download_path": str(playlist_path),
                "video_count": len(entries),
            }

        except Exception as e:
            logger.error(f"âŒ Bilibiliæ’­æ”¾åˆ—è¡¨ä¸‹è½½å¤±è´¥: {e}")
            import traceback

            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    async def _download_youtube_playlist_with_progress(
        self, playlist_id: str, download_path: Path, progress_callback=None
    ) -> Dict[str, Any]:
        """ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨ï¼ˆå¸¦è¯¦ç»†è¿›åº¦ï¼‰"""
        logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨: {playlist_id}")
        logger.info(f"ğŸ“ ä¸‹è½½è·¯å¾„: {download_path}")

        try:
            # é¦–å…ˆæ£€æŸ¥æ’­æ”¾åˆ—è¡¨æ˜¯å¦å·²ç»å®Œæ•´ä¸‹è½½
            logger.info("ğŸ” æ£€æŸ¥æ’­æ”¾åˆ—è¡¨æ˜¯å¦å·²å®Œæ•´ä¸‹è½½...")
            check_result = self._check_playlist_already_downloaded(
                playlist_id, download_path
            )

            if check_result.get("already_downloaded", False):
                logger.info("âœ… æ’­æ”¾åˆ—è¡¨å·²å®Œæ•´ä¸‹è½½ï¼Œç›´æ¥è¿”å›ç»“æœ")
                return {
                    "success": True,
                    "already_downloaded": True,
                    "playlist_title": check_result.get("playlist_title", ""),
                    "video_count": check_result.get("video_count", 0),
                    "download_path": check_result.get("download_path", ""),
                    "total_size_mb": check_result.get("total_size_mb", 0),
                    "resolution": check_result.get("resolution", "æœªçŸ¥"),
                    "downloaded_files": check_result.get("downloaded_files", []),
                    "completion_rate": check_result.get("completion_rate", 100),
                }
            else:
                logger.info(f"ğŸ“¥ æ’­æ”¾åˆ—è¡¨æœªå®Œæ•´ä¸‹è½½ï¼ŒåŸå› : {check_result.get('reason', 'æœªçŸ¥')}")
                if check_result.get("completion_rate", 0) > 0:
                    logger.info(
                        f"ğŸ“Š å½“å‰å®Œæˆåº¦: {check_result.get('completion_rate', 0):.1f}%"
                    )

            # è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯
            info_opts = {"quiet": True, "extract_flat": True, "ignoreerrors": True}
            if self.proxy_host:
                info_opts["proxy"] = self.proxy_host
                logger.info(f"ğŸŒ ä½¿ç”¨ä»£ç†: {self.proxy_host}")
            if self.youtube_cookies_path and os.path.exists(self.youtube_cookies_path):
                info_opts["cookiefile"] = self.youtube_cookies_path
                logger.info(
                    f"ğŸª ä½¿ç”¨YouTube cookies: {self.youtube_cookies_path}"
                )

            def extract_playlist_info():
                logger.info("ğŸ“¡ æ­£åœ¨ä»YouTubeè·å–æ’­æ”¾åˆ—è¡¨æ•°æ®...")
                with yt_dlp.YoutubeDL(info_opts) as ydl:
                    result = ydl.extract_info(
                        f"https://www.youtube.com/playlist?list={playlist_id}",
                        download=False,
                    )
                    return result

            loop = asyncio.get_running_loop()
            info = await loop.run_in_executor(None, extract_playlist_info)

            if not info:
                logger.error("âŒ æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ä¸ºç©º")
                return {"success": False, "error": "æ— æ³•è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ã€‚"}

            entries = info.get("entries", [])
            if not entries:
                logger.warning("âŒ æ’­æ”¾åˆ—è¡¨ä¸ºç©º")
                return {"success": False, "error": "æ’­æ”¾åˆ—è¡¨ä¸ºç©ºã€‚"}

            logger.info(f"ğŸ“Š æ’­æ”¾åˆ—è¡¨åŒ…å« {len(entries)} ä¸ªè§†é¢‘")

            # åˆ›å»ºæ’­æ”¾åˆ—è¡¨ç›®å½•
            playlist_title = re.sub(
                r'[\\/:*?"<>|]', "_", info.get("title", f"Playlist_{playlist_id}")
            ).strip()
            playlist_path = download_path / playlist_title
            playlist_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ æ’­æ”¾åˆ—è¡¨ç›®å½•: {playlist_path}")

            # é¢„å…ˆè®°å½•é¢„æœŸæ–‡ä»¶ä¿¡æ¯ï¼ˆåƒBç«™å¤šPä¸‹è½½ä¸€æ ·ï¼‰
            expected_files = []
            for i, entry in enumerate(entries, 1):
                title = entry.get("title", f"Video_{i}")
                safe_title = re.sub(r'[\\/:*?"<>|]', "_", title).strip()
                expected_filename = f"{i:02d}. {safe_title}.mp4"
                expected_files.append({
                    'title': title,
                    'filename': expected_filename,
                    'index': i,
                    'id': entry.get('id', ''),
                })

            logger.info(f"ğŸ“‹ é¢„æœŸæ–‡ä»¶åˆ—è¡¨: {len(expected_files)} ä¸ªæ–‡ä»¶")

            # ä¸‹è½½æ’­æ”¾åˆ—è¡¨ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
            def download_playlist():
                logger.info("ğŸš€ å¼€å§‹ä¸‹è½½æ’­æ”¾åˆ—è¡¨...")
                # ä½¿ç”¨ç»å¯¹è·¯å¾„æ„å»ºouttmplï¼Œä½¿ç”¨ä¸¤ä½æ•°å­—æ ¼å¼
                abs_outtmpl = str(
                    playlist_path.absolute() / "%(playlist_index)02d. %(title)s.%(ext)s"
                )
                logger.info(
                    f"ğŸ”§ [YT_PLAYLIST_WITH_PROGRESS] outtmpl ç»å¯¹è·¯å¾„: {abs_outtmpl}"
                )
                # ä½¿ç”¨å¢å¼ºé…ç½®ï¼Œé¿å…PARTæ–‡ä»¶
                base_opts = {
                    "outtmpl": abs_outtmpl,
                    "merge_output_format": "mp4",
                    "ignoreerrors": True,
                    "progress_hooks": [progress_callback] if progress_callback else [],
                }

                ydl_opts = self._get_enhanced_ydl_opts(base_opts)
                logger.info("ğŸ›¡ï¸ ä½¿ç”¨å¢å¼ºé…ç½®ï¼Œé¿å…PARTæ–‡ä»¶äº§ç”Ÿ")
                logger.info(f"ğŸ”§ [YT_PLAYLIST_WITH_PROGRESS] æœ€ç»ˆydl_optså…³é”®é…ç½®: outtmpl={abs_outtmpl}")

                playlist_url = f"https://www.youtube.com/playlist?list={playlist_id}"
                try:
                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        ydl.download([playlist_url])

                    # ä¸‹è½½å®Œæˆåæ£€æŸ¥å¹¶å¤„ç†PARTæ–‡ä»¶
                    logger.info("ğŸ” æ£€æŸ¥YouTubeæ’­æ”¾åˆ—è¡¨ä¸‹è½½å®ŒæˆçŠ¶æ€...")
                    resume_success = self._resume_failed_downloads(download_path, playlist_url, max_retries=2)

                    if not resume_success:
                        logger.warning("âš ï¸ éƒ¨åˆ†æ–‡ä»¶ä¸‹è½½æœªå®Œæˆï¼Œä½†å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    else:
                        logger.info("âœ… YouTubeæ’­æ”¾åˆ—è¡¨æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å®Œæˆ")

                except Exception as e:
                    logger.error(f"âŒ YouTubeæ’­æ”¾åˆ—è¡¨ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                    # å³ä½¿å‡ºé”™ä¹Ÿå°è¯•æ–­ç‚¹ç»­ä¼ PARTæ–‡ä»¶
                    logger.info("ğŸ”„ å°è¯•æ–­ç‚¹ç»­ä¼ æœªå®Œæˆçš„æ–‡ä»¶...")
                    self._resume_part_files(download_path, playlist_url)
                    raise

            await loop.run_in_executor(None, download_playlist)

            logger.info("ğŸ‰ æ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆ!")

            # ä½¿ç”¨é¢„æœŸæ–‡ä»¶åç²¾ç¡®æŸ¥æ‰¾ï¼ˆåƒBç«™å¤šPä¸‹è½½ä¸€æ ·ï¼‰
            downloaded_files = []
            total_size_mb = 0
            all_resolutions = set()

            logger.info("ğŸ” ä½¿ç”¨é¢„æœŸæ–‡ä»¶åæŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶")
            for expected_file in expected_files:
                expected_filename = expected_file['filename']
                expected_path = playlist_path / expected_filename

                if expected_path.exists():
                    try:
                        file_size = expected_path.stat().st_size
                        if file_size > 0:
                            file_size_mb = file_size / (1024 * 1024)
                            total_size_mb += file_size_mb

                            # è·å–åª’ä½“ä¿¡æ¯
                            media_info = self.get_media_info(str(expected_path))
                            resolution = media_info.get('resolution', 'æœªçŸ¥')
                            if resolution != 'æœªçŸ¥':
                                all_resolutions.add(resolution)

                            downloaded_files.append({
                                "filename": expected_filename,
                                "path": str(expected_path),
                                "size_mb": file_size_mb,
                                "video_title": expected_file['title'],
                            })
                            logger.info(f"âœ… æ‰¾åˆ°é¢„æœŸæ–‡ä»¶: {expected_filename} ({file_size_mb:.2f}MB)")
                        else:
                            logger.warning(f"âš ï¸ é¢„æœŸæ–‡ä»¶ä¸ºç©º: {expected_filename}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ— æ³•æ£€æŸ¥é¢„æœŸæ–‡ä»¶: {expected_filename}, é”™è¯¯: {e}")
                else:
                    # å°è¯•ä½¿ç”¨æ¸…ç†åçš„æ–‡ä»¶ååŒ¹é…ï¼ˆå¤„ç†æ ¼å¼ä»£ç ç­‰ï¼‰
                    def clean_filename_for_matching(filename):
                        """æ¸…ç†æ–‡ä»¶åç”¨äºåŒ¹é…"""
                        import re
                        if not filename:
                            return ""

                        # åˆ é™¤yt-dlpçš„å„ç§æ ¼å¼ä»£ç 
                        cleaned = re.sub(r'\.[fm]\d+(\+\d+)*', '', filename)
                        cleaned = re.sub(r'\.f\d+', '', cleaned)
                        cleaned = re.sub(r'\.(webm|m4a|mp3)$', '.mp4', cleaned)

                        # ç¡®ä¿ä»¥ .mp4 ç»“å°¾
                        if not cleaned.endswith('.mp4'):
                            cleaned = cleaned.rstrip('.') + '.mp4'

                        return cleaned

                    # åœ¨æ’­æ”¾åˆ—è¡¨ç›®å½•ä¸­æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
                    found = False
                    for video_ext in ["*.mp4", "*.mkv", "*.webm", "*.avi", "*.mov", "*.flv"]:
                        matching_files = list(playlist_path.glob(video_ext))
                        for file_path in matching_files:
                            actual_filename = file_path.name
                            cleaned_actual = clean_filename_for_matching(actual_filename)
                            cleaned_expected = clean_filename_for_matching(expected_filename)

                            if cleaned_actual == cleaned_expected:
                                try:
                                    file_size = file_path.stat().st_size
                                    if file_size > 0:
                                        file_size_mb = file_size / (1024 * 1024)
                                        total_size_mb += file_size_mb

                                        # è·å–åª’ä½“ä¿¡æ¯
                                        media_info = self.get_media_info(str(file_path))
                                        resolution = media_info.get('resolution', 'æœªçŸ¥')
                                        if resolution != 'æœªçŸ¥':
                                            all_resolutions.add(resolution)

                                        downloaded_files.append({
                                            "filename": actual_filename,
                                            "path": str(file_path),
                                            "size_mb": file_size_mb,
                                            "video_title": expected_file['title'],
                                        })
                                        logger.info(f"âœ… é€šè¿‡æ™ºèƒ½åŒ¹é…æ‰¾åˆ°æ–‡ä»¶: {actual_filename} ({file_size_mb:.2f}MB)")
                                        found = True
                                        break
                                except Exception as e:
                                    continue
                        if found:
                            break

                    if not found:
                        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°é¢„æœŸæ–‡ä»¶: {expected_filename}")

            # è®¡ç®—åˆ†è¾¨ç‡æ˜¾ç¤º
            resolution = ', '.join(sorted(all_resolutions)) if all_resolutions else 'æœªçŸ¥'

            logger.info(f"ğŸ“Š æ‰¾åˆ°æ–‡ä»¶æ•°é‡: {len(downloaded_files)}/{len(expected_files)}")
            logger.info(f"ğŸ“Š æ€»å¤§å°: {total_size_mb:.2f}MB")

            return {
                "success": True,
                "playlist_title": playlist_title,
                "video_count": len(downloaded_files),
                "download_path": str(playlist_path),
                "total_size_mb": total_size_mb,
                "size_mb": total_size_mb,  # æ·»åŠ è¿™ä¸ªå­—æ®µä»¥å…¼å®¹main.py
                "resolution": resolution,
                "downloaded_files": downloaded_files,
            }

        except Exception as e:
            logger.error(f"âŒ YouTubeæ’­æ”¾åˆ—è¡¨ä¸‹è½½å¤±è´¥: {e}")
            import traceback

            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}
    
    def _escape_markdown(self, text: str) -> str:
        # å…ˆè½¬ä¹‰åæ–œæ 
        text = text.replace("\\", "\\\\")
        # å†è½¬ä¹‰å…¶å®ƒæ‰€æœ‰ç‰¹æ®Šå­—ç¬¦
        for ch in "_*[]()~`>#+-=|{}.!":
            text = text.replace(ch, f"\\{ch}")
        return text

    def _make_progress_bar(self, percent: float) -> str:
        """ç”Ÿæˆè¿›åº¦æ¡"""
        bar_length = 20
        filled_length = int(bar_length * percent / 100)
        bar = "â–ˆ" * filled_length + "â–‘" * (bar_length - filled_length)
        return f"[{bar}] {percent:.1f}%"

    def _check_playlist_already_downloaded(
        self, playlist_id: str, download_path: Path
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥YouTubeæ’­æ”¾åˆ—è¡¨æ˜¯å¦å·²ç»å®Œæ•´ä¸‹è½½ï¼ˆä½¿ç”¨é¢„æœŸæ–‡ä»¶åæ–¹å¼ï¼‰

        Args:
            playlist_id: æ’­æ”¾åˆ—è¡¨ID
            download_path: ä¸‹è½½è·¯å¾„

        Returns:
            Dict: åŒ…å«æ£€æŸ¥ç»“æœçš„å­—å…¸
        """
        logger.info(f"ğŸ” æ£€æŸ¥æ’­æ”¾åˆ—è¡¨æ˜¯å¦å·²ä¸‹è½½: {playlist_id}")

        try:
            # è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯
            info_opts = {
                "quiet": True,
                "extract_flat": True,
                "ignoreerrors": True,
                "socket_timeout": 10,
                "retries": 2,
            }
            if self.proxy_host:
                info_opts["proxy"] = self.proxy_host
            if self.youtube_cookies_path and os.path.exists(self.youtube_cookies_path):
                info_opts["cookiefile"] = self.youtube_cookies_path

            with yt_dlp.YoutubeDL(info_opts) as ydl:
                info = ydl.extract_info(
                    f"https://www.youtube.com/playlist?list={playlist_id}",
                    download=False,
                )

            if not info:
                logger.warning("âŒ æ— æ³•è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯")
                return {"already_downloaded": False, "reason": "æ— æ³•è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯"}

            entries = info.get("entries", [])
            if not entries:
                logger.warning("âŒ æ’­æ”¾åˆ—è¡¨ä¸ºç©º")
                return {"already_downloaded": False, "reason": "æ’­æ”¾åˆ—è¡¨ä¸ºç©º"}

            # æ„å»ºé¢„æœŸæ–‡ä»¶åˆ—è¡¨ï¼ˆå’Œä¸‹è½½æ—¶ä¸€è‡´ï¼‰
            expected_files = []
            for i, entry in enumerate(entries, 1):
                title = entry.get("title", f"Video_{i}")
                safe_title = re.sub(r'[\\/:*?"<>|]', "_", title).strip()
                expected_filename = f"{i:02d}. {safe_title}.mp4"
                expected_files.append({
                    'title': title,
                    'filename': expected_filename,
                    'index': i,
                    'id': entry.get('id', ''),
                })

            # åˆ›å»ºæ’­æ”¾åˆ—è¡¨ç›®å½•å
            playlist_title = re.sub(
                r'[\\/:*?"<>|]', "_", info.get("title", f"Playlist_{playlist_id}")
            ).strip()
            playlist_path = download_path / playlist_title

            if not playlist_path.exists():
                logger.info(f"ğŸ“ æ’­æ”¾åˆ—è¡¨ç›®å½•ä¸å­˜åœ¨: {playlist_path}")
                return {"already_downloaded": False, "reason": "ç›®å½•ä¸å­˜åœ¨"}

            logger.info(f"ğŸ“ æ£€æŸ¥æ’­æ”¾åˆ—è¡¨ç›®å½•: {playlist_path}")

            # ä½¿ç”¨é¢„æœŸæ–‡ä»¶åæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆå’Œä¸‹è½½é€»è¾‘ä¸€è‡´ï¼‰
            missing_files = []
            existing_files = []
            total_size_mb = 0
            all_resolutions = set()

            def clean_filename_for_matching(filename):
                """æ¸…ç†æ–‡ä»¶åç”¨äºåŒ¹é…"""
                import re
                if not filename:
                    return ""

                # åˆ é™¤yt-dlpçš„å„ç§æ ¼å¼ä»£ç 
                cleaned = re.sub(r'\.[fm]\d+(\+\d+)*', '', filename)
                cleaned = re.sub(r'\.f\d+', '', cleaned)
                cleaned = re.sub(r'\.(webm|m4a|mp3)$', '.mp4', cleaned)

                # ç¡®ä¿ä»¥ .mp4 ç»“å°¾
                if not cleaned.endswith('.mp4'):
                    cleaned = cleaned.rstrip('.') + '.mp4'

                return cleaned

            for expected_file in expected_files:
                expected_filename = expected_file['filename']
                expected_path = playlist_path / expected_filename
                title = expected_file['title']

                if expected_path.exists():
                    try:
                        file_size = expected_path.stat().st_size
                        if file_size > 0:
                            file_size_mb = file_size / (1024 * 1024)
                            total_size_mb += file_size_mb

                            # è·å–åª’ä½“ä¿¡æ¯
                            media_info = self.get_media_info(str(expected_path))
                            resolution = media_info.get('resolution', 'æœªçŸ¥')
                            if resolution != 'æœªçŸ¥':
                                all_resolutions.add(resolution)

                            existing_files.append({
                                "filename": expected_filename,
                                "path": str(expected_path),
                                "size_mb": file_size_mb,
                                "video_title": title,
                            })
                            logger.info(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {expected_filename} ({file_size_mb:.2f}MB)")
                        else:
                            missing_files.append(f"{expected_file['index']}. {title}")
                            logger.warning(f"âš ï¸ æ–‡ä»¶ä¸ºç©º: {expected_filename}")
                    except Exception as e:
                        missing_files.append(f"{expected_file['index']}. {title}")
                        logger.warning(f"âš ï¸ æ— æ³•æ£€æŸ¥æ–‡ä»¶: {expected_filename}, é”™è¯¯: {e}")
                else:
                    # å°è¯•æ™ºèƒ½åŒ¹é…ï¼ˆå¤„ç†æ ¼å¼ä»£ç ç­‰ï¼‰
                    found = False
                    for video_ext in ["*.mp4", "*.mkv", "*.webm", "*.avi", "*.mov", "*.flv"]:
                        matching_files = list(playlist_path.glob(video_ext))
                        for file_path in matching_files:
                            actual_filename = file_path.name
                            cleaned_actual = clean_filename_for_matching(actual_filename)
                            cleaned_expected = clean_filename_for_matching(expected_filename)

                            if cleaned_actual == cleaned_expected:
                                try:
                                    file_size = file_path.stat().st_size
                                    if file_size > 0:
                                        file_size_mb = file_size / (1024 * 1024)
                                        total_size_mb += file_size_mb

                                        # è·å–åª’ä½“ä¿¡æ¯
                                        media_info = self.get_media_info(str(file_path))
                                        resolution = media_info.get('resolution', 'æœªçŸ¥')
                                        if resolution != 'æœªçŸ¥':
                                            all_resolutions.add(resolution)

                                        existing_files.append({
                                            "filename": actual_filename,
                                            "path": str(file_path),
                                            "size_mb": file_size_mb,
                                            "video_title": title,
                                        })
                                        logger.info(f"âœ… é€šè¿‡æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°æ–‡ä»¶: {actual_filename} ({file_size_mb:.2f}MB)")
                                        found = True
                                        break
                                except Exception as e:
                                    continue
                        if found:
                            break

                    if not found:
                        missing_files.append(f"{expected_file['index']}. {title}")
                        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶: {expected_filename}")

            # è®¡ç®—å®Œæˆåº¦
            total_videos = len(expected_files)
            downloaded_videos = len(existing_files)
            completion_rate = (
                (downloaded_videos / total_videos) * 100 if total_videos > 0 else 0
            )

            logger.info(
                f"ğŸ“Š ä¸‹è½½å®Œæˆåº¦: {downloaded_videos}/{total_videos} ({completion_rate:.1f}%)"
            )

            # å¦‚æœå®Œæˆåº¦è¾¾åˆ°95%ä»¥ä¸Šï¼Œè®¤ä¸ºå·²ç»ä¸‹è½½å®Œæˆ
            if completion_rate >= 95:
                logger.info(f"âœ… æ’­æ”¾åˆ—è¡¨å·²å®Œæ•´ä¸‹è½½ ({completion_rate:.1f}%)")

                # è®¡ç®—åˆ†è¾¨ç‡ä¿¡æ¯
                resolution = ', '.join(sorted(all_resolutions)) if all_resolutions else 'æœªçŸ¥'
                if existing_files:
                    try:
                        import subprocess

                        first_file_path = existing_files[0]["path"]
                        result = subprocess.run(
                            [
                                "ffprobe",
                                "-v",
                                "quiet",
                                "-print_format",
                                "json",
                                "-show_streams",
                                first_file_path,
                            ],
                            capture_output=True,
                            text=True,
                        )
                        if result.returncode == 0:
                            import json

                            data = json.loads(result.stdout)
                            for stream in data.get("streams", []):
                                if stream.get("codec_type") == "video":
                                    width = stream.get("width", 0)
                                    height = stream.get("height", 0)
                                    if width and height:
                                        resolution = f"{width}x{height}"
                                        break
                    except Exception as e:
                        logger.warning(f"æ— æ³•è·å–è§†é¢‘åˆ†è¾¨ç‡: {e}")

                return {
                    "already_downloaded": True,
                    "playlist_title": playlist_title,
                    "video_count": downloaded_videos,
                    "total_videos": total_videos,
                    "completion_rate": completion_rate,
                    "download_path": str(playlist_path),
                    "total_size_mb": total_size_mb,
                    "resolution": resolution,
                    "downloaded_files": existing_files,
                    "missing_files": missing_files,
                }
            else:
                logger.info(f"ğŸ“¥ æ’­æ”¾åˆ—è¡¨æœªå®Œæ•´ä¸‹è½½ ({completion_rate:.1f}%)")
                return {
                    "already_downloaded": False,
                    "reason": f"å®Œæˆåº¦ä¸è¶³ ({completion_rate:.1f}%)",
                    "downloaded_videos": downloaded_videos,
                    "total_videos": total_videos,
                    "completion_rate": completion_rate,
                    "missing_files": missing_files,
                }

        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥æ’­æ”¾åˆ—è¡¨ä¸‹è½½çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return {"already_downloaded": False, "reason": f"æ£€æŸ¥å¤±è´¥: {str(e)}"}

    def _convert_cookies_to_json(self, cookies_path: str) -> dict:
        """å°† Netscape æ ¼å¼çš„ cookies è½¬æ¢ä¸º gallery-dl æ”¯æŒçš„ JSON æ ¼å¼"""
        try:
            import http.cookiejar
            
            # åˆ›å»º cookie jar å¹¶åŠ è½½ cookies
            cookie_jar = http.cookiejar.MozillaCookieJar(cookies_path)
            cookie_jar.load()
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            cookies_dict = {}
            for cookie in cookie_jar:
                cookies_dict[cookie.name] = cookie.value
            
            logger.info(f"âœ… æˆåŠŸè½¬æ¢ cookiesï¼Œå…± {len(cookies_dict)} ä¸ª")
            return cookies_dict
            
        except Exception as e:
            logger.error(f"âŒ cookies è½¬æ¢å¤±è´¥: {e}")
            return {}

    async def download_with_gallery_dl(
        self, url: str, download_path: Path, message_updater=None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ gallery-dl ä¸‹è½½å›¾ç‰‡"""
        if not GALLERY_DL_AVAILABLE:
            return {
                "success": False,
                "error": "gallery-dl æœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½å›¾ç‰‡ã€‚è¯·è¿è¡Œ: pip install gallery-dl"
            }
        
        try:
            # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
            download_path.mkdir(parents=True, exist_ok=True)
            download_path_str = str(download_path)
            
            # ä½¿ç”¨æˆ‘ä»¬åˆ›å»ºçš„ gallery-dl.conf é…ç½®æ–‡ä»¶ - ä¸å®¹å™¨ä¸­å®Œå…¨ä¸€è‡´
            config_path = Path(self.download_path / "gallery-dl.conf")
            if config_path.exists():
                logger.info(f"ğŸ“„ ä½¿ç”¨ gallery-dl.conf é…ç½®æ–‡ä»¶: {config_path}")
                # åŠ è½½é…ç½®æ–‡ä»¶ - ä¸å®¹å™¨ä¸­å®Œå…¨ä¸€è‡´
                gallery_dl.config.load([str(config_path)])
            else:
                logger.warning(f"âš ï¸ gallery-dl.conf é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                return {
                    "success": False,
                    "error": "gallery-dl.conf é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
                }
            
            # è·å– gallery-dl å®é™…ä½¿ç”¨çš„ä¸‹è½½ç›®å½•
            try:
                # ç›´æ¥ä»é…ç½®æ–‡ä»¶ä¸­è¯»å– base-directory
                import json
                if config_path.exists():
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config_data = json.load(f)
                    actual_download_dir = config_data.get("base-directory", str(download_path))
                else:
                    actual_download_dir = str(download_path)
                logger.info(f"ğŸ¯ gallery-dl å®é™…ä¸‹è½½ç›®å½•: {actual_download_dir}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ— æ³•ä»é…ç½®æ–‡ä»¶è¯»å–ä¸‹è½½ç›®å½•: {e}")
                actual_download_dir = str(download_path)
                logger.info(f"ğŸ¯ ä½¿ç”¨é»˜è®¤ä¸‹è½½ç›®å½•: {actual_download_dir}")
            
            # è®°å½•ä¸‹è½½å‰çš„æ–‡ä»¶
            actual_download_path = Path(actual_download_dir)
            before_files = set()
            if actual_download_path.exists():
                for file_path in actual_download_path.rglob("*"):
                    if file_path.is_file():
                        relative_path = str(file_path.relative_to(actual_download_path))
                        before_files.add(relative_path)
            
            logger.info(f"ğŸ“Š ä¸‹è½½å‰æ–‡ä»¶æ•°é‡: {len(before_files)}")
            if before_files:
                logger.info(f"ğŸ“Š ä¸‹è½½å‰æ–‡ä»¶ç¤ºä¾‹: {list(before_files)[:5]}")
            
            # å‘é€å¼€å§‹ä¸‹è½½æ¶ˆæ¯
            if message_updater:
                try:
                    if asyncio.iscoroutinefunction(message_updater):
                        await message_updater("ğŸ–¼ï¸ **å›¾ç‰‡ä¸‹è½½ä¸­**\nğŸ“ å½“å‰ä¸‹è½½ï¼šå‡†å¤‡ä¸­...\nğŸ–¼ï¸ å·²å®Œæˆï¼š0 å¼ ")
                    else:
                        message_updater("ğŸ–¼ï¸ **å›¾ç‰‡ä¸‹è½½ä¸­**\nğŸ“ å½“å‰ä¸‹è½½ï¼šå‡†å¤‡ä¸­...\nğŸ–¼ï¸ å·²å®Œæˆï¼š0 å¼ ")
                except Exception as e:
                    logger.warning(f"âš ï¸ å‘é€å¼€å§‹æ¶ˆæ¯å¤±è´¥: {e}")
            
            # åˆ›å»ºè¿›åº¦ç›‘æ§ä»»åŠ¡
            progress_task = None
            if message_updater:
                progress_task = asyncio.create_task(self._monitor_gallery_dl_progress(
                    actual_download_path, before_files, message_updater
                ))
            
            # ä½¿ç”¨æ­£ç¡®çš„ gallery-dl API - ä¸å®¹å™¨ä¸­å®Œå…¨ä¸€è‡´
            job = gallery_dl.job.DownloadJob(url, None)
            
            logger.info("ğŸ“¸ gallery-dl å¼€å§‹ä¸‹è½½...")
            
            # æ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    # åœ¨å¼‚æ­¥æ‰§è¡Œå™¨ä¸­è¿è¡ŒåŒæ­¥çš„ job.run()ï¼Œè®©è¿›åº¦ç›‘æ§èƒ½å¤ŸæŒç»­è¿è¡Œ
                    loop = asyncio.get_running_loop()
                    await loop.run_in_executor(None, job.run)
                    
                    logger.info("ğŸ“¸ gallery-dl ä¸‹è½½ä»»åŠ¡å®Œæˆ")
                    break  # æˆåŠŸå®Œæˆï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    
                except Exception as e:
                    retry_count += 1
                    error_str = str(e).lower()
                    
                    if ("403" in error_str or "forbidden" in error_str) and retry_count < max_retries:
                        logger.warning(f"âš ï¸ é‡åˆ° 403 é”™è¯¯ï¼Œç¬¬ {retry_count} æ¬¡é‡è¯•...")
                        await asyncio.sleep(10)  # ç­‰å¾…10ç§’åé‡è¯•
                        continue
                    else:
                        # å…¶ä»–é”™è¯¯æˆ–é‡è¯•æ¬¡æ•°ç”¨å®Œï¼ŒæŠ›å‡ºå¼‚å¸¸
                        raise e
            
            # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
            await asyncio.sleep(3)
            
            # å–æ¶ˆè¿›åº¦ç›‘æ§ä»»åŠ¡
            if progress_task:
                progress_task.cancel()
                try:
                    await progress_task
                except asyncio.CancelledError:
                    logger.info("ğŸ“Š è¿›åº¦ç›‘æ§ä»»åŠ¡å·²å–æ¶ˆ")
                    pass
            
            # æŸ¥æ‰¾æ–°ä¸‹è½½çš„æ–‡ä»¶ï¼ˆåœ¨ gallery-dl å®é™…ä¸‹è½½ç›®å½•ä¸­ï¼‰
            downloaded_files = []
            total_size_bytes = 0
            file_formats = set()
            
            logger.info(f"ğŸ” å¼€å§‹æŸ¥æ‰¾æ–°ä¸‹è½½çš„æ–‡ä»¶...")
            logger.info(f"ğŸ” æŸ¥æ‰¾ç›®å½•: {actual_download_dir}")
            logger.info(f"ğŸ” ä¸‹è½½å‰æ–‡ä»¶æ•°é‡: {len(before_files)}")
            
            if actual_download_path.exists():
                # è·å–å½“å‰æ‰€æœ‰æ–‡ä»¶
                current_files = set()
                for file_path in actual_download_path.rglob("*"):
                    if file_path.is_file():
                        relative_path = str(file_path.relative_to(actual_download_path))
                        current_files.add(relative_path)
                
                logger.info(f"ğŸ” å½“å‰æ–‡ä»¶æ•°é‡: {len(current_files)}")
                
                # è®¡ç®—æ–°æ–‡ä»¶
                new_files = current_files - before_files
                logger.info(f"ğŸ” æ–°æ–‡ä»¶æ•°é‡: {len(new_files)}")
                
                # è®°å½•ä¸€äº›æ–°æ–‡ä»¶ä½œä¸ºç¤ºä¾‹
                if new_files:
                    sample_files = list(new_files)[:5]  # å‰5ä¸ªæ–‡ä»¶
                    logger.info(f"ğŸ” æ–°æ–‡ä»¶ç¤ºä¾‹: {sample_files}")
                    
                    # ç›´æ¥å¤„ç†æ–°æ–‡ä»¶ï¼Œä¸éœ€è¦é¢å¤–éå†
                    for relative_path in new_files:
                        file_path = actual_download_path / relative_path
                        if file_path.is_file():
                            # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡æˆ–è§†é¢‘æ–‡ä»¶
                            if file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.mp4', '.mov', '.avi', '.mkv']:
                                downloaded_files.append(file_path)
                                try:
                                    file_size = file_path.stat().st_size
                                    total_size_bytes += file_size
                                    file_formats.add(file_path.suffix.lower())
                                    logger.info(f"âœ… æ‰¾åˆ°ä¸‹è½½æ–‡ä»¶: {relative_path} ({file_size} bytes)")
                                except OSError as e:
                                    logger.warning(f"æ— æ³•è·å–æ–‡ä»¶å¤§å°: {file_path} - {e}")
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–°æ–‡ä»¶ï¼Œå°è¯•æŸ¥æ‰¾æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
                    logger.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ–°æ–‡ä»¶ï¼Œå°è¯•æŸ¥æ‰¾æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶...")
                    try:
                        recent_files = []
                        for file_path in actual_download_path.rglob("*"):
                            if file_path.is_file():
                                # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ˜¯å¦åœ¨æœ€è¿‘5åˆ†é’Ÿå†…
                                file_mtime = file_path.stat().st_mtime
                                if time.time() - file_mtime < 300:  # 5åˆ†é’Ÿ
                                    recent_files.append(file_path)
                        
                        logger.info(f"ğŸ” æœ€è¿‘5åˆ†é’Ÿå†…ä¿®æ”¹çš„æ–‡ä»¶æ•°é‡: {len(recent_files)}")
                        if recent_files:
                            logger.info(f"ğŸ” æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ç¤ºä¾‹: {[f.name for f in recent_files[:3]]}")
                            # å°†è¿™äº›æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ä½œä¸ºä¸‹è½½çš„æ–‡ä»¶
                            for file_path in recent_files:
                                if file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.mp4', '.mov', '.avi', '.mkv']:
                                    downloaded_files.append(file_path)
                                    try:
                                        file_size = file_path.stat().st_size
                                        total_size_bytes += file_size
                                        file_formats.add(file_path.suffix.lower())
                                        logger.info(f"âœ… æ‰¾åˆ°æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶: {file_path.name} ({file_size} bytes)")
                                    except OSError as e:
                                        logger.warning(f"æ— æ³•è·å–æ–‡ä»¶å¤§å°: {file_path} - {e}")
                    except Exception as e:
                        logger.error(f"âŒ æŸ¥æ‰¾æœ€è¿‘ä¿®æ”¹æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            else:
                logger.warning(f"âš ï¸ ä¸‹è½½ç›®å½•ä¸å­˜åœ¨: {actual_download_dir}")
            
            logger.info(f"ğŸ” æœ€ç»ˆæ‰¾åˆ°çš„ä¸‹è½½æ–‡ä»¶æ•°é‡: {len(downloaded_files)}")
            
            if downloaded_files:
                # è®¡ç®—æ€»å¤§å°
                size_mb = total_size_bytes / (1024 * 1024)
                
                # æ ¼å¼åŒ–æ–‡ä»¶æ ¼å¼æ˜¾ç¤º
                format_str = ", ".join(sorted(file_formats)) if file_formats else "æœªçŸ¥æ ¼å¼"
                
                # ç”Ÿæˆè¯¦ç»†çš„ç»“æœä¿¡æ¯
                result = {
                    "success": True,
                    "message": f"âœ… å›¾ç‰‡ä¸‹è½½å®Œæˆï¼\n\nğŸ–¼ï¸ å›¾ç‰‡æ•°é‡ï¼š{len(downloaded_files)} å¼ \nğŸ“ ä¿å­˜ä½ç½®ï¼š{actual_download_dir}\nğŸ’¾ æ€»å¤§å°ï¼š{size_mb:.1f} MB\nğŸ“„ æ–‡ä»¶æ ¼å¼ï¼š{format_str}",
                    "files_count": len(downloaded_files),
                    "failed_count": 0,
                    "files": [str(f) for f in downloaded_files],
                    "size_mb": size_mb,
                    "filename": downloaded_files[0].name if downloaded_files else "æœªçŸ¥æ–‡ä»¶",
                    "download_path": actual_download_dir,
                    "full_path": str(downloaded_files[0]) if downloaded_files else "",
                    "resolution": "å›¾ç‰‡",
                    "abr": None,
                    "file_formats": list(file_formats)
                }
                
                logger.info(f"âœ… gallery-dl ä¸‹è½½æˆåŠŸ: {len(downloaded_files)} ä¸ªæ–‡ä»¶, æ€»å¤§å°: {size_mb:.1f} MB")
                return result
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æ–°ä¸‹è½½çš„æ–‡ä»¶ï¼ŒæŸ¥æ‰¾ç›®å½•: {actual_download_dir}")
                logger.warning(f"âš ï¸ ä¸‹è½½å‰æ–‡ä»¶æ•°é‡: {len(before_files)}")
                return {
                    "success": False,
                    "error": "æœªæ‰¾åˆ°ä¸‹è½½çš„æ–‡ä»¶"
                }
                
        except Exception as e:
            logger.error(f"gallery-dl ä¸‹è½½å¤±è´¥: {e}")
            
            # ç‰¹æ®Šå¤„ç†ä¸åŒç±»å‹çš„é”™è¯¯
            error_str = str(e).lower()
            if "403" in error_str or "forbidden" in error_str:
                error_msg = (
                    f"âŒ è®¿é—®è¢«æ‹’ç» (403 Forbidden)\n\n"
                    f"å¯èƒ½çš„åŸå› ï¼š\n"
                    f"1. æœåŠ¡å™¨æ£€æµ‹åˆ°çˆ¬è™«è¡Œä¸º\n"
                    f"2. IPåœ°å€è¢«ä¸´æ—¶å°ç¦\n"
                    f"3. éœ€è¦ç‰¹å®šçš„è¯·æ±‚å¤´æˆ–cookies\n"
                    f"4. å†…å®¹éœ€è¦ç™»å½•æ‰èƒ½è®¿é—®\n\n"
                    f"å»ºè®®è§£å†³æ–¹æ¡ˆï¼š\n"
                    f"1. ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•\n"
                    f"2. æ£€æŸ¥cookiesæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ\n"
                    f"3. å°è¯•ä½¿ç”¨ä»£ç†\n"
                    f"4. è”ç³»ç®¡ç†å‘˜è·å–å¸®åŠ©"
                )
            elif "nsfw" in error_str or "authorizationerror" in error_str:
                error_msg = (
                    f"âŒ NSFWå†…å®¹ä¸‹è½½å¤±è´¥\n\n"
                    f"è¯·ç¡®ä¿ï¼š\n"
                    f"1. å·²é…ç½®æœ‰æ•ˆçš„X cookiesæ–‡ä»¶è·¯å¾„\n"
                    f"2. Xè´¦æˆ·å…è®¸æŸ¥çœ‹NSFWå†…å®¹\n"
                    f"3. è´¦æˆ·å·²å®Œæˆå¹´é¾„éªŒè¯\n"
                    f"4. cookiesæ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆNetscapeæ ¼å¼ï¼‰\n"
                    f"5. cookiesæ–‡ä»¶åŒ…å«æœ‰æ•ˆçš„è®¤è¯ä¿¡æ¯"
                )
            elif "timeout" in error_str or "connection" in error_str:
                error_msg = (
                    f"âŒ ç½‘ç»œè¿æ¥è¶…æ—¶\n\n"
                    f"å¯èƒ½çš„åŸå› ï¼š\n"
                    f"1. ç½‘ç»œè¿æ¥ä¸ç¨³å®š\n"
                    f"2. æœåŠ¡å™¨å“åº”æ…¢\n"
                    f"3. é˜²ç«å¢™é˜»æ­¢è¿æ¥\n\n"
                    f"å»ºè®®è§£å†³æ–¹æ¡ˆï¼š\n"
                    f"1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n"
                    f"2. ç¨åé‡è¯•\n"
                    f"3. å°è¯•ä½¿ç”¨ä»£ç†"
                )
            else:
                error_msg = f"âŒ gallery-dl ä¸‹è½½å¤±è´¥: {str(e)}"
            
            return {
                "success": False,
                "error": error_msg
            }
    
    async def _monitor_gallery_dl_progress(self, download_path: Path, before_files: set, message_updater):
        """ç›‘æ§ gallery-dl ä¸‹è½½è¿›åº¦"""
        try:
            last_count = 0
            last_update_time = time.time()
            update_interval = 3  # æ¯3ç§’æ›´æ–°ä¸€æ¬¡è¿›åº¦
            
            logger.info(f"ğŸ“Š å¼€å§‹ç›‘æ§ gallery-dl è¿›åº¦")
            logger.info(f"ğŸ“Š ç›‘æ§ç›®å½•: {download_path}")
            logger.info(f"ğŸ“Š ä¸‹è½½å‰æ–‡ä»¶æ•°é‡: {len(before_files)}")
            if before_files:
                logger.info(f"ğŸ“Š ä¸‹è½½å‰æ–‡ä»¶ç¤ºä¾‹: {list(before_files)[:3]}")
            
            while True:
                await asyncio.sleep(2)  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
                
                # è®¡ç®—å½“å‰æ–‡ä»¶æ•°é‡
                current_files = set()
                if download_path.exists():
                    for file_path in download_path.rglob("*"):
                        if file_path.is_file():
                            relative_path = str(file_path.relative_to(download_path))
                            current_files.add(relative_path)
                
                # è®¡ç®—æ–°æ–‡ä»¶æ•°é‡
                new_files = current_files - before_files
                current_count = len(new_files)
                
                logger.info(f"ğŸ“Š å½“å‰æ–‡ä»¶æ•°é‡: {len(current_files)}, æ–°æ–‡ä»¶æ•°é‡: {current_count}")
                if new_files:
                    logger.info(f"ğŸ“Š æ–°æ–‡ä»¶ç¤ºä¾‹: {list(new_files)[:3]}")
                
                # å¦‚æœæ–‡ä»¶æ•°é‡æœ‰å˜åŒ–æˆ–æ—¶é—´é—´éš”åˆ°äº†ï¼Œæ›´æ–°è¿›åº¦
                if current_count != last_count or time.time() - last_update_time > update_interval:
                    last_count = current_count
                    last_update_time = time.time()
                    
                    # è·å–å½“å‰æ­£åœ¨ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„
                    current_file_path = "å‡†å¤‡ä¸­..."
                    if new_files:
                        # è·å–æœ€æ–°çš„æ–‡ä»¶
                        latest_file = sorted(new_files)[-1]
                        # æ˜¾ç¤ºå®Œæ•´çš„ç›¸å¯¹è·¯å¾„
                        current_file_path = latest_file
                    
                    progress_text = (
                        f"ğŸ–¼ï¸ **å›¾ç‰‡ä¸‹è½½ä¸­**\n"
                        f"ğŸ“ å½“å‰ä¸‹è½½ï¼š`{current_file_path}`\n"
                        f"ğŸ–¼ï¸ å·²å®Œæˆï¼š{current_count} å¼ "
                    )
                    
                    try:
                        # æ£€æŸ¥message_updateræ˜¯å¦ä¸ºNone
                        if message_updater is None:
                            logger.warning(f"âš ï¸ message_updaterä¸ºNoneï¼Œè·³è¿‡è¿›åº¦æ›´æ–°")
                            continue
                        
                        # æ£€æŸ¥message_updaterçš„ç±»å‹å¹¶å®‰å…¨è°ƒç”¨
                        if asyncio.iscoroutinefunction(message_updater):
                            await message_updater(progress_text)
                        else:
                            message_updater(progress_text)
                        logger.info(f"ğŸ“Š gallery-dl è¿›åº¦æ›´æ–°: {current_count} å¼ å›¾ç‰‡, å½“å‰æ–‡ä»¶: {current_file_path}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ›´æ–°è¿›åº¦æ¶ˆæ¯å¤±è´¥: {e}")
                        # ä¸é€€å‡ºå¾ªç¯ï¼Œç»§ç»­ç›‘æ§
                        continue
                
        except asyncio.CancelledError:
            logger.info("ğŸ“Š è¿›åº¦ç›‘æ§ä»»åŠ¡å·²å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ è¿›åº¦ç›‘æ§ä»»åŠ¡é”™è¯¯: {e}")

    async def download_x_content(self, url: str, message: types.Message) -> dict:
        """ä¸‹è½½ X å†…å®¹ï¼ˆå›¾ç‰‡æˆ–è§†é¢‘ï¼‰"""
        logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½ X å†…å®¹: {url}")
        
        # æ£€æµ‹å†…å®¹ç±»å‹
        content_type = self._detect_x_content_type(url)
        logger.info(f"ğŸ“Š æ£€æµ‹åˆ°å†…å®¹ç±»å‹: {content_type}")
        
        if content_type == "video":
            # è§†é¢‘ä½¿ç”¨ yt-dlp ä¸‹è½½
            logger.info("ğŸ¬ ä½¿ç”¨ yt-dlp ä¸‹è½½ X è§†é¢‘")
            
            # åˆ›å»º message_updater å‡½æ•°
            async def message_updater(text_or_dict):
                try:
                    if isinstance(text_or_dict, dict):
                        await message.reply(str(text_or_dict))
                    else:
                        await message.reply(text_or_dict)
                except Exception as e:
                    logger.warning(f"âš ï¸ æ›´æ–°è¿›åº¦æ¶ˆæ¯å¤±è´¥: {e}")
            
            return await self._download_x_video_with_ytdlp(url, message_updater)
        else:
            # å›¾ç‰‡ä½¿ç”¨ gallery-dl ä¸‹è½½
            logger.info("ğŸ“¸ ä½¿ç”¨ gallery-dl ä¸‹è½½ X å›¾ç‰‡")
            return await self._download_x_image_with_gallerydl(url, message)

    async def _download_x_video_with_ytdlp(self, url: str, message_updater=None) -> dict:
        """ä½¿ç”¨ yt-dlp ä¸‹è½½ X è§†é¢‘"""
        return await self._download_with_ytdlp_unified(
            url=url,
            download_path=self.x_download_path,
            message_updater=message_updater,
            platform_name="X",
            content_type="video",
            format_spec="best[height<=1080]",
            cookies_path=self.x_cookies_path
        )



    async def _download_x_playlist(self, url: str, download_path: Path, message_updater=None, playlist_info: dict = None) -> Dict[str, Any]:
        """ä¸‹è½½Xæ’­æ”¾åˆ—è¡¨ä¸­çš„æ‰€æœ‰è§†é¢‘"""
        import os
        import time
        from pathlib import Path
        import asyncio
        
        logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½Xæ’­æ”¾åˆ—è¡¨: {url}")
        logger.info(f"ğŸ“Š æ’­æ”¾åˆ—è¡¨ä¿¡æ¯: {playlist_info}")
        
        if not playlist_info:
            return {'success': False, 'error': 'æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ä¸ºç©º'}
        
        total_videos = playlist_info.get('total_videos', 0)
        if total_videos == 0:
            return {'success': False, 'error': 'æ’­æ”¾åˆ—è¡¨ä¸­æ²¡æœ‰è§†é¢‘'}
        
        # è®°å½•ä¸‹è½½å¼€å§‹æ—¶é—´
        download_start_time = time.time()
        logger.info(f"â° ä¸‹è½½å¼€å§‹æ—¶é—´: {download_start_time}")
        
        # åˆ›å»ºè¿›åº¦è·Ÿè¸ª
        progress_data = {
            'current': 0,
            'total': total_videos,
            'start_time': download_start_time,
            'downloaded_files': []
        }
        
        # è®°å½•ä¸‹è½½å¼€å§‹æ—¶é—´
        download_start_time = time.time()
        logger.info(f"â° ä¸‹è½½å¼€å§‹æ—¶é—´: {download_start_time}")
        
        def create_playlist_progress_callback(progress_data):
            def escape_num(text):
                # åªè½¬ä¹‰MarkdownV2ç‰¹æ®Šå­—ç¬¦ï¼Œä¸è½¬ä¹‰å°æ•°ç‚¹
                special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
                for char in special_chars:
                    text = text.replace(char, f'\\{char}')
                return text
            
            def calculate_overall_progress():
                if progress_data['total'] == 0:
                    return 0
                return (progress_data['current'] / progress_data['total']) * 100
            
            def progress_callback(d):
                try:
                    current = progress_data['current']
                    total = progress_data['total']
                    overall_percent = calculate_overall_progress()
                    
                    if d.get('status') == 'finished':
                        progress_data['current'] += 1
                        current = progress_data['current']
                        overall_percent = calculate_overall_progress()

                        # è®°å½•ä¸‹è½½çš„æ–‡ä»¶å¹¶ç›‘æ§åˆå¹¶çŠ¶æ€
                        if 'filename' in d:
                            filename = d['filename']
                            progress_data['downloaded_files'].append(filename)

                            # ç›‘æ§æ–‡ä»¶åˆå¹¶çŠ¶æ€
                            if filename.endswith('.part'):
                                logger.warning(f"âš ï¸ æ–‡ä»¶åˆå¹¶å¯èƒ½å¤±è´¥: {filename}")
                            else:
                                logger.info(f"âœ… æ–‡ä»¶ä¸‹è½½å¹¶åˆå¹¶æˆåŠŸ: {filename}")
                    
                    # åˆ›å»ºè¿›åº¦æ¶ˆæ¯
                    progress_bar = self._make_progress_bar(overall_percent)
                    elapsed_time = time.time() - progress_data['start_time']
                    
                    status_text = f"ğŸ¬ Xæ’­æ”¾åˆ—è¡¨ä¸‹è½½è¿›åº¦\n"
                    status_text += f"ğŸ“Š æ€»ä½“è¿›åº¦: {progress_bar} {overall_percent:.1f}%\n"
                    status_text += f"ğŸ“¹ å½“å‰: {current}/{total} ä¸ªè§†é¢‘\n"
                    status_text += f"â±ï¸ å·²ç”¨æ—¶: {elapsed_time:.0f}ç§’\n"
                    
                    if d.get('status') == 'downloading':
                        if '_percent_str' in d:
                            status_text += f"ğŸ“¥ å½“å‰è§†é¢‘: {d.get('_percent_str', '0%')}\n"
                        if '_speed_str' in d:
                            status_text += f"ğŸš€ é€Ÿåº¦: {d.get('_speed_str', 'N/A')}\n"
                    
                    # è½¬ä¹‰Markdownç‰¹æ®Šå­—ç¬¦
                    escaped_text = escape_num(status_text)
                    
                    # ä½¿ç”¨asyncio.run_coroutine_threadsafeæ¥æ›´æ–°è¿›åº¦
                    try:
                        if message_updater:
                            # æ£€æŸ¥message_updaterçš„ç±»å‹
                            if asyncio.iscoroutinefunction(message_updater):
                                # å®‰å…¨åœ°è·å–äº‹ä»¶å¾ªç¯
                                try:
                                    loop = asyncio.get_running_loop()
                                except RuntimeError:
                                    try:
                                        loop = asyncio.get_event_loop()
                                    except RuntimeError:
                                        loop = asyncio.new_event_loop()
                                        asyncio.set_event_loop(loop)
                                
                                # è°ƒç”¨å¼‚æ­¥å‡½æ•°å¹¶è·å–åç¨‹å¯¹è±¡
                                coro = message_updater(escaped_text)
                                asyncio.run_coroutine_threadsafe(coro, loop)
                            else:
                                # å¦‚æœæ˜¯åŒæ­¥å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
                                message_updater(escaped_text)
                    except Exception as e:
                        if "Message is not modified" not in str(e):
                            logger.warning(f"âš ï¸ æ›´æ–°æ’­æ”¾åˆ—è¡¨è¿›åº¦å¤±è´¥: {e}")
                        # å¦‚æœmessage_updaterå¤±è´¥ï¼Œè®°å½•æ—¥å¿—
                        logger.info(f"è¿›åº¦æ›´æ–°: {escaped_text}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ æ›´æ–°æ’­æ”¾åˆ—è¡¨è¿›åº¦å¤±è´¥: {e}")
            
            return progress_callback
        
        try:
            # ä½¿ç”¨å¢å¼ºçš„yt-dlpé…ç½®ä¸‹è½½æ•´ä¸ªæ’­æ”¾åˆ—è¡¨
            base_opts = {
                'outtmpl': str(download_path / '%(title)s.%(ext)s'),
                'format': 'best[height<=1080]',
                'progress_hooks': [create_playlist_progress_callback(progress_data)],
            }

            # è·å–å¢å¼ºé…ç½®ï¼Œé¿å…PARTæ–‡ä»¶
            ydl_opts = self._get_enhanced_ydl_opts(base_opts)
            logger.info("ğŸ›¡ï¸ ä½¿ç”¨å¢å¼ºé…ç½®ï¼Œé¿å…PARTæ–‡ä»¶äº§ç”Ÿ")

            # ä¸‹è½½æ’­æ”¾åˆ—è¡¨
            loop = asyncio.get_running_loop()
            try:
                await loop.run_in_executor(None, lambda: yt_dlp.YoutubeDL(ydl_opts).download([url]))

                # ä¸‹è½½å®Œæˆåæ£€æŸ¥å¹¶å¤„ç†PARTæ–‡ä»¶
                logger.info("ğŸ” æ£€æŸ¥ä¸‹è½½å®ŒæˆçŠ¶æ€...")
                resume_success = self._resume_failed_downloads(download_path, url, max_retries=2)

                if not resume_success:
                    logger.warning("âš ï¸ éƒ¨åˆ†æ–‡ä»¶ä¸‹è½½æœªå®Œæˆï¼Œä½†å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                else:
                    logger.info("âœ… æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å®Œæˆ")

            except Exception as e:
                logger.error(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                # å³ä½¿å‡ºé”™ä¹Ÿå°è¯•æ–­ç‚¹ç»­ä¼ PARTæ–‡ä»¶
                logger.info("ğŸ”„ å°è¯•æ–­ç‚¹ç»­ä¼ æœªå®Œæˆçš„æ–‡ä»¶...")
                self._resume_part_files(download_path, url)
            
            await asyncio.sleep(1)
            
            # ä½¿ç”¨progress_dataä¸­è®°å½•çš„æ–‡ä»¶åˆ—è¡¨æ¥æ£€æµ‹ä¸‹è½½çš„æ–‡ä»¶
            video_files = []
            downloaded_files = progress_data.get('downloaded_files', [])
            logger.info(f"ğŸ“Š progress_dataä¸­è®°å½•çš„æ–‡ä»¶: {downloaded_files}")
            
            # é¦–å…ˆå°è¯•ä½¿ç”¨progress_dataä¸­è®°å½•çš„æ–‡ä»¶
            if downloaded_files:
                for filename in downloaded_files:
                    file_path = download_path / filename
                    if file_path.exists():
                        video_files.append((file_path, os.path.getmtime(file_path)))
                        logger.info(f"âœ… æ‰¾åˆ°æœ¬æ¬¡ä¸‹è½½æ–‡ä»¶: {filename}")
                    else:
                        logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            
            # å¦‚æœprogress_dataä¸­æ²¡æœ‰è®°å½•ï¼Œåˆ™ä½¿ç”¨æ—¶é—´æ£€æµ‹
            if not video_files:
                logger.info("ğŸ”„ ä½¿ç”¨æ—¶é—´æ£€æµ‹æ–¹æ³•æŸ¥æ‰¾ä¸‹è½½æ–‡ä»¶")
                for file in download_path.glob("*.mp4"):
                    try:
                        mtime = os.path.getmtime(file)
                        # å¦‚æœæ–‡ä»¶ä¿®æ”¹æ—¶é—´åœ¨ä¸‹è½½å¼€å§‹æ—¶é—´ä¹‹åï¼Œè®¤ä¸ºæ˜¯æœ¬æ¬¡ä¸‹è½½çš„æ–‡ä»¶
                        if mtime >= download_start_time:
                            video_files.append((file, mtime))
                            logger.info(f"âœ… æ‰¾åˆ°æœ¬æ¬¡ä¸‹è½½æ–‡ä»¶: {file.name}, ä¿®æ”¹æ—¶é—´: {mtime}")
                    except OSError:
                        continue
            
            video_files.sort(key=lambda x: x[0].name)

            # æ£€æµ‹PARTæ–‡ä»¶
            part_files = self._detect_part_files(download_path)
            success_count = len(video_files)
            part_count = len(part_files)

            # åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
            logger.info(f"ğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡ï¼š")
            logger.info(f"âœ… æˆåŠŸæ–‡ä»¶ï¼š{success_count} ä¸ª")
            if part_count > 0:
                logger.warning(f"âš ï¸ æœªå®Œæˆæ–‡ä»¶ï¼š{part_count} ä¸ª")
                self._log_part_files_details(part_files)
            else:
                logger.info("âœ… æœªå‘ç°PARTæ–‡ä»¶ï¼Œæ‰€æœ‰ä¸‹è½½éƒ½å·²å®Œæˆ")

            if video_files:
                total_size_mb = 0
                file_info_list = []
                all_resolutions = set()
                
                for file_path, mtime in video_files:
                    size_mb = os.path.getsize(file_path) / (1024 * 1024)
                    total_size_mb += size_mb
                    media_info = self.get_media_info(str(file_path))
                    resolution = media_info.get('resolution', 'æœªçŸ¥')
                    if resolution != 'æœªçŸ¥':
                        all_resolutions.add(resolution)
                    file_info_list.append({
                        'filename': os.path.basename(file_path),
                        'size_mb': size_mb,
                        'resolution': resolution,
                        'abr': media_info.get('bit_rate')
                    })
                
                filename_list = [info['filename'] for info in file_info_list]
                filename_display = '\n'.join([f"  {i+1:02d}. {name}" for i, name in enumerate(filename_list)])
                resolution_display = ', '.join(sorted(all_resolutions)) if all_resolutions else 'æœªçŸ¥'
                
                return {
                    'success': True,
                    'is_playlist': True,
                    'file_count': len(video_files),
                    'total_size_mb': total_size_mb,
                    'files': file_info_list,
                    'platform': 'X',
                    'download_path': str(download_path),
                    'filename': filename_display,
                    'size_mb': total_size_mb,
                    'resolution': resolution_display,
                    'episode_count': len(video_files),
                    # æ·»åŠ PARTæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
                    'success_count': success_count,
                    'part_count': part_count,
                    'part_files': [str(pf) for pf in part_files] if part_files else []
                }
            else:
                return {'success': False, 'error': 'Xæ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆä½†æœªæ‰¾åˆ°æœ¬æ¬¡ä¸‹è½½çš„æ–‡ä»¶'}
                
        except Exception as e:
            logger.error(f"âŒ Xæ’­æ”¾åˆ—è¡¨ä¸‹è½½å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
        finally:
            # è®°å½•ä¸‹è½½å®Œæˆæ—¶é—´
            download_end_time = time.time()
            total_time = download_end_time - download_start_time
            logger.info(f"â° ä¸‹è½½å®Œæˆæ—¶é—´: {download_end_time}, æ€»ç”¨æ—¶: {total_time:.1f}ç§’")

    async def _download_x_image_with_gallerydl(self, url: str, message: types.Message) -> dict:
        """ä½¿ç”¨ gallery-dl ä¸‹è½½ X å›¾ç‰‡ï¼Œé‡åˆ°NSFWé”™è¯¯æ—¶fallbackåˆ°yt-dlp"""
        try:
            # åˆ›å»º message_updater å‡½æ•°
            async def message_updater(text_or_dict):
                try:
                    if isinstance(text_or_dict, dict):
                        await message.reply(str(text_or_dict))
                    else:
                        await message.reply(text_or_dict)
                except Exception as e:
                    logger.warning(f"âš ï¸ æ›´æ–°è¿›åº¦æ¶ˆæ¯å¤±è´¥: {e}")
            
            # ä½¿ç”¨ç°æœ‰çš„ download_with_gallery_dl å‡½æ•°ï¼Œä¼ é€’ message_updater
            download_path = self.x_download_path
            result = await self.download_with_gallery_dl(url, download_path, message_updater)
            
            if result.get("success"):
                return {
                    "success": True,
                    "platform": "X",
                    "content_type": "image",
                    "download_path": result.get("download_path", ""),
                    "full_path": result.get("full_path", ""),
                    "filename": result.get("filename", ""),
                    "size_mb": result.get("size_mb", 0),
                    "title": f"Xå›¾ç‰‡ ({result.get('files_count', 0)}å¼ )",
                    "resolution": "å›¾ç‰‡",  # æ·»åŠ  resolution å­—æ®µï¼Œç¡®ä¿è¯†åˆ«ä¸ºå›¾ç‰‡
                    "files_count": result.get("files_count", 0),
                    "file_formats": result.get("file_formats", []),
                }
            else:
                # æ£€æŸ¥æ˜¯å¦ä¸ºNSFWé”™è¯¯ï¼Œå¦‚æœæ˜¯åˆ™è¿”å›é”™è¯¯ä¿¡æ¯
                error_msg = result.get("error", "")
                if "NSFW" in error_msg or "AuthorizationError" in error_msg:
                    logger.info("ğŸ”„ æ£€æµ‹åˆ°NSFWé”™è¯¯ï¼Œgallery-dlæ— æ³•ä¸‹è½½æ­¤å†…å®¹")
                    return {
                        "success": False,
                        "error": "æ­¤å†…å®¹åŒ…å«NSFWå†…å®¹ï¼Œæ— æ³•ä¸‹è½½",
                        "platform": "X",
                        "content_type": "image"
                    }
                else:
                    return result
                    
        except Exception as e:
            logger.error(f"âŒ gallery-dl ä¸‹è½½ X å›¾ç‰‡å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"gallery-dl ä¸‹è½½å¤±è´¥: {str(e)}",
                "platform": "X",
                "content_type": "image"
            }



    async def _download_xiaohongshu_with_playwright(self, url: str, message: types.Message, message_updater=None) -> dict:
        """ä½¿ç”¨ Playwright ä¸‹è½½å°çº¢ä¹¦è§†é¢‘"""
        # è‡ªåŠ¨æå–å°çº¢ä¹¦é“¾æ¥
        real_url = extract_xiaohongshu_url(url)
        if real_url:
            url = real_url
        else:
            logger.warning('æœªæ£€æµ‹åˆ°å°çº¢ä¹¦é“¾æ¥ï¼ŒåŸæ ·ä½¿ç”¨å‚æ•°')
        if not PLAYWRIGHT_AVAILABLE:
            return {
                "success": False,
                "error": "Playwright æœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½å°çº¢ä¹¦è§†é¢‘",
                "platform": "Xiaohongshu",
                "content_type": "video"
            }
        
        try:
            from playwright.async_api import async_playwright
            import httpx
            from dataclasses import dataclass
            from typing import Optional
            from enum import Enum
            import re
            import time
            
            # æ•°æ®ç±»å®šä¹‰
            @dataclass
            class VideoInfo:
                video_id: str
                platform: str
                share_url: str
                download_url: Optional[str] = None
                title: Optional[str] = None
                author: Optional[str] = None
                create_time: Optional[str] = None
                quality: Optional[str] = None
                thumbnail_url: Optional[str] = None
            
            # ä½¿ç”¨ç±»çº§åˆ«çš„ Platform æšä¸¾
            
            # æ£€æµ‹å¹³å°
            def detect_platform(url: str) -> VideoDownloader.Platform:
                if any(domain in url.lower() for domain in ['douyin.com', 'iesdouyin.com']):
                    return VideoDownloader.Platform.DOUYIN
                elif any(domain in url.lower() for domain in ['kuaishou.com']):
                    return VideoDownloader.Platform.KUAISHOU
                elif any(domain in url.lower() for domain in ['xiaohongshu.com', 'xhslink.com']):
                    return VideoDownloader.Platform.XIAOHONGSHU
                else:
                    return VideoDownloader.Platform.UNKNOWN
            
            platform = VideoDownloader.Platform.XIAOHONGSHU
            
            # å‘é€å¼€å§‹ä¸‹è½½æ¶ˆæ¯ï¼ˆå¦‚æœbotå¯ç”¨ï¼‰
            start_message = None
            if hasattr(self, 'bot') and self.bot:
                try:
                    start_message = await self.bot.send_message(
                        message.chat.id,
                        f"ğŸ¬ å¼€å§‹ä¸‹è½½{platform.value}è§†é¢‘..."
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ å‘é€å¼€å§‹æ¶ˆæ¯å¤±è´¥: {e}")
            else:
                logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½{platform.value}è§†é¢‘...")
            
            # å°çº¢ä¹¦ä¸‹è½½ç›®å½•
            download_dir = str(self.xiaohongshu_download_path)
            
            os.makedirs(download_dir, exist_ok=True)
            
            # ä½¿ç”¨ Playwright æå–è§†é¢‘ä¿¡æ¯
            async with async_playwright() as p:
                # å°çº¢ä¹¦ä¸éœ€è¦ cookies
                
                # å°çº¢ä¹¦æµè§ˆå™¨é…ç½® - å‚è€ƒdouyin.py
                browser = await p.chromium.launch(headless=True)
                context = await browser.new_context(
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
                    viewport={'width': 1920, 'height': 1080},
                    device_scale_factor=1,
                    locale='zh-CN',
                    timezone_id='Asia/Shanghai',
                    is_mobile=False,
                    has_touch=False,
                    color_scheme='light',
                    extra_http_headers={
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,video/mp4,*/*;q=0.8',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                    }
                )
                
                # å°çº¢ä¹¦ä¸éœ€è¦ cookies
                
                page = await context.new_page()
                
                # è®¾ç½®å¹³å°ç‰¹å®šçš„è¯·æ±‚å¤´
                await self._set_platform_headers(page, platform)
                
                # ç›‘å¬ç½‘ç»œè¯·æ±‚ï¼Œæ•è·å°çº¢ä¹¦è§†é¢‘URL
                video_url_holder = {'url': None}
                def handle_request(request):
                    req_url = request.url
                    if any(ext in req_url.lower() for ext in ['.mp4', '.m3u8']):
                        if 'xhscdn.com' in req_url or 'xiaohongshu.com' in req_url:
                            # åªä¿å­˜ç¬¬ä¸€ä¸ªæ•è·åˆ°çš„è§†é¢‘URLï¼Œé¿å…è¢«åç»­è¯·æ±‚è¦†ç›–
                            if not video_url_holder['url']:
                                video_url_holder['url'] = req_url
                                logger.info(f"[cat-catch] å—…æ¢åˆ°å°çº¢ä¹¦è§†é¢‘æµ: {req_url}")
                page.on("request", handle_request)
                
                # è®¿é—®é¡µé¢ - å‚è€ƒdouyin.pyçš„å®ç°
                logger.info("[extract] goto å‰")
                await page.goto(url, wait_until="domcontentloaded", timeout=30000)
                logger.info("[extract] goto åï¼Œå¼€å§‹æé€Ÿå—…æ¢")

                # æé€Ÿå—…æ¢ï¼šåªç›‘å¬networkï¼Œä¸åšä»»ä½•äº¤äº’ - å‚è€ƒdouyin.py
                for _ in range(5):  # 1.5ç§’å†…ç›‘å¬
                    if video_url_holder['url']:
                        logger.info(f"[cat-catch][fast] æé€Ÿå—…æ¢åˆ°å°çº¢ä¹¦è§†é¢‘æµ: {video_url_holder['url']}")
                        # ç«‹å³è·å–æ ‡é¢˜å’Œä½œè€…ï¼Œå‚è€ƒdouyin.py
                        title = await self._get_video_title(page, platform)
                        author = await self._get_video_author(page, platform)
                        # ç›´æ¥è¿”å›ç»“æœï¼Œä¸ç»§ç»­åç»­é€»è¾‘
                        video_info = VideoInfo(
                            video_id=str(int(time.time())),
                            platform=platform.value,
                            share_url=url,
                            download_url=video_url_holder['url'],
                            title=title,
                            author=author
                        )
                        logger.info("[cat-catch][fast] æé€Ÿå—…æ¢æµç¨‹å®Œæˆ")
                        # å…³é—­æµè§ˆå™¨
                        await page.close()
                        await context.close()
                        await browser.close()
                        
                        # ä¸‹è½½è§†é¢‘
                        return await self._download_video_file(video_info, download_dir, message_updater, start_message)
                    await asyncio.sleep(0.3)
                # å…œåº•ï¼šæœªæ•è·åˆ°æµï¼Œç›´æ¥è¿›å…¥æ­£åˆ™/å…¶å®ƒé€»è¾‘ï¼ˆä¸å†åšè‡ªåŠ¨äº¤äº’ï¼‰
                
                # æ£€æŸ¥æ˜¯å¦æ•è·åˆ°è§†é¢‘URL
                if not video_url_holder['url']:
                    logger.warning(f"âš ï¸ ç½‘ç»œå—…æ¢æœªæ•è·åˆ°å°çº¢ä¹¦è§†é¢‘æµ")
                else:
                    logger.info(f"âœ… ç½‘ç»œå—…æ¢æˆåŠŸæ•è·åˆ°å°çº¢ä¹¦è§†é¢‘æµ: {video_url_holder['url']}")
                
                # å¦‚æœç½‘ç»œå—…æ¢å¤±è´¥ï¼Œå°è¯•ä»é¡µé¢æå–
                if not video_url_holder['url']:
                    html = await page.content()
                    logger.info(f"ğŸ” å¼€å§‹ä»HTMLæå–å°çº¢ä¹¦è§†é¢‘ç›´é“¾...")
                    
                    # å°çº¢ä¹¦HTMLæ­£åˆ™æå– - å‚è€ƒdouyin.pyçš„ç®€åŒ–æ¨¡å¼
                    patterns = [
                        r'(https://sns-[^"\']+\.xhscdn\.com/stream/[^"\']+\.mp4)',
                        r'(https://ci[^"\']+\.xhscdn\.com/[^"\']+\.mp4)',
                        r'(https://[^"\']+\.xhscdn\.com/[^"\']+\.mp4)',
                        r'"videoUrl":"(https://[^"\\]+)"',
                        r'"video_url":"(https://[^"\\]+)"',
                        r'"url":"(https://[^"\\]+\.mp4)"'
                    ]
                    
                    # ç›´æ¥ä½¿ç”¨HTMLæ­£åˆ™æå– - å‚è€ƒdouyin.pyçš„ç®€å•æ–¹æ³•
                    for i, pattern in enumerate(patterns):
                        m = re.search(pattern, html)
                        if m:
                            url = m.group(1).replace('\\u002F', '/').replace('\\u0026', '&')
                            # éªŒè¯URLæ˜¯å¦æœ‰æ•ˆï¼Œå¹¶ä¸”ç½‘ç»œå—…æ¢æ²¡æœ‰æ•è·åˆ°URLæ—¶æ‰ä½¿ç”¨
                            if self._is_valid_xiaohongshu_url(url) and not video_url_holder['url']:
                                video_url_holder['url'] = url
                                logger.info(f"âœ… ä½¿ç”¨æ¨¡å¼{i+1}æå–åˆ°å°çº¢ä¹¦è§†é¢‘URL: {url}")
                                break
                            elif self._is_valid_xiaohongshu_url(url) and video_url_holder['url']:
                                logger.info(f"âš ï¸ ç½‘ç»œå—…æ¢å·²æ•è·åˆ°URLï¼Œè·³è¿‡HTMLæå–çš„URL: {url}")
                                break
                
                # å¦‚æœHTMLæå–æˆåŠŸï¼Œè·å–æ ‡é¢˜å’Œä½œè€…
                title = None
                author = None
                if video_url_holder['url']:
                    try:
                        title = await self._get_video_title(page, platform)
                        author = await self._get_video_author(page, platform)
                        logger.info(f"ğŸ“ è·å–åˆ°æ ‡é¢˜: {title}")
                        logger.info(f"ğŸ‘¤ è·å–åˆ°ä½œè€…: {author}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ è·å–æ ‡é¢˜å’Œä½œè€…å¤±è´¥: {e}")
                
                # å…³é—­æµè§ˆå™¨
                await page.close()
                await context.close()
                await browser.close()
                
                if not video_url_holder['url']:
                    # å¦‚æœä»ç„¶æ²¡æœ‰è·å–åˆ°è§†é¢‘URLï¼Œä¿å­˜è°ƒè¯•ä¿¡æ¯
                    debug_html_path = f"/tmp/xiaohongshu_debug_{int(time.time())}.html"
                    try:
                        with open(debug_html_path, 'w', encoding='utf-8') as f:
                            f.write(html)
                        logger.error(f"âŒ æ— æ³•æå–å°çº¢ä¹¦è§†é¢‘ç›´é“¾ï¼Œå·²ä¿å­˜è°ƒè¯•HTMLåˆ°: {debug_html_path}")
                    except Exception as e:
                        logger.error(f"âŒ æ— æ³•æå–å°çº¢ä¹¦è§†é¢‘ç›´é“¾ï¼Œä¿å­˜è°ƒè¯•æ–‡ä»¶å¤±è´¥: {e}")
                    
                    raise Exception(f"æ— æ³•æå–å°çº¢ä¹¦è§†é¢‘ç›´é“¾ï¼Œè¯·æ£€æŸ¥é“¾æ¥æœ‰æ•ˆæ€§")
                
                # åˆ›å»ºVideoInfoå¯¹è±¡
                video_info = VideoInfo(
                    video_id=str(int(time.time())),
                    platform=platform.value,
                    share_url=url,
                    download_url=video_url_holder['url'],
                    title=title,
                    author=author
                )
                
                # ä½¿ç”¨ç»Ÿä¸€çš„ä¸‹è½½æ–¹æ³•
                result = await self._download_video_file(video_info, download_dir, message_updater, start_message)
                
                if not result.get("success"):
                    raise Exception(result.get("error", "ä¸‹è½½å¤±è´¥"))
                
                # åˆ é™¤å¼€å§‹æ¶ˆæ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if start_message and hasattr(self, 'bot') and self.bot:
                    try:
                        await start_message.delete()
                    except Exception as e:
                        logger.warning(f"âš ï¸ åˆ é™¤å¼€å§‹æ¶ˆæ¯å¤±è´¥: {e}")
                
                # æ–‡ä»¶ä¿¡æ¯ç°åœ¨åœ¨ _download_video_file æ–¹æ³•ä¸­å¤„ç†
                logger.info(f"âœ… {platform.value}è§†é¢‘ä¸‹è½½æˆåŠŸ")
                
                # è¿”å›ä¸‹è½½ç»“æœ
                return result
                
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ Playwright ä¸‹è½½å°çº¢ä¹¦è§†é¢‘å¤±è´¥: {error_msg}")
            
            # åˆ é™¤å¼€å§‹æ¶ˆæ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'start_message' in locals() and start_message and hasattr(self, 'bot') and self.bot:
                try:
                    await self.bot.delete_message(message.chat.id, start_message.message_id)
                except Exception as del_e:
                    logger.warning(f"âš ï¸ åˆ é™¤å¼€å§‹æ¶ˆæ¯å¤±è´¥: {del_e}")
            
            return {
                "success": False,
                "error": f"Playwright ä¸‹è½½å¤±è´¥: {error_msg}",
                "platform": "Xiaohongshu",
                "content_type": "video"
            }
    
    async def _extract_douyin_url_from_html(self, html: str) -> Optional[str]:
        """ä»æŠ–éŸ³HTMLæºç ä¸­æå–è§†é¢‘ç›´é“¾ - ä½¿ç”¨ç®€å•æœ‰æ•ˆçš„é€»è¾‘"""
        try:
            logger.info(f"[extract] HTMLé•¿åº¦: {len(html)} å­—ç¬¦")
            
            # æŸ¥æ‰¾åŒ…å«è§†é¢‘æ•°æ®çš„scriptæ ‡ç­¾
            script_matches = re.findall(r'<script[^>]*>(.*?)</script>', html, re.DOTALL)
            
            for script_content in script_matches:
                if 'aweme_id' in script_content and 'status_code' in script_content:
                    # å°è¯•æå–JSONéƒ¨åˆ†
                    json_matches = re.findall(r'({.*?"errors":\s*null\s*})', script_content, re.DOTALL)
                    for json_str in json_matches:
                        try:
                            # æ¸…ç†JSON
                            brace_count = 0
                            json_end = -1
                            for i, char in enumerate(json_str):
                                if char == '{':
                                    brace_count += 1
                                elif char == '}':
                                    brace_count -= 1
                                    if brace_count == 0:
                                        json_end = i + 1
                                        break
                            
                            if json_end > 0:
                                clean_json = json_str[:json_end]
                                data = json.loads(clean_json)
                                
                                # ä¸“é—¨æŸ¥æ‰¾videoå­—æ®µä¸­çš„æ— æ°´å°è§†é¢‘URL
                                def find_video_url(obj):
                                    if isinstance(obj, dict):
                                        for key, value in obj.items():
                                            # ä¸“é—¨æŸ¥æ‰¾videoå­—æ®µ
                                            if key == "video" and isinstance(value, dict):
                                                logger.info(f"[extract] æ‰¾åˆ°videoå­—æ®µ: {list(value.keys())}")
                                                
                                                # ä¼˜å…ˆæŸ¥æ‰¾play_urlå­—æ®µï¼ˆæ— æ°´å°ï¼‰
                                                if "play_url" in value:
                                                    play_url = value["play_url"]
                                                    logger.info(f"[extract] play_urlå­—æ®µå†…å®¹: {play_url}")
                                                    logger.info(f"[extract] play_urlç±»å‹: {type(play_url)}")
                                                    # å¤„ç†play_urlå­—å…¸æ ¼å¼
                                                    if isinstance(play_url, dict) and "url_list" in play_url:
                                                        url_list = play_url["url_list"]
                                                        if isinstance(url_list, list) and url_list:
                                                            video_url = url_list[0]
                                                            if video_url.startswith("http"):
                                                                logger.info(f"[extract] ä»play_url.url_listæ‰¾åˆ°æ— æ°´å°è§†é¢‘URL: {video_url}")
                                                                return video_url
                                                    # å¤„ç†play_urlå­—ç¬¦ä¸²æ ¼å¼
                                                    elif isinstance(play_url, str) and play_url.startswith("http"):
                                                        if any(ext in play_url.lower() for ext in [".mp4", ".m3u8", ".ts", "douyinvod.com", "snssdk.com"]):
                                                            logger.info(f"[extract] æ‰¾åˆ°æ— æ°´å°è§†é¢‘URL: {play_url}")
                                                            return play_url
                                                
                                                # å…œåº•ï¼šå¦‚æœæ²¡æœ‰play_urlï¼Œå†æŸ¥æ‰¾play_addrå­—æ®µï¼ˆæœ‰æ°´å°ï¼‰
                                                if "play_addr" in value:
                                                    play_addr = value["play_addr"]
                                                    logger.info(f"[extract] play_addrå­—æ®µå†…å®¹: {play_addr}")
                                                    logger.info(f"[extract] play_addrç±»å‹: {type(play_addr)}")
                                                    # å¤„ç†play_addrå­—å…¸æ ¼å¼
                                                    if isinstance(play_addr, dict) and "url_list" in play_addr:
                                                        url_list = play_addr["url_list"]
                                                        if isinstance(url_list, list) and url_list:
                                                            video_url = url_list[0]
                                                            if video_url.startswith("http"):
                                                                logger.info(f"[extract] ä»play_addr.url_listæ‰¾åˆ°æœ‰æ°´å°è§†é¢‘URL: {video_url}")
                                                                return video_url
                                                    # æŸ¥æ‰¾playAddr
                                                    if isinstance(play_addr, list) and play_addr:
                                                        video_url = play_addr[0]
                                                        if video_url.startswith("http") and any(ext in video_url.lower() for ext in [".mp4", ".m3u8", ".ts", "douyinvod.com", "snssdk.com"]):
                                                            logger.info(f"[extract] æ‰¾åˆ°æœ‰æ°´å°è§†é¢‘URL: {video_url}")
                                                            return video_url
                                                    elif isinstance(play_addr, str) and play_addr.startswith("http"):
                                                        if any(ext in play_addr.lower() for ext in [".mp4", ".m3u8", ".ts", "douyinvod.com", "snssdk.com"]):
                                                            logger.info(f"[extract] æ‰¾åˆ°æœ‰æ°´å°è§†é¢‘URL: {play_addr}")
                                                            return play_addr
                                            elif isinstance(value, (dict, list)):
                                                result = find_video_url(value)
                                                if result:
                                                    return result
                                    elif isinstance(obj, list):
                                        for item in obj:
                                            result = find_video_url(item)
                                            if result:
                                                return result
                                    return None
                                
                                video_url = find_video_url(data)
                                if video_url:
                                    return video_url
                                    
                        except json.JSONDecodeError:
                            continue
            
            return None
            
        except Exception as e:
            logger.warning(f"æŠ–éŸ³HTMLæ­£åˆ™æå–å¤±è´¥: {str(e)}")
        return None

    async def _get_douyin_no_watermark_url(self, video_id: str) -> str:
        """é€šè¿‡æŠ–éŸ³å®˜æ–¹æ¥å£è·å–æ— æ°´å°è§†é¢‘ç›´é“¾"""
        try:
            # æŠ–éŸ³å®˜æ–¹APIåˆ—è¡¨
            apis = [
                f'https://aweme.snssdk.com/aweme/v1/play/?video_id={video_id}&ratio=1080p&line=1',
                f'https://aweme.snssdk.com/aweme/v1/play/?video_id={video_id}&ratio=720p&line=0',
                f'https://aweme.snssdk.com/aweme/v1/play/?video_id={video_id}&ratio=540p&line=2',
                f'https://aweme.snssdk.com/aweme/v1/play/?video_id={video_id}&ratio=1080p&line=0',
                f'https://aweme.snssdk.com/aweme/v1/play/?video_id={video_id}&ratio=720p&line=1',
            ]
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
                'Accept': '*/*',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Referer': 'https://www.douyin.com/',
                'Connection': 'keep-alive',
                'Range': 'bytes=0-1',  # åªè¯·æ±‚å¼€å¤´1ä¸ªå­—èŠ‚ï¼ŒéªŒè¯å¯è®¿é—®æ€§
            }

            async def validate_url(api_url: str) -> Optional[str]:
                """éªŒè¯å•ä¸ªAPI URLçš„å¯ç”¨æ€§ï¼Œæ£€æŸ¥content-length"""
                try:
                    async with httpx.AsyncClient(follow_redirects=True, timeout=5.0) as client:
                        # å…ˆç”¨ HEAD è¯·æ±‚å¿«é€ŸéªŒè¯
                        try:
                            head_resp = await client.head(
                                api_url,
                                headers=headers,
                                timeout=3.0
                            )
                            if head_resp.status_code in [200, 206]:
                                # æ£€æŸ¥content-lengthï¼Œå¦‚æœä¸º0åˆ™è®¤ä¸ºAPIå¤±æ•ˆ
                                content_length = int(head_resp.headers.get("content-length", 0))
                                if content_length > 0:
                                    logger.info(f"[douyin_api] HEADè¯·æ±‚æˆåŠŸ: {api_url} (å¤§å°: {content_length})")
                                    return api_url
                                else:
                                    logger.warning(f"[douyin_api] HEADè¯·æ±‚æˆåŠŸä½†content-lengthä¸º0: {api_url}")
                                    return None
                        except Exception:
                            pass  # HEAD å¤±è´¥å°±ç”¨ GET è¯•è¯•

                        # HEAD å¤±è´¥çš„è¯ç”¨ GET è¯·æ±‚é‡è¯•
                        resp = await client.get(
                            api_url,
                            headers=headers,
                            timeout=3.0
                        )
                        if resp.status_code in [200, 206]:
                            content_length = int(resp.headers.get("content-length", 0))
                            if content_length > 0:
                                logger.info(f"[douyin_api] GETè¯·æ±‚æˆåŠŸ: {api_url} (å¤§å°: {content_length})")
                                return api_url
                            else:
                                logger.warning(f"[douyin_api] GETè¯·æ±‚æˆåŠŸä½†content-lengthä¸º0: {api_url}")
                                return None
                        
                except Exception as e:
                    logger.warning(f"[douyin_api] éªŒè¯å¤±è´¥: {api_url} - {str(e)}")
                return None

            # æœ€å¤šé‡è¯•2æ¬¡
            for attempt in range(2):
                try:
                    logger.info(f"[douyin_api] ç¬¬{attempt + 1}æ¬¡å°è¯•éªŒè¯API")
                    # å¹¶å‘éªŒè¯æ‰€æœ‰API
                    tasks = [validate_url(api) for api in apis]
                    results = await asyncio.gather(*tasks)
                    
                    # è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„URL
                    for url in results:
                        if url:
                            logger.info(f"[douyin_api] æ‰¾åˆ°å¯ç”¨API: {url}")
                            return url
                            
                    logger.warning(f"[douyin_api] ç¬¬{attempt + 1}æ¬¡å°è¯•æ‰€æœ‰APIéƒ½è¿”å›0å­—èŠ‚")
                    if attempt < 1:  # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡é‡è¯•
                        await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                        
                except Exception as e:
                    logger.error(f"[douyin_api] ç¬¬{attempt + 1}æ¬¡å°è¯•å‘ç”Ÿé”™è¯¯: {str(e)}")
                    if attempt < 1:
                        await asyncio.sleep(1)
                        
            logger.warning("[douyin_api] æ‰€æœ‰APIéƒ½è¿”å›0å­—èŠ‚ï¼ŒAPIå¯èƒ½å·²å¤±æ•ˆ")
            return None
            
        except Exception as e:
            logger.error(f"[douyin_api] è·å–æ— æ°´å°ç›´é“¾å¼‚å¸¸: {str(e)}")
            return None
    
    async def _get_video_title(self, page, platform: 'VideoDownloader.Platform') -> str:
        """è·å–è§†é¢‘æ ‡é¢˜ - é’ˆå¯¹ä¸åŒå¹³å°ä¼˜åŒ–"""
        try:
            # å¿«æ‰‹ç‰¹æ®Šå¤„ç†
            if platform == VideoDownloader.Platform.KUAISHOU:
                return await self._get_kuaishou_video_title(page)

            # å…¶ä»–å¹³å°ä½¿ç”¨é€šç”¨æ–¹æ³•
            page_title = await page.title()
            if page_title and page_title.strip():
                logger.info(f"ğŸ“ é€šè¿‡<title>æ ‡ç­¾è·å–æ ‡é¢˜æˆåŠŸ")
                logger.info(f"ğŸ“ åŸå§‹<title> repr: {repr(page_title)}")
                clean_title = page_title.strip()
                return re.sub(r'[<>:"/\\|?*]', '_', clean_title)[:100]
        except Exception as e:
            logger.warning(f"è·å–æ ‡é¢˜å¤±è´¥: {str(e)}")
        return None

    async def _get_kuaishou_video_title(self, page) -> str:
        """ä¸“é—¨è·å–å¿«æ‰‹è§†é¢‘æ ‡é¢˜"""
        try:
            # æ–¹æ³•1: å°è¯•ä»é¡µé¢çš„JSONæ•°æ®ä¸­æå–æ ‡é¢˜
            html = await page.content()

            # æŸ¥æ‰¾åŒ…å«è§†é¢‘ä¿¡æ¯çš„scriptæ ‡ç­¾
            script_matches = re.findall(r'<script[^>]*>(.*?)</script>', html, re.DOTALL)
            for script_content in script_matches:
                if 'caption' in script_content or 'title' in script_content:
                    # å°è¯•æå–JSONä¸­çš„æ ‡é¢˜å­—æ®µ
                    title_patterns = [
                        r'"caption":"([^"]+)"',
                        r'"title":"([^"]+)"',
                        r'"content":"([^"]+)"',
                        r'"text":"([^"]+)"',
                        r'"description":"([^"]+)"'
                    ]

                    for pattern in title_patterns:
                        matches = re.findall(pattern, script_content)
                        for match in matches:
                            # æ¸…ç†å’ŒéªŒè¯æ ‡é¢˜
                            title = match.replace('\\u002F', '/').replace('\\u0026', '&').replace('\\n', ' ').replace('\\', '')
                            title = title.strip()
                            # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯æ ‡é¢˜çš„å†…å®¹
                            if (len(title) > 5 and len(title) < 200 and
                                not title.startswith('http') and
                                not all(c.isdigit() or c in '.-_' for c in title) and
                                'å¿«æ‰‹' not in title and 'kuaishou' not in title.lower()):
                                logger.info(f"ğŸ“ ä»JSONæå–åˆ°å¿«æ‰‹æ ‡é¢˜: {title}")
                                return re.sub(r'[<>:"/\\|?*]', '_', title)[:100]

            # æ–¹æ³•2: å°è¯•ä»é¡µé¢å…ƒç´ ä¸­æå–æ ‡é¢˜
            title_selectors = [
                '.video-info-title',
                '.content-text',
                '.video-title',
                '.caption',
                '[data-testid="video-title"]',
                '.description',
                'h1', 'h2', 'h3'
            ]

            for selector in title_selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    for element in elements:
                        text = await element.text_content()
                        if text and len(text.strip()) > 5 and len(text.strip()) < 200:
                            title = text.strip()
                            if (not title.startswith('http') and
                                not all(c.isdigit() or c in '.-_' for c in title)):
                                logger.info(f"ğŸ“ ä»å…ƒç´ {selector}æå–åˆ°å¿«æ‰‹æ ‡é¢˜: {title}")
                                return re.sub(r'[<>:"/\\|?*]', '_', title)[:100]
                except:
                    continue

            # æ–¹æ³•3: ä»é¡µé¢titleä¸­æå–ï¼Œå»é™¤å¿«æ‰‹ç›¸å…³åç¼€
            page_title = await page.title()
            if page_title and page_title.strip():
                title = page_title.strip()
                # å»é™¤å¿«æ‰‹ç›¸å…³çš„åç¼€
                title = re.sub(r'[-_\s]*å¿«æ‰‹[-_\s]*', '', title)
                title = re.sub(r'[-_\s]*kuaishou[-_\s]*', '', title, flags=re.IGNORECASE)
                title = re.sub(r'[-_\s]*çŸ­è§†é¢‘[-_\s]*', '', title)
                title = title.strip()
                if len(title) > 3:
                    logger.info(f"ğŸ“ ä»é¡µé¢titleæå–å¿«æ‰‹æ ‡é¢˜: {title}")
                    return re.sub(r'[<>:"/\\|?*]', '_', title)[:100]

            logger.warning("ğŸ“ æœªèƒ½æå–åˆ°å¿«æ‰‹è§†é¢‘æ ‡é¢˜")
            return None

        except Exception as e:
            logger.warning(f"è·å–å¿«æ‰‹æ ‡é¢˜å¤±è´¥: {str(e)}")
            return None
    
    async def _get_video_author(self, page, platform: 'VideoDownloader.Platform') -> str:
        """è·å–è§†é¢‘ä½œè€…"""
        try:
            # å¿«æ‰‹ç‰¹æ®Šå¤„ç†
            if platform == VideoDownloader.Platform.KUAISHOU:
                return await self._get_kuaishou_video_author(page)

            # å…¶ä»–å¹³å°ä½¿ç”¨é€šç”¨æ–¹æ³•
            selectors = {
                VideoDownloader.Platform.DOUYIN: '[data-e2e="user-name"]',
                VideoDownloader.Platform.XIAOHONGSHU: '.user-name, .author, .nickname, [data-e2e="user-name"], .user-info .name',
            }

            selector = selectors.get(platform, '.author, .username')
            author_element = await page.query_selector(selector)

            if author_element:
                return await author_element.text_content()
        except Exception as e:
            logger.warning(f"è·å–ä½œè€…å¤±è´¥: {str(e)}")
        return None

    async def _get_kuaishou_video_author(self, page) -> str:
        """ä¸“é—¨è·å–å¿«æ‰‹è§†é¢‘ä½œè€…"""
        try:
            # æ–¹æ³•1: ä»é¡µé¢çš„JSONæ•°æ®ä¸­æå–ä½œè€…
            html = await page.content()

            # æŸ¥æ‰¾åŒ…å«ç”¨æˆ·ä¿¡æ¯çš„scriptæ ‡ç­¾
            script_matches = re.findall(r'<script[^>]*>(.*?)</script>', html, re.DOTALL)
            for script_content in script_matches:
                if 'user' in script_content or 'author' in script_content:
                    # å°è¯•æå–JSONä¸­çš„ä½œè€…å­—æ®µ
                    author_patterns = [
                        r'"userName":"([^"]+)"',
                        r'"user_name":"([^"]+)"',
                        r'"nickname":"([^"]+)"',
                        r'"name":"([^"]+)"',
                        r'"author":"([^"]+)"',
                        r'"performer":"([^"]+)"'
                    ]

                    for pattern in author_patterns:
                        matches = re.findall(pattern, script_content)
                        for match in matches:
                            # æ¸…ç†å’ŒéªŒè¯ä½œè€…å
                            author = match.replace('\\u002F', '/').replace('\\u0026', '&').replace('\\', '')
                            author = author.strip()
                            # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯ä½œè€…åçš„å†…å®¹
                            if (len(author) > 1 and len(author) < 50 and
                                not author.startswith('http') and
                                not all(c.isdigit() or c in '.-_' for c in author) and
                                author not in ['null', 'undefined', 'true', 'false']):
                                logger.info(f"ğŸ‘¤ ä»JSONæå–åˆ°å¿«æ‰‹ä½œè€…: {author}")
                                return re.sub(r'[<>:"/\\|?*]', '_', author)[:30]

            # æ–¹æ³•2: ä»é¡µé¢å…ƒç´ ä¸­æå–ä½œè€…
            author_selectors = [
                '.user-name',
                '.author-name',
                '.nickname',
                '.username',
                '.user-info .name',
                '.profile-name',
                '[data-testid="user-name"]',
                '.creator-name'
            ]

            for selector in author_selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    for element in elements:
                        text = await element.text_content()
                        if text and len(text.strip()) > 1 and len(text.strip()) < 50:
                            author = text.strip()
                            if (not author.startswith('http') and
                                not all(c.isdigit() or c in '.-_' for c in author)):
                                logger.info(f"ğŸ‘¤ ä»å…ƒç´ {selector}æå–åˆ°å¿«æ‰‹ä½œè€…: {author}")
                                return re.sub(r'[<>:"/\\|?*]', '_', author)[:30]
                except:
                    continue

            logger.warning("ğŸ‘¤ æœªèƒ½æå–åˆ°å¿«æ‰‹è§†é¢‘ä½œè€…")
            return None

        except Exception as e:
            logger.warning(f"è·å–å¿«æ‰‹ä½œè€…å¤±è´¥: {str(e)}")
            return None
    
    def _is_valid_xiaohongshu_url(self, url: str) -> bool:
        """éªŒè¯å°çº¢ä¹¦è§†é¢‘URLæ˜¯å¦æœ‰æ•ˆ"""
        if not url:
            return False
            
        url_lower = url.lower()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶
        if not any(ext in url_lower for ext in ['.mp4', '.m3u8', '.ts', '.flv', '.webm']):
            return False
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥è‡ªå°çº¢ä¹¦çš„CDN
        if not any(cdn in url_lower for cdn in ['xhscdn.com', 'xiaohongshu.com']):
            return False
            
        # æ’é™¤ä¸€äº›æ— æ•ˆçš„URL
        if any(x in url_lower for x in ['static', 'avatar', 'icon', 'logo', 'banner']):
            return False
            
        return True

    async def _set_platform_headers(self, page, platform: 'VideoDownloader.Platform'):
        """è®¾ç½®å¹³å°ç‰¹å®šçš„è¯·æ±‚å¤´"""
        headers = {
            self.Platform.DOUYIN: {'Referer': 'https://www.douyin.com/'},
            self.Platform.KUAISHOU: {'Referer': 'https://www.kuaishou.com/'},
            self.Platform.XIAOHONGSHU: {'Referer': 'https://www.xiaohongshu.com/'},
        }
        
        if platform in headers:
            await page.set_extra_http_headers(headers[platform])
            logger.info(f"ğŸ¬ å·²è®¾ç½® {platform.value} å¹³å°è¯·æ±‚å¤´")

    async def _download_douyin_with_playwright(self, url: str, message: types.Message, message_updater=None) -> dict:
        """ä½¿ç”¨Playwrightä¸‹è½½æŠ–éŸ³è§†é¢‘ - å®Œå…¨å¤åˆ¶douyin.pyçš„extracté€»è¾‘"""
        if not PLAYWRIGHT_AVAILABLE:
            return {
                "success": False,
                "error": "Playwright æœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½æŠ–éŸ³è§†é¢‘",
                "platform": "Douyin",
                "content_type": "video"
            }
        
        try:
            from playwright.async_api import async_playwright
            import httpx
            from dataclasses import dataclass
            from typing import Optional
            import re
            import time
            
            @dataclass
            class VideoInfo:
                video_id: str
                platform: str
                share_url: str
                download_url: Optional[str] = None
                title: Optional[str] = None
                author: Optional[str] = None
                create_time: Optional[str] = None
                quality: Optional[str] = None
                thumbnail_url: Optional[str] = None
            
            class Platform(str, Enum):
                DOUYIN = "douyin"
                XIAOHONGSHU = "xiaohongshu"
                UNKNOWN = "unknown"
            
            logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½æŠ–éŸ³è§†é¢‘: {url}")
            
            total_start = time.time()
            platform = Platform.DOUYIN
            
            async with async_playwright() as p:
                # æŒ‰ç…§douyin.pyå¯åŠ¨æµè§ˆå™¨ï¼ˆæ— ç‰¹æ®Šå‚æ•°ï¼‰
                browser = await p.chromium.launch(headless=True)
                
                # æŒ‰ç…§douyin.pyçš„contexté…ç½®ï¼ˆæŠ–éŸ³ç”¨æ‰‹æœºç‰ˆï¼‰
                context = await browser.new_context(
                    user_agent='Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
                    viewport={'width': 375, 'height': 667},
                    device_scale_factor=2,
                    locale='zh-CN',
                    timezone_id='Asia/Shanghai',
                    is_mobile=True,
                    has_touch=True,
                    color_scheme='light',
                    extra_http_headers={
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,video/mp4,*/*;q=0.8',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                    }
                )
                
                page = await context.new_page()
                
                # å°è¯•åŠ è½½cookiesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if self.douyin_cookies_path and os.path.exists(self.douyin_cookies_path):
                    try:
                        cookies_dict = self._parse_douyin_cookies_file(self.douyin_cookies_path)
                        cookies = []
                        for name, value in cookies_dict.items():
                            cookies.append({
                                'name': name,
                                'value': value,
                                'domain': '.douyin.com',
                                'path': '/'
                            })
                        await context.add_cookies(cookies)
                        logger.info(f"[extract] æˆåŠŸåŠ è½½{len(cookies)}ä¸ªcookies")
                    except Exception as e:
                        logger.warning(f"[extract] cookiesåŠ è½½å¤±è´¥: {e}")

                # å‡†å¤‡video_idç›‘å¬
                video_id_holder = {'id': None}
                
                # å¤‡ç”¨ï¼šç›‘å¬ç½‘ç»œè¯·æ±‚ä¸­çš„video_id
                def handle_video_id(request):
                    request_url = request.url
                    if 'video_id=' in request_url:
                        m = re.search(r'video_id=([a-zA-Z0-9]+)', request_url)
                        if m:
                            video_id_holder['id'] = m.group(1)
                            logger.info(f"[extract] ç½‘ç»œè¯·æ±‚ä¸­æ•è·åˆ° video_id: {m.group(1)}")
                page.on("request", handle_video_id)

                try:
                    # æŒ‰ç…§douyin.pyè®¾ç½®headers
                    await self._set_platform_headers(page, platform)
                    
                    # å¤„ç†çŸ­é“¾æ¥é‡å®šå‘ï¼ˆå…³é”®ä¿®å¤ï¼‰
                    if 'v.douyin.com' in url:
                        logger.info(f"[extract] æ£€æµ‹åˆ°çŸ­é“¾æ¥ï¼Œå…ˆè·å–é‡å®šå‘: {url}")
                        response = await page.goto(url, wait_until="domcontentloaded", timeout=30000)
                        real_url = page.url
                        logger.info(f"[extract] çŸ­é“¾æ¥é‡å®šå‘åˆ°: {real_url}")
                        
                        # æå–video_idå¹¶æ„é€ æ ‡å‡†douyin.comé“¾æ¥
                        import re
                        video_id_match = re.search(r'/video/(\d+)', real_url)
                        if video_id_match:
                            video_id = video_id_match.group(1)
                            standard_url = f"https://www.douyin.com/video/{video_id}"
                            logger.info(f"[extract] è½¬æ¢ä¸ºæ ‡å‡†é“¾æ¥: {standard_url}")
                            await page.goto(standard_url, wait_until="domcontentloaded", timeout=30000)
                            logger.info(f"[extract] è®¿é—®æ ‡å‡†é“¾æ¥å®Œæˆ")
                        else:
                            # å¦‚æœæå–ä¸åˆ°video_idï¼Œç›´æ¥ç”¨é‡å®šå‘çš„URL
                            if real_url != url:
                                await page.goto(real_url, wait_until="domcontentloaded", timeout=30000)
                                logger.info(f"[extract] é‡æ–°è®¿é—®çœŸå®URLå®Œæˆ")
                    else:
                        logger.info("[extract] goto å‰")
                        await page.goto(url, wait_until="domcontentloaded", timeout=30000)
                        logger.info("[extract] goto åï¼Œç­‰å¾… video_id")
                    
                    # è°ƒè¯•ï¼šæ£€æŸ¥é¡µé¢æ˜¯å¦æ­£ç¡®åŠ è½½
                    page_title = await page.title()
                    current_url = page.url
                    logger.info(f"[debug] é¡µé¢æ ‡é¢˜: {repr(page_title)}")
                    logger.info(f"[debug] å½“å‰URL: {current_url}")
                    
                    # ç›´æ¥ä»URLæå–video_idï¼ˆæœ€å…³é”®çš„ä¿®å¤ï¼‰
                    video_id_match = re.search(r'/video/(\d+)', current_url)
                    if video_id_match:
                        video_id_holder['id'] = video_id_match.group(1)
                        logger.info(f"[extract] ä»å½“å‰URLç›´æ¥æå–åˆ° video_id: {video_id_holder['id']}")
                    else:
                        # å¦‚æœå½“å‰URLæå–å¤±è´¥ï¼Œä»åŸå§‹URLæå–
                        video_id_match = re.search(r'/video/(\d+)', url)
                        if video_id_match:
                            video_id_holder['id'] = video_id_match.group(1)
                            logger.info(f"[extract] ä»åŸå§‹URLæå–åˆ° video_id: {video_id_holder['id']}")

                    # æŒ‰ç…§douyin.pyï¼šæŠ–éŸ³å…ˆç­‰2ç§’
                    await asyncio.sleep(2)

                    # æŒ‰ç…§douyin.pyï¼šç­‰å¾…video_idå‡ºç°ï¼Œæœ€å¤šç­‰3ç§’
                    wait_start = time.time()
                    max_wait = 3  # æœ€å¤šç­‰3ç§’
                    while time.time() - wait_start < max_wait:
                        if video_id_holder['id']:
                            break
                        await asyncio.sleep(0.1)
                    logger.info(f"[extract] video_id ç­‰å¾…ç”¨æ—¶: {time.time() - wait_start:.2f}s")
                    
                    # å¦‚æœè¿˜æ²¡æœ‰video_idï¼Œæœ€åä¸€æ¬¡å°è¯•ä»URLæå–
                    if not video_id_holder['id']:
                        logger.info("[extract] ç½‘ç»œç›‘å¬æœªæ•è·åˆ°video_idï¼Œå°è¯•ä»URLç›´æ¥æå–")
                        # å°è¯•ä»å„ç§å¯èƒ½çš„URLæ ¼å¼ä¸­æå–
                        for test_url in [current_url, url]:
                            video_id_match = re.search(r'/video/(\d+)', test_url)
                            if video_id_match:
                                video_id_holder['id'] = video_id_match.group(1)
                                logger.info(f"[extract] ä»URLç›´æ¥æå–åˆ° video_id: {video_id_holder['id']} (æ¥æº: {test_url})")
                                break

                    video_url = None
                    # ç›´æ¥ä½¿ç”¨HTMLæå–æ–¹å¼ï¼ˆæŠ–éŸ³å®˜æ–¹APIå·²å¤±æ•ˆï¼‰
                    logger.info("[extract] è¿›å…¥HTMLæå–æµç¨‹")
                    html = await page.content()
                    
                    # æ ¹æ®å¹³å°é€‰æ‹©ä¸åŒçš„æå–æ–¹æ³•
                    if platform == Platform.DOUYIN:
                        video_url = await self._extract_douyin_url_from_html(html)
                    else:
                        # é€šç”¨æå–æ–¹æ³•
                        video_url = await self._extract_douyin_url_from_html(html)
                    
                    logger.info(f"[extract] æ­£åˆ™æå–ç»“æœ: {video_url}")
                    
                    if video_url:
                        # å¦‚æœæ˜¯å¸¦æ°´å°çš„URLï¼Œå°è¯•è½¬æ¢ä¸ºæ— æ°´å°URL
                        if 'playwm' in video_url:
                            logger.info("[extract] æ£€æµ‹åˆ°å¸¦æ°´å°URLï¼Œå°è¯•è½¬æ¢ä¸ºæ— æ°´å°URL")
                            no_watermark_url = video_url.replace('playwm', 'play')
                            logger.info(f"[extract] è½¬æ¢åçš„æ— æ°´å°URL: {no_watermark_url}")
                            video_url = no_watermark_url
                        # éªŒè¯URLæœ‰æ•ˆæ€§
                        is_valid = False
                        if platform == Platform.DOUYIN:
                            def is_valid_video_url(u):
                                u = u.lower()
                                # æŠ–éŸ³è§†é¢‘URLé€šå¸¸ä¸åŒ…å«æ–‡ä»¶æ‰©å±•åï¼Œè€Œæ˜¯é€šè¿‡å‚æ•°æŒ‡å®š
                                # æ£€æŸ¥æ˜¯å¦æ˜¯æŠ–éŸ³çš„CDNåŸŸå
                                if any(domain in u for domain in ['aweme.snssdk.com', 'douyinvod.com', 'snssdk.com']):
                                    return True
                                # æ£€æŸ¥æ˜¯å¦åŒ…å«è§†é¢‘ç›¸å…³å‚æ•°
                                if any(param in u for param in ['video_id', 'play', 'aweme']):
                                    return True
                                # æ’é™¤ä¸€äº›æ— æ•ˆçš„URL
                                if any(x in u for x in ['client.mp4', 'static', 'eden-cn', 'download/douyin_pc_client', 'douyin_pc_client.mp4']):
                                    return False
                                return True
                            is_valid = is_valid_video_url(video_url)
                        else:
                            # é€šç”¨éªŒè¯
                            is_valid = any(ext in video_url.lower() for ext in ['.mp4', '.m3u8', '.ts', '.flv', '.webm'])
                        
                        if is_valid:
                            logger.info(f"[extract] æ­£åˆ™æµç¨‹å‘½ä¸­: {video_url}")
                            title = await self._get_video_title(page, platform)
                            author = await self._get_video_author(page, platform)
                            video_info = VideoInfo(
                                video_id=str(int(time.time())),
                                platform=platform,
                                share_url=url,
                                download_url=video_url,
                                title=title,
                                author=author,
                                thumbnail_url=None
                            )
                            logger.info("[extract] æ­£åˆ™æµç¨‹å®Œæˆ")
                            
                            # ä¸‹è½½è§†é¢‘
                            download_result = await self._download_video_file(
                                video_info, 
                                str(self.douyin_download_path),
                                message_updater,
                                None
                            )
                            
                            await page.close()
                            await context.close()
                            await browser.close()
                            return download_result
                        else:
                            logger.warning(f"[extract] æå–çš„URLæ— æ•ˆ: {video_url}")
                            video_url = None

                    if not video_url:
                        logger.info("[extract] æ‰€æœ‰æµç¨‹å‡æœªæ•è·åˆ°è§†é¢‘æ•°æ®ï¼ŒæŠ›å‡º TimeoutError")
                        raise TimeoutError("æœªèƒ½æ•è·åˆ°è§†é¢‘æ•°æ®")

                finally:
                    logger.info("[extract] å…³é—­ page/context å‰")
                    await page.close()
                    await context.close()
                    logger.info("[extract] å…³é—­ page/context å")
                    
                await browser.close()
                    
        except Exception as e:
            logger.error(f"æŠ–éŸ³ä¸‹è½½å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": f"ä¸‹è½½å¤±è´¥: {str(e)}",
                "platform": "Douyin",
                "content_type": "video"
            }

    async def _download_kuaishou_with_playwright(self, url: str, message, message_updater=None) -> dict:
        """ä½¿ç”¨Playwrightä¸‹è½½å¿«æ‰‹è§†é¢‘ - å‚è€ƒæŠ–éŸ³å®ç°"""
        if not PLAYWRIGHT_AVAILABLE:
            return {
                "success": False,
                "error": "Playwright æœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½å¿«æ‰‹è§†é¢‘",
                "platform": "Kuaishou",
                "content_type": "video"
            }

        try:
            from playwright.async_api import async_playwright
            import httpx
            from dataclasses import dataclass
            from typing import Optional
            from enum import Enum
            import time
            import re

            @dataclass
            class VideoInfo:
                video_id: str
                title: str
                author: str
                download_url: str
                platform: str = "kuaishou"
                create_time: Optional[str] = None
                quality: Optional[str] = None
                thumbnail_url: Optional[str] = None

            class Platform(str, Enum):
                KUAISHOU = "kuaishou"
                DOUYIN = "douyin"
                XIAOHONGSHU = "xiaohongshu"
                UNKNOWN = "unknown"

            # é¦–å…ˆæ¸…ç†URLï¼Œæå–çº¯é“¾æ¥
            clean_url = self._extract_clean_url_from_text(url)
            if not clean_url:
                return {
                    "success": False,
                    "error": "æ— æ³•ä»æ–‡æœ¬ä¸­æå–æœ‰æ•ˆçš„å¿«æ‰‹é“¾æ¥",
                    "platform": "Kuaishou",
                    "content_type": "video"
                }

            logger.info(f"âš¡ å¼€å§‹ä¸‹è½½å¿«æ‰‹è§†é¢‘: {clean_url}")
            if clean_url != url:
                logger.info(f"ğŸ”§ URLå·²æ¸…ç†: {url} -> {clean_url}")

            url = clean_url  # ä½¿ç”¨æ¸…ç†åçš„URL

            total_start = time.time()
            platform = Platform.KUAISHOU

            async with async_playwright() as p:
                # å¯åŠ¨æµè§ˆå™¨ï¼ˆå‚è€ƒæŠ–éŸ³é…ç½®ï¼‰
                browser = await p.chromium.launch(headless=True)

                # å¿«æ‰‹ä½¿ç”¨æ‰‹æœºç‰ˆé…ç½®
                context = await browser.new_context(
                    user_agent='Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
                    viewport={'width': 375, 'height': 667},
                    device_scale_factor=2,
                    locale='zh-CN',
                    timezone_id='Asia/Shanghai',
                    permissions=['geolocation'],
                    geolocation={'latitude': 39.9042, 'longitude': 116.4074},
                    extra_http_headers={
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                    }
                )

                page = await context.new_page()

                # å°è¯•åŠ è½½cookiesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if self.kuaishou_cookies_path and os.path.exists(self.kuaishou_cookies_path):
                    try:
                        cookies_dict = self._parse_kuaishou_cookies_file(self.kuaishou_cookies_path)
                        cookies = []
                        for name, value in cookies_dict.items():
                            cookies.append({
                                'name': name,
                                'value': value,
                                'domain': '.kuaishou.com',
                                'path': '/'
                            })
                        await context.add_cookies(cookies)
                        logger.info(f"[extract] æˆåŠŸåŠ è½½{len(cookies)}ä¸ªå¿«æ‰‹cookies")
                    except Exception as e:
                        logger.warning(f"[extract] åŠ è½½å¿«æ‰‹cookieså¤±è´¥: {e}")

                # ç›‘å¬ç½‘ç»œè¯·æ±‚ï¼Œæ•è·è§†é¢‘IDå’Œè§†é¢‘URL
                video_id_holder = {'id': None}
                video_url_holder = {'url': None}

                def handle_video_id(request):
                    req_url = request.url
                    # å¿«æ‰‹è§†é¢‘IDæ¨¡å¼
                    m = re.search(r'photoId[=:]([a-zA-Z0-9_-]+)', req_url)
                    if m and not video_id_holder['id']:
                        video_id_holder['id'] = m.group(1)
                        logger.info(f"[extract] ç½‘ç»œè¯·æ±‚ä¸­æ•è·åˆ°å¿«æ‰‹ photo_id: {m.group(1)}")

                    # ç›‘å¬è§†é¢‘æ–‡ä»¶è¯·æ±‚ - æ”¹è¿›è¿‡æ»¤é€»è¾‘
                    if not video_url_holder['url']:
                        # æ’é™¤æ—¥å¿—ã€ç»Ÿè®¡ã€APIç­‰éè§†é¢‘è¯·æ±‚
                        exclude_patterns = [
                            'log', 'collect', 'radar', 'stat', 'track', 'analytics',
                            'api', 'rest', 'sdk', 'report', 'beacon', 'ping'
                        ]

                        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶è¯·æ±‚
                        is_video_request = False
                        if '.mp4' in req_url and any(domain in req_url for domain in ['kwaicdn.com', 'ksapisrv.com', 'kuaishou.com']):
                            # ç¡®ä¿ä¸æ˜¯æ—¥å¿—æˆ–APIè¯·æ±‚
                            if not any(pattern in req_url.lower() for pattern in exclude_patterns):
                                is_video_request = True

                        # æˆ–è€…æ£€æŸ¥æ˜¯å¦ä¸ºå¿«æ‰‹CDNçš„è§†é¢‘æµ
                        elif any(domain in req_url for domain in ['kwaicdn.com']) and any(ext in req_url for ext in ['.mp4', '.m3u8', '.ts']):
                            if not any(pattern in req_url.lower() for pattern in exclude_patterns):
                                is_video_request = True

                        if is_video_request:
                            video_url_holder['url'] = req_url
                            logger.info(f"[extract] ç½‘ç»œè¯·æ±‚ä¸­æ•è·åˆ°å¿«æ‰‹è§†é¢‘URL: {req_url}")
                        elif any(pattern in req_url.lower() for pattern in exclude_patterns):
                            logger.debug(f"[extract] è·³è¿‡éè§†é¢‘è¯·æ±‚: {req_url}")

                page.on("request", handle_video_id)

                try:
                    # è®¾ç½®å¿«æ‰‹å¹³å°headers
                    await self._set_platform_headers(page, platform)

                    # è®¿é—®é¡µé¢
                    logger.info(f"[extract] å¼€å§‹è®¿é—®å¿«æ‰‹é¡µé¢: {url}")
                    await page.goto(url, wait_until="domcontentloaded", timeout=30000)
                    logger.info(f"[extract] é¡µé¢è®¿é—®å®Œæˆ")

                    # ç­‰å¾…é¡µé¢åŠ è½½æ›´é•¿æ—¶é—´ï¼Œè®©JavaScriptæ‰§è¡Œ
                    logger.info(f"[extract] ç­‰å¾…é¡µé¢JavaScriptæ‰§è¡Œ...")
                    await asyncio.sleep(5)

                    # å°è¯•ç­‰å¾…è§†é¢‘å…ƒç´ å‡ºç°
                    try:
                        await page.wait_for_selector('video, [data-testid*="video"], .video-player', timeout=10000)
                        logger.info(f"[extract] æ£€æµ‹åˆ°è§†é¢‘å…ƒç´ ")
                    except:
                        logger.warning(f"[extract] æœªæ£€æµ‹åˆ°è§†é¢‘å…ƒç´ ï¼Œç»§ç»­å¤„ç†")

                    # å°è¯•ä¸€äº›é¡µé¢äº¤äº’æ¥è§¦å‘è§†é¢‘åŠ è½½
                    try:
                        # æ»šåŠ¨é¡µé¢
                        await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                        await asyncio.sleep(1)
                        await page.evaluate('window.scrollTo(0, 0)')
                        await asyncio.sleep(1)

                        # å°è¯•ç‚¹å‡»æ’­æ”¾æŒ‰é’®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        play_selectors = [
                            '.play-button', '.video-play', '[data-testid="play"]',
                            '.player-play', 'button[aria-label*="play"]', '.play-icon'
                        ]
                        for selector in play_selectors:
                            try:
                                play_button = await page.query_selector(selector)
                                if play_button:
                                    await play_button.click()
                                    logger.info(f"[extract] ç‚¹å‡»äº†æ’­æ”¾æŒ‰é’®: {selector}")
                                    await asyncio.sleep(2)
                                    break
                            except:
                                continue

                        # å°è¯•é¼ æ ‡æ‚¬åœåœ¨è§†é¢‘åŒºåŸŸ
                        try:
                            video_area = await page.query_selector('video, .video-container, .player-container')
                            if video_area:
                                await video_area.hover()
                                await asyncio.sleep(1)
                        except:
                            pass

                    except Exception as e:
                        logger.warning(f"[extract] é¡µé¢äº¤äº’å¤±è´¥: {e}")

                    # å†ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿å†…å®¹åŠ è½½å®Œæˆ
                    await asyncio.sleep(3)

                    # å°è¯•ä»URLä¸­æå–photo_id
                    if not video_id_holder['id']:
                        photo_id_match = re.search(r'/short-video/([a-zA-Z0-9_-]+)', url)
                        if photo_id_match:
                            video_id_holder['id'] = photo_id_match.group(1)
                            logger.info(f"[extract] ä»URLæå–åˆ°å¿«æ‰‹ photo_id: {video_id_holder['id']}")

                    # ä¼˜å…ˆä½¿ç”¨ç½‘ç»œç›‘å¬æ•è·çš„è§†é¢‘URL
                    video_url = video_url_holder['url']

                    if not video_url:
                        # å¦‚æœç½‘ç»œç›‘å¬æ²¡æœ‰æ•è·åˆ°ï¼Œä»HTMLä¸­æå–è§†é¢‘ç›´é“¾
                        logger.info(f"[extract] ç½‘ç»œç›‘å¬æœªæ•è·åˆ°è§†é¢‘URLï¼Œå°è¯•ä»HTMLæå–")
                        html = await page.content()
                        video_url = await self._extract_kuaishou_url_from_html(html)
                        logger.info(f"[extract] å¿«æ‰‹HTMLæå–ç»“æœ: {video_url}")
                    else:
                        logger.info(f"[extract] ä½¿ç”¨ç½‘ç»œç›‘å¬æ•è·çš„è§†é¢‘URL: {video_url}")

                    if video_url:
                        # è·å–æ ‡é¢˜å’Œä½œè€…
                        title = await self._get_video_title(page, platform)
                        author = await self._get_video_author(page, platform)

                        # åˆ›å»ºè§†é¢‘ä¿¡æ¯å¯¹è±¡
                        video_info = VideoInfo(
                            video_id=video_id_holder['id'] or str(int(time.time())),
                            title=title or f"å¿«æ‰‹è§†é¢‘_{int(time.time())}",
                            author=author or "æœªçŸ¥ä½œè€…",
                            download_url=video_url,
                            platform="kuaishou"
                        )

                        logger.info(f"[extract] å¿«æ‰‹è§†é¢‘ä¿¡æ¯: æ ‡é¢˜={video_info.title}, ä½œè€…={video_info.author}")
                        logger.info("[extract] æ­£åˆ™æµç¨‹å®Œæˆ")

                        # ä¸‹è½½è§†é¢‘
                        download_result = await self._download_video_file(
                            video_info,
                            str(self.kuaishou_download_path),
                            message_updater,
                            None
                        )

                        await page.close()
                        await context.close()
                        return download_result
                    else:
                        logger.error("[extract] æœªèƒ½æå–åˆ°å¿«æ‰‹è§†é¢‘ç›´é“¾")
                        await page.close()
                        await context.close()
                        return {
                            "success": False,
                            "error": "æœªèƒ½æå–åˆ°å¿«æ‰‹è§†é¢‘ç›´é“¾",
                            "platform": "Kuaishou",
                            "content_type": "video"
                        }

                except Exception as e:
                    logger.error(f"[extract] å¿«æ‰‹é¡µé¢å¤„ç†å¼‚å¸¸: {str(e)}")
                    try:
                        await page.close()
                        await context.close()
                    except:
                        pass
                    logger.info("[extract] å…³é—­ page/context å")

                await browser.close()

        except Exception as e:
            logger.error(f"å¿«æ‰‹ä¸‹è½½å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": f"ä¸‹è½½å¤±è´¥: {str(e)}",
                "platform": "Kuaishou",
                "content_type": "video"
            }

    async def _extract_kuaishou_url_from_html(self, html: str) -> Optional[str]:
        """ä»å¿«æ‰‹HTMLæºç ä¸­æå–è§†é¢‘ç›´é“¾"""
        try:
            logger.info(f"[extract] å¿«æ‰‹HTMLé•¿åº¦: {len(html)} å­—ç¬¦")

            # å…ˆä¿å­˜HTMLåˆ°æ–‡ä»¶ç”¨äºè°ƒè¯•
            try:
                debug_path = '/tmp/kuaishou_debug.html'
                with open(debug_path, 'w', encoding='utf-8') as f:
                    f.write(html)
                logger.info(f"[extract] å·²ä¿å­˜HTMLåˆ° {debug_path} ç”¨äºè°ƒè¯•")

                # è¾“å‡ºHTMLçš„å‰500ä¸ªå­—ç¬¦ç”¨äºå¿«é€Ÿåˆ†æ
                logger.info(f"[extract] HTMLå¼€å¤´å†…å®¹: {html[:500]}")

                # æ£€æŸ¥HTMLä¸­æ˜¯å¦åŒ…å«å…³é”®è¯
                keywords = ['video', 'mp4', 'src', 'url', 'play', 'kwai']
                for keyword in keywords:
                    count = html.lower().count(keyword)
                    if count > 0:
                        logger.info(f"[extract] HTMLä¸­åŒ…å« '{keyword}': {count} æ¬¡")

            except Exception as e:
                logger.warning(f"[extract] ä¿å­˜HTMLè°ƒè¯•æ–‡ä»¶å¤±è´¥: {e}")

            # å¿«æ‰‹è§†é¢‘URLçš„æ­£åˆ™æ¨¡å¼ - æ‰©å±•æ›´å¤šæ¨¡å¼
            patterns = [
                # å¿«æ‰‹è§†é¢‘ç›´é“¾æ¨¡å¼
                r'"srcNoMark":"(https://[^"]+\.mp4[^"]*)"',
                r'"playUrl":"(https://[^"]+\.mp4[^"]*)"',
                r'"videoUrl":"(https://[^"]+\.mp4[^"]*)"',
                r'"src":"(https://[^"]+\.mp4[^"]*)"',
                r'"url":"(https://[^"]+\.mp4[^"]*)"',
                # å¿«æ‰‹CDNæ¨¡å¼
                r'(https://[^"\']+\.kwaicdn\.com/[^"\']+\.mp4[^"\']*)',
                r'(https://[^"\']+\.kuaishou\.com/[^"\']+\.mp4[^"\']*)',
                r'(https://[^"\']+\.ksapisrv\.com/[^"\']+\.mp4[^"\']*)',
                # JSONä¸­çš„è§†é¢‘URL
                r'"photoUrl":"(https://[^"]+\.mp4[^"]*)"',
                r'"manifest":"(https://[^"]+\.mp4[^"]*)"',
                # é€šç”¨è§†é¢‘URLæ¨¡å¼
                r'(https://[^"\'>\s]+\.mp4[^"\'>\s]*)',
                # æŸ¥æ‰¾åŒ…å«videoçš„JSONå­—æ®µ
                r'"[^"]*[Vv]ideo[^"]*":"(https://[^"]+)"',
                r'"[^"]*[Pp]lay[^"]*":"(https://[^"]+\.mp4[^"]*)"',
            ]

            for i, pattern in enumerate(patterns):
                matches = re.findall(pattern, html)
                if matches:
                    for match in matches:
                        # æ¸…ç†URL
                        video_url = match.replace('\\u002F', '/').replace('\\u0026', '&').replace('\\/', '/').replace('\\', '')
                        # éªŒè¯URLæ ¼å¼
                        if (video_url.startswith('http') and
                            ('.mp4' in video_url or 'kwaicdn.com' in video_url or 'kuaishou.com' in video_url) and
                            len(video_url) > 20):  # åŸºæœ¬é•¿åº¦æ£€æŸ¥
                            logger.info(f"[extract] å¿«æ‰‹æ¨¡å¼{i+1}æ‰¾åˆ°è§†é¢‘URL: {video_url}")
                            return video_url

            # å¦‚æœæ­£åˆ™éƒ½å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾scriptæ ‡ç­¾ä¸­çš„JSONæ•°æ®
            logger.info("[extract] æ­£åˆ™æ¨¡å¼å¤±è´¥ï¼Œå°è¯•è§£æscriptæ ‡ç­¾ä¸­çš„JSON")
            script_matches = re.findall(r'<script[^>]*>(.*?)</script>', html, re.DOTALL)
            for script_content in script_matches:
                if 'mp4' in script_content or 'video' in script_content.lower():
                    # å°è¯•ä»scriptä¸­æå–è§†é¢‘URL
                    video_patterns = [
                        r'"(https://[^"]+\.mp4[^"]*)"',
                        r"'(https://[^']+\.mp4[^']*)'",
                        r'(https://[^\s"\']+\.mp4[^\s"\']*)',
                    ]
                    for pattern in video_patterns:
                        matches = re.findall(pattern, script_content)
                        for match in matches:
                            video_url = match.replace('\\u002F', '/').replace('\\u0026', '&').replace('\\/', '/').replace('\\', '')
                            if (video_url.startswith('http') and
                                ('.mp4' in video_url or 'kwaicdn.com' in video_url) and
                                len(video_url) > 20):
                                logger.info(f"[extract] ä»scriptæ ‡ç­¾æ‰¾åˆ°è§†é¢‘URL: {video_url}")
                                return video_url

            logger.warning("[extract] æ‰€æœ‰å¿«æ‰‹æ­£åˆ™æ¨¡å¼éƒ½æœªåŒ¹é…åˆ°è§†é¢‘URL")

            # è¾“å‡ºä¸€äº›HTMLç‰‡æ®µç”¨äºè°ƒè¯•
            if 'mp4' in html:
                mp4_contexts = []
                for match in re.finditer(r'.{0,50}mp4.{0,50}', html, re.IGNORECASE):
                    mp4_contexts.append(match.group())
                logger.info(f"[extract] HTMLä¸­åŒ…å«mp4çš„ä¸Šä¸‹æ–‡: {mp4_contexts[:3]}")  # åªæ˜¾ç¤ºå‰3ä¸ª

            return None

        except Exception as e:
            logger.warning(f"å¿«æ‰‹HTMLæ­£åˆ™æå–å¤±è´¥: {str(e)}")
        return None

    async def _download_video_file(self, video_info, download_dir, message_updater=None, start_message=None):
        """ä¸‹è½½è§†é¢‘æ–‡ä»¶"""
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            if video_info.title:
                # æ¸…ç†æ ‡é¢˜ï¼Œå»é™¤ç‰¹æ®Šå­—ç¬¦å’Œå¹³å°åç¼€
                clean_title = self._sanitize_filename(video_info.title)
                # å°çº¢ä¹¦ã€æŠ–éŸ³å’Œå¿«æ‰‹çš„ç‰¹æ®Šå‘½åé€»è¾‘
                if video_info.platform in ["xiaohongshu", "douyin", "kuaishou"]:
                    # å»æ‰å¼€å¤´çš„#å’Œç©ºæ ¼
                    clean_title = clean_title.lstrip('#').strip()
                    # ç”¨#åˆ†å‰²ï¼Œå–ç¬¬ä¸€ä¸ªåˆ†å‰²åçš„å†…å®¹ï¼ˆå³ç¬¬2ä¸ª#å‰çš„å†…å®¹ï¼‰
                    clean_title = clean_title.split('#')[0].strip()
                    # å¦‚æœå¤„ç†åæ ‡é¢˜ä¸ºç©ºï¼Œä½¿ç”¨å¹³å°+æ—¶é—´æˆ³
                    if not clean_title:
                        clean_title = f"{video_info.platform}_{int(time.time())}"
                else:
                    # å…¶ä»–å¹³å°ä¿æŒåŸæœ‰é€»è¾‘
                    clean_title = re.split(r'#', clean_title)[0].strip()
                # å»é™¤å¹³å°åç¼€
                clean_title = re.sub(r'[-_ ]*(æŠ–éŸ³|å¿«æ‰‹|å°çº¢ä¹¦|YouTube|youtube)$', '', clean_title, flags=re.IGNORECASE).strip()
                filename = f"{clean_title}.mp4"
            else:
                # å¦‚æœè·å–æ ‡é¢˜å¤±è´¥ï¼Œä½¿ç”¨æ—¶é—´æˆ³
                filename = f"{video_info.platform}_{int(time.time())}.mp4"
            
            file_path = os.path.join(download_dir, filename)
            
            # å°çº¢ä¹¦ä½¿ç”¨ç®€å•ä¸‹è½½é€»è¾‘ï¼ŒæŠ–éŸ³ä¿æŒç°æœ‰é€»è¾‘
            if video_info.platform == 'xiaohongshu':
                # å°çº¢ä¹¦ï¼šç®€å•ä¸‹è½½é€»è¾‘ï¼Œå‚è€ƒdouyin.py
                async with httpx.AsyncClient(follow_redirects=True, timeout=60) as client:
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
                        'Referer': 'https://www.xiaohongshu.com/'
                    }
                    
                    logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½å°çº¢ä¹¦è§†é¢‘: {video_info.download_url}")
                    
                    # å…ˆæ£€æŸ¥å“åº”çŠ¶æ€å’Œå¤´ä¿¡æ¯
                    try:
                        async with client.stream("GET", video_info.download_url, headers=headers) as resp:
                            logger.info(f"ğŸ“Š HTTPçŠ¶æ€ç : {resp.status_code}")
                            logger.info(f"ğŸ“Š å“åº”å¤´: {dict(resp.headers)}")
                            
                            total = int(resp.headers.get("content-length", 0))
                            logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {total} bytes")
                            
                            if resp.status_code != 200:
                                logger.error(f"âŒ HTTPçŠ¶æ€ç é”™è¯¯: {resp.status_code}")
                                # è¯»å–é”™è¯¯å“åº”å†…å®¹
                                error_content = await resp.aread()
                                logger.error(f"âŒ é”™è¯¯å“åº”å†…å®¹: {error_content[:500]}")
                                raise Exception(f"HTTPçŠ¶æ€ç é”™è¯¯: {resp.status_code}")
                            
                            with open(file_path, "wb") as f:
                                downloaded = 0
                                chunk_size = 1024 * 256
                                
                                async for chunk in resp.aiter_bytes(chunk_size=chunk_size):
                                    f.write(chunk)
                                    downloaded += len(chunk)
                                    
                                    # æ›´æ–°è¿›åº¦ - ä½¿ç”¨ä¸ YouTube ç›¸åŒçš„æ ¼å¼
                                    if total > 0:
                                        progress = downloaded / total * 100
                                    else:
                                        # å¦‚æœæ²¡æœ‰content-lengthï¼Œä½¿ç”¨ä¸‹è½½çš„å­—èŠ‚æ•°ä½œä¸ºè¿›åº¦æŒ‡ç¤º
                                        progress = min(downloaded / (1024 * 1024), 99)  # å‡è®¾è‡³å°‘1MB
                                    
                                    # è®¡ç®—é€Ÿåº¦ï¼ˆæ¯ç§’æ›´æ–°ä¸€æ¬¡ï¼‰
                                    current_time = time.time()
                                    if not hasattr(self, '_last_update_time'):
                                        self._last_update_time = current_time
                                        self._last_downloaded = 0
                                    
                                    if current_time - self._last_update_time >= 1.0:
                                        speed = (downloaded - self._last_downloaded) / (current_time - self._last_update_time)
                                        self._last_update_time = current_time
                                        self._last_downloaded = downloaded
                                    else:
                                        speed = 0
                                    
                                    # è®¡ç®—ETA
                                    if speed > 0 and total > 0:
                                        remaining_bytes = total - downloaded
                                        eta_seconds = remaining_bytes / speed
                                    else:
                                        eta_seconds = 0
                                    
                                    # æ„å»ºè¿›åº¦æ•°æ®ï¼Œæ ¼å¼ä¸ yt-dlp ä¸€è‡´
                                    progress_data = {
                                        'status': 'downloading',
                                        'downloaded_bytes': downloaded,
                                        'total_bytes': total,
                                        'speed': speed,
                                        'eta': eta_seconds,
                                        'filename': filename
                                    }
                                    
                                    # ä½¿ç”¨ message_updater æ›´æ–°è¿›åº¦
                                    if message_updater:
                                        try:
                                            import asyncio
                                            if asyncio.iscoroutinefunction(message_updater):
                                                # å¦‚æœæ˜¯åç¨‹å‡½æ•°ï¼Œéœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
                                                try:
                                                    loop = asyncio.get_running_loop()
                                                except RuntimeError:
                                                    try:
                                                        loop = asyncio.get_event_loop()
                                                    except RuntimeError:
                                                        loop = asyncio.new_event_loop()
                                                        asyncio.set_event_loop(loop)
                                                asyncio.run_coroutine_threadsafe(message_updater(progress_data), loop)
                                            else:
                                                # åŒæ­¥å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
                                                message_updater(progress_data)
                                        except Exception as e:
                                            logger.warning(f"âš ï¸ æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
                                
                                # ä¸‹è½½å®Œæˆåçš„æœ€ç»ˆæ›´æ–°
                                logger.info(f"âœ… å°çº¢ä¹¦è§†é¢‘ä¸‹è½½å®Œæˆ: {downloaded} bytes @{video_info.download_url}")
                                if message_updater:
                                    try:
                                        final_progress_data = {
                                            'status': 'finished',
                                            'downloaded_bytes': downloaded,
                                            'total_bytes': total,
                                            'filename': filename
                                        }
                                        message_updater(final_progress_data)
                                    except Exception as e:
                                        logger.warning(f"âš ï¸ æ›´æ–°å®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
                    except Exception as e:
                        logger.error(f"âŒ å°çº¢ä¹¦ä¸‹è½½å¼‚å¸¸: {e}")
                        raise
            else:
                # æŠ–éŸ³ç­‰å…¶ä»–å¹³å°ï¼šå¤„ç†APIé‡å®šå‘
                # å‡†å¤‡cookiesï¼ˆå¦‚æœæœ‰ï¼‰
                cookies_dict = {}
                if video_info.platform == 'douyin' and self.douyin_cookies_path and os.path.exists(self.douyin_cookies_path):
                    try:
                        cookies_dict = self._parse_douyin_cookies_file(self.douyin_cookies_path)
                        logger.info(f"ğŸ“Š åŠ è½½äº†{len(cookies_dict)}ä¸ªcookiesç”¨äºä¸‹è½½")
                    except Exception as e:
                        logger.warning(f"âš ï¸ åŠ è½½cookieså¤±è´¥: {e}")
                
                async with httpx.AsyncClient(follow_redirects=True, timeout=60, cookies=cookies_dict) as client:
                    # ä½¿ç”¨æ‰‹æœºç‰ˆUser-Agentï¼ˆæŒ‰ç…§åŸå§‹douyin.pyï¼‰
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
                        'Accept': '*/*',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Referer': 'https://www.douyin.com/' if video_info.platform == 'douyin' else 'https://www.xiaohongshu.com/',
                        'Connection': 'keep-alive',
                    }
                    
                    # å¯¹äºæŠ–éŸ³APIé“¾æ¥ï¼Œç›´æ¥ä½¿ç”¨streamä¸‹è½½ï¼ˆæŒ‰ç…§åŸå§‹douyin.pyçš„æ–¹å¼ï¼‰
                    logger.info(f"ğŸ¬ å¼€å§‹ä¸‹è½½æŠ–éŸ³è§†é¢‘: {video_info.download_url}")
                    
                    with open(file_path, "wb") as f:
                        async with client.stream("GET", video_info.download_url, headers=headers) as resp:
                            total = int(resp.headers.get("content-length", 0))
                            downloaded = 0
                            chunk_size = 1024 * 256
                            last_update_time = time.time()
                            last_downloaded = 0
                            
                            logger.info(f"ğŸ“Š Streamå“åº”çŠ¶æ€ç : {resp.status_code}")
                            logger.info(f"ğŸ“Š Streamæ–‡ä»¶å¤§å°: {total} bytes")
                            logger.info(f"ğŸ“Š å®é™…è¯·æ±‚URL: {resp.url}")
                            logger.info(f"ğŸ“Š å“åº”å¤´: {dict(resp.headers)}")
                            
                            if resp.status_code != 200:
                                raise Exception(f"HTTPçŠ¶æ€ç é”™è¯¯: {resp.status_code}")
                            
                            async for chunk in resp.aiter_bytes(chunk_size=chunk_size):
                                if not chunk:
                                    break
                                f.write(chunk)
                                downloaded += len(chunk)
                                current_time = time.time()
                                
                                # æ›´æ–°è¿›åº¦ - ä½¿ç”¨ä¸ YouTube ç›¸åŒçš„æ ¼å¼
                                if total > 0:
                                    progress = downloaded / total * 100
                                else:
                                    # å¦‚æœæ²¡æœ‰content-lengthï¼Œä½¿ç”¨ä¸‹è½½çš„å­—èŠ‚æ•°ä½œä¸ºè¿›åº¦æŒ‡ç¤º
                                    progress = min(downloaded / (1024 * 1024), 99)  # å‡è®¾è‡³å°‘1MB
                                
                                # è®¡ç®—é€Ÿåº¦ï¼ˆæ¯ç§’æ›´æ–°ä¸€æ¬¡ï¼‰
                                if current_time - last_update_time >= 1.0:
                                    speed = (downloaded - last_downloaded) / (current_time - last_update_time)
                                    last_update_time = current_time
                                    last_downloaded = downloaded
                                    
                                    # è®¡ç®—ETA
                                    if speed > 0 and total > 0:
                                        remaining_bytes = total - downloaded
                                        eta_seconds = remaining_bytes / speed
                                    else:
                                        eta_seconds = 0
                                    
                                    # æ„å»ºè¿›åº¦æ•°æ®ï¼Œæ ¼å¼ä¸ yt-dlp ä¸€è‡´
                                    progress_data = {
                                        'status': 'downloading',
                                        'downloaded_bytes': downloaded,
                                        'total_bytes': total,
                                        'speed': speed,
                                        'eta': eta_seconds,
                                        'filename': filename
                                    }
                                    
                                    # ä½¿ç”¨ message_updater æ›´æ–°è¿›åº¦
                                    if message_updater:
                                        try:
                                            import asyncio
                                            if asyncio.iscoroutinefunction(message_updater):
                                                # å¦‚æœæ˜¯åç¨‹å‡½æ•°ï¼Œéœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
                                                try:
                                                    loop = asyncio.get_running_loop()
                                                except RuntimeError:
                                                    try:
                                                        loop = asyncio.get_event_loop()
                                                    except RuntimeError:
                                                        loop = asyncio.new_event_loop()
                                                        asyncio.set_event_loop(loop)
                                                asyncio.run_coroutine_threadsafe(message_updater(progress_data), loop)
                                            else:
                                                # åŒæ­¥å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
                                                message_updater(progress_data)
                                        except Exception as e:
                                            logger.warning(f"âš ï¸ æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
                                    else:
                                        # å¦‚æœæ²¡æœ‰ message_updaterï¼Œä½¿ç”¨åŸæ¥çš„ç®€å•æ›´æ–°
                                        if start_message and hasattr(self, 'bot') and self.bot:
                                            try:
                                                await start_message.edit_text(
                                                    f"ğŸ“¥ ä¸‹è½½ä¸­... {progress:.1f}% ({downloaded/(1024*1024):.1f}MB)"
                                                )
                                            except Exception as e:
                                                logger.warning(f"âš ï¸ æ›´æ–°è¿›åº¦æ¶ˆæ¯å¤±è´¥: {e}")
                                        else:
                                            logger.info(f"ğŸ“¥ ä¸‹è½½ä¸­... {progress:.1f}% ({downloaded/(1024*1024):.1f}MB)")
                            
                            # ä¸‹è½½å®Œæˆåçš„æœ€ç»ˆæ›´æ–°
                            logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {downloaded} bytes")
                            if message_updater:
                                try:
                                    final_progress_data = {
                                        'status': 'finished',
                                        'downloaded_bytes': downloaded,
                                        'total_bytes': total,
                                        'filename': filename
                                    }
                                    import asyncio
                                    if asyncio.iscoroutinefunction(message_updater):
                                        # å¦‚æœæ˜¯åç¨‹å‡½æ•°ï¼Œéœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
                                        try:
                                            loop = asyncio.get_running_loop()
                                        except RuntimeError:
                                            try:
                                                loop = asyncio.get_event_loop()
                                            except RuntimeError:
                                                loop = asyncio.new_event_loop()
                                                asyncio.set_event_loop(loop)
                                        asyncio.run_coroutine_threadsafe(message_updater(final_progress_data), loop)
                                    else:
                                        # åŒæ­¥å‡½æ•°ï¼Œç›´æ¥è°ƒç”¨
                                        message_updater(final_progress_data)
                                except Exception as e:
                                    logger.warning(f"âš ï¸ æ›´æ–°å®ŒæˆçŠ¶æ€å¤±è´¥: {e}")
            
            # åˆ é™¤å¼€å§‹æ¶ˆæ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if start_message and hasattr(self, 'bot') and self.bot:
                try:
                    await start_message.delete()
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ é™¤å¼€å§‹æ¶ˆæ¯å¤±è´¥: {e}")
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(file_path)
            size_mb = file_size / (1024 * 1024)
            
            # ä½¿ç”¨ ffprobe è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯
            resolution = "æœªçŸ¥"
            try:
                media_info = self.get_media_info(file_path)
                if media_info.get("resolution"):
                    resolution = media_info["resolution"]
                    logger.info(f"ğŸ“º è·å–åˆ°è§†é¢‘åˆ†è¾¨ç‡: {resolution}")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–è§†é¢‘åˆ†è¾¨ç‡å¤±è´¥: {e}")
            
            logger.info(f"âœ… {video_info.platform}è§†é¢‘ä¸‹è½½æˆåŠŸ: {filename} ({size_mb:.1f} MB, åˆ†è¾¨ç‡: {resolution})")
            
            return {
                "success": True,
                "file_path": file_path,
                "filename": filename,
                "title": video_info.title,
                "author": video_info.author,
                "platform": video_info.platform,
                "content_type": "video",
                "size_mb": size_mb,
                "resolution": resolution,
                "download_path": download_dir,
                "full_path": file_path,
                "file_count": 1,
                "files": [file_path]
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            # ç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿèƒ½è¿”å›æœ‰æ•ˆçš„ç»“æœ
            return {
                "success": False,
                "error": f"ä¸‹è½½è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}",
                "platform": video_info.platform,
                "content_type": "video",
                "downloaded_bytes": 0,
                "total_bytes": 0,
                "filename": video_info.title or f"{video_info.platform}_{int(time.time())}.mp4"
            }



    def _build_bilibili_rename_script(self):
        """
        æ„å»ºBç«™å¤šPè§†é¢‘æ™ºèƒ½é‡å‘½åè„šæœ¬

        åŸºäºæ‚¨çš„ä¼˜ç§€å»ºè®®ï¼šä½¿ç”¨yt-dlpçš„--execåŠŸèƒ½åœ¨ä¸‹è½½å®Œæˆåç«‹å³é‡å‘½å
        é¿å…äº†ä¸‹è½½å®Œæˆåçš„æ‰¹é‡é‡å‘½åæ“ä½œï¼Œæ›´é«˜æ•ˆæ›´å‡†ç¡®

        Returns:
            str: é‡å‘½åè„šæœ¬å‘½ä»¤
        """
        import shlex

        # æ„å»ºé‡å‘½åè„šæœ¬
        # 1. è·å–å½“å‰æ–‡ä»¶çš„URLï¼ˆä»æ–‡ä»¶åæ¨å¯¼ï¼‰
        # 2. ä½¿ç”¨yt-dlp --get-titleè·å–å®Œæ•´æ ‡é¢˜
        # 3. ä½¿ç”¨grepæå–pxxéƒ¨åˆ†
        # 4. é‡å‘½åæ–‡ä»¶

        script = '''
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_path="{}"
        file_dir=$(dirname "$file_path")
        file_name=$(basename "$file_path")
        file_ext="${file_name##*.}"
        video_id="${file_name%.*}"

        # æ„å»ºURLï¼ˆå‡è®¾æ˜¯Bç«™è§†é¢‘ï¼‰
        if [[ $video_id == *"_p"* ]]; then
            # å¤šPè§†é¢‘æ ¼å¼ï¼šBV1Jgf6YvE8e_p1
            bv_id="${video_id%_p*}"
            part_num="${video_id#*_p}"
            video_url="https://www.bilibili.com/video/${bv_id}?p=${part_num}"
        else
            # å•Pè§†é¢‘æ ¼å¼ï¼šBV1Jgf6YvE8e
            video_url="https://www.bilibili.com/video/${video_id}"
        fi

        # è·å–å®Œæ•´æ ‡é¢˜å¹¶æå–pxxéƒ¨åˆ†
        full_title=$(yt-dlp --get-title --skip-download "$video_url" 2>/dev/null)
        if [[ $? -eq 0 && -n "$full_title" ]]; then
            # æå–pxxåŠåç»­å†…å®¹
            new_name=$(echo "$full_title" | grep -o "p[0-9]\\{1,3\\}.*" | head -1)
            if [[ -n "$new_name" ]]; then
                # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
                new_name=$(echo "$new_name" | sed 's/[\\/:*?"<>|ã€ã€‘ï½œ]/\\_/g' | sed 's/\\s\\+/ /g')
                new_file_path="$file_dir/${new_name}.${file_ext}"

                # æ‰§è¡Œé‡å‘½å
                if [[ "$file_path" != "$new_file_path" ]]; then
                    mv "$file_path" "$new_file_path"
                    echo "âœ… æ™ºèƒ½é‡å‘½å: $(basename "$file_path") -> ${new_name}.${file_ext}"
                else
                    echo "ğŸ“ æ–‡ä»¶åå·²æ­£ç¡®: ${new_name}.${file_ext}"
                fi
            else
                echo "âš ï¸ æœªæ‰¾åˆ°pxxæ¨¡å¼ï¼Œä¿æŒåŸæ–‡ä»¶å: $file_name"
            fi
        else
            echo "âš ï¸ æ— æ³•è·å–æ ‡é¢˜ï¼Œä¿æŒåŸæ–‡ä»¶å: $file_name"
        fi
        '''

        return script.strip()

    def _is_temp_format_file(self, filename):
        """
        æ£€æŸ¥æ˜¯å¦æ˜¯ä¸´æ—¶æ ¼å¼æ–‡ä»¶ï¼ˆåŒ…å«yt-dlpæ ¼å¼ä»£ç ï¼‰

        Args:
            filename: æ–‡ä»¶è·¯å¾„

        Returns:
            bool: å¦‚æœæ˜¯ä¸´æ—¶æ ¼å¼æ–‡ä»¶è¿”å›True
        """
        import re
        from pathlib import Path

        file_name = Path(filename).name

        # æ£€æŸ¥æ˜¯å¦åŒ…å«yt-dlpçš„æ ¼å¼ä»£ç 
        # ä¾‹å¦‚ï¼š.f100026, .f137+140, .m4a, .webm ç­‰
        temp_patterns = [
            r'\.f\d+',           # .f100026
            r'\.f\d+\+\d+',      # .f137+140
            r'\.m4a$',           # .m4a
            r'\.webm$',          # .webm
        ]

        for pattern in temp_patterns:
            if re.search(pattern, file_name):
                return True

        return False

    def _get_final_filename_from_mapping(self, filename, title_mapping):
        """
        ä»æ ‡é¢˜æ˜ å°„è¡¨ä¸­è·å–æœ€ç»ˆæ–‡ä»¶å

        Args:
            filename: å½“å‰ä¸‹è½½çš„æ–‡ä»¶å
            title_mapping: è§†é¢‘IDåˆ°æœ€ç»ˆæ–‡ä»¶åçš„æ˜ å°„è¡¨

        Returns:
            str: æœ€ç»ˆæ–‡ä»¶åï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›None
        """
        import re
        from pathlib import Path

        try:
            file_path = Path(filename)

            # ä»æ–‡ä»¶åä¸­æå–è§†é¢‘ID
            # ä¾‹å¦‚ï¼šBV1aDMezREUj_p1.f100026.mp4 -> BV1aDMezREUj_p1
            raw_video_id = file_path.stem
            video_id = re.sub(r'\.f\d+.*$', '', raw_video_id)

            # ä»æ˜ å°„è¡¨ä¸­æŸ¥æ‰¾æœ€ç»ˆæ–‡ä»¶å
            final_filename = title_mapping.get(video_id)
            if final_filename:
                logger.debug(f"ğŸ“‹ æ˜ å°„æŸ¥æ‰¾: {video_id} -> {final_filename}")
                return final_filename
            else:
                logger.debug(f"âš ï¸ æœªæ‰¾åˆ°æ˜ å°„: {video_id}")
                return None

        except Exception as e:
            logger.debug(f"æ˜ å°„æŸ¥æ‰¾å¤±è´¥: {e}")
            return None

    def _optimize_filename_display_for_telegram(self, filename_display, file_count, total_size_mb, resolution_display, download_path):
        """
        åŠ¨æ€ä¼˜åŒ–æ–‡ä»¶åæ˜¾ç¤ºï¼Œæœ€å¤§åŒ–åˆ©ç”¨TGæ¶ˆæ¯ç©ºé—´

        Args:
            filename_display: åŸå§‹æ–‡ä»¶åæ˜¾ç¤ºå­—ç¬¦ä¸²
            file_count: æ–‡ä»¶æ•°é‡
            total_size_mb: æ€»æ–‡ä»¶å¤§å°
            resolution_display: åˆ†è¾¨ç‡æ˜¾ç¤º
            download_path: ä¸‹è½½è·¯å¾„

        Returns:
            str: ä¼˜åŒ–åçš„æ–‡ä»¶åæ˜¾ç¤ºå­—ç¬¦ä¸²
        """
        # TGæ¶ˆæ¯æœ€å¤§é•¿åº¦é™åˆ¶
        MAX_MESSAGE_LENGTH = 4096

        # æ„å»ºæ¶ˆæ¯çš„å…¶ä»–éƒ¨åˆ†ï¼ˆä¸åŒ…æ‹¬æ–‡ä»¶ååˆ—è¡¨ï¼‰
        other_parts = (
            f"ğŸ¬ **è§†é¢‘ä¸‹è½½å®Œæˆ**\n\n"
            f"ğŸ“ **æ–‡ä»¶å**:\n"
            f"FILENAME_PLACEHOLDER\n\n"
            f"ğŸ’¾ **æ–‡ä»¶å¤§å°**: `{total_size_mb:.2f} MB`\n"
            f"ğŸ“Š **é›†æ•°**: `{file_count} é›†`\n"
            f"ğŸ–¼ï¸ **åˆ†è¾¨ç‡**: `{resolution_display}`\n"
            f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{download_path}`"
        )

        # è®¡ç®—é™¤æ–‡ä»¶ååˆ—è¡¨å¤–çš„æ¶ˆæ¯é•¿åº¦
        other_parts_length = len(other_parts) - len("FILENAME_PLACEHOLDER")

        # å¯ç”¨äºæ–‡ä»¶ååˆ—è¡¨çš„æœ€å¤§é•¿åº¦
        available_length = MAX_MESSAGE_LENGTH - other_parts_length - 100  # ç•™100å­—ç¬¦ç¼“å†²

        lines = filename_display.split('\n')

        # å¦‚æœåŸå§‹æ–‡ä»¶ååˆ—è¡¨ä¸è¶…è¿‡å¯ç”¨é•¿åº¦ï¼Œç›´æ¥è¿”å›
        if len(filename_display) <= available_length:
            return filename_display

        # éœ€è¦æˆªæ–­ï¼Œæ‰¾åˆ°èƒ½æ˜¾ç¤ºçš„æœ€å¤§æ–‡ä»¶æ•°é‡
        result_lines = []
        current_length = 0

        # çœç•¥æç¤ºçš„æ¨¡æ¿
        omit_template = "  ... (çœç•¥ {} ä¸ªæ–‡ä»¶ï¼Œå—é™äºTGæ¶ˆæ¯é™åˆ¶ï¼Œå®Œæ•´æ–‡ä»¶åˆ—è¡¨è¯·åˆ°ä¸‹è½½ç›®å½•æŸ¥çœ‹) ..."

        for i, line in enumerate(lines):
            # è®¡ç®—åŠ ä¸Šè¿™ä¸€è¡Œå’Œå¯èƒ½çš„çœç•¥æç¤ºåçš„æ€»é•¿åº¦
            remaining_files = len(lines) - i - 1
            if remaining_files > 0:
                omit_text = omit_template.format(remaining_files)
                projected_length = current_length + len(line) + 1 + len(omit_text)  # +1 for newline
            else:
                projected_length = current_length + len(line)

            # å¦‚æœåŠ ä¸Šè¿™ä¸€è¡Œä¼šè¶…è¿‡é™åˆ¶
            if projected_length > available_length:
                # å¦‚æœè¿˜æœ‰å‰©ä½™æ–‡ä»¶ï¼Œæ·»åŠ çœç•¥æç¤º
                if remaining_files > 0:
                    omit_text = omit_template.format(remaining_files)
                    result_lines.append(omit_text)
                break
            else:
                # å¯ä»¥æ·»åŠ è¿™ä¸€è¡Œ
                result_lines.append(line)
                current_length = projected_length

        return '\n'.join(result_lines)

    def _rename_bilibili_file_from_full_title(self, filename):
        """
        ä»å®Œæ•´æ ‡é¢˜æ–‡ä»¶åé‡å‘½åä¸ºç®€æ´çš„pxxæ ¼å¼

        ä¾‹å¦‚ï¼š
        è¾“å…¥: å°šç¡…è°·Cursorä½¿ç”¨æ•™ç¨‹ï¼Œ2å°æ—¶ç©è½¬cursor p01 01-Cursoræ•™ç¨‹ç®€ä»‹.mp4
        è¾“å‡º: p01 01-Cursoræ•™ç¨‹ç®€ä»‹.mp4

        Args:
            filename: ä¸‹è½½å®Œæˆçš„æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«å®Œæ•´æ ‡é¢˜ï¼‰
        """
        import re
        from pathlib import Path

        try:
            file_path = Path(filename)
            if not file_path.exists():
                logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
                return

            file_name = file_path.name
            file_ext = file_path.suffix
            title_without_ext = file_path.stem

            logger.info(f"ğŸ” å¤„ç†å®Œæ•´æ ‡é¢˜æ–‡ä»¶: {file_name}")

            # ä½¿ç”¨æ™ºèƒ½å¤„ç†é€»è¾‘æå–pxxéƒ¨åˆ†
            processed_title = self._process_bilibili_multipart_title(title_without_ext)

            if processed_title != title_without_ext:
                # æ ‡é¢˜è¢«å¤„ç†äº†ï¼Œè¯´æ˜æ‰¾åˆ°äº†pxxéƒ¨åˆ†
                safe_title = self._sanitize_filename(processed_title)
                new_file_path = file_path.parent / f"{safe_title}{file_ext}"

                logger.info(f"ğŸ¯ ç®€æ´æ–‡ä»¶å: {safe_title}{file_ext}")

                # æ‰§è¡Œé‡å‘½å
                if file_path != new_file_path:
                    try:
                        file_path.rename(new_file_path)
                        logger.info(f"âœ… æ™ºèƒ½é‡å‘½åæˆåŠŸ: {file_name} -> {safe_title}{file_ext}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ é‡å‘½åå¤±è´¥: {e}")
                else:
                    logger.info(f"ğŸ“ æ–‡ä»¶åå·²æ˜¯ç®€æ´æ ¼å¼: {safe_title}{file_ext}")
            else:
                logger.info(f"ğŸ“ æœªæ‰¾åˆ°pxxæ¨¡å¼ï¼Œä¿æŒåŸæ–‡ä»¶å: {file_name}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–‡ä»¶åå¤±è´¥: {e}")

    def _get_processed_filename_for_display(self, filename):
        """
        è·å–ç”¨äºæ˜¾ç¤ºçš„å¤„ç†åæ–‡ä»¶å

        è¿™ä¸ªå‡½æ•°ç”¨äºåœ¨ä¸‹è½½è¿›åº¦ä¸­æ˜¾ç¤ºç”¨æˆ·å‹å¥½çš„æ–‡ä»¶åï¼Œ
        è€Œä¸æ˜¯æŠ€æœ¯æ€§çš„ä¸´æ—¶æ–‡ä»¶å

        Args:
            filename: åŸå§‹æ–‡ä»¶å

        Returns:
            str: å¤„ç†åçš„æ˜¾ç¤ºæ–‡ä»¶å
        """
        import re
        from pathlib import Path

        try:
            file_path = Path(filename)
            file_name = file_path.name
            file_ext = file_path.suffix

            # å¦‚æœæ˜¯ä¸´æ—¶æ ¼å¼æ–‡ä»¶ï¼Œå°è¯•æ¨å¯¼æœ€ç»ˆæ–‡ä»¶å
            if self._is_temp_format_file(filename):
                # ä»ä¸´æ—¶æ–‡ä»¶åæ¨å¯¼è§†é¢‘ID
                # ä¾‹å¦‚ï¼šBV1aDMezREUj_p1.f100026.mp4 -> BV1aDMezREUj_p1
                raw_video_id = file_path.stem
                video_id = re.sub(r'\.f\d+.*$', '', raw_video_id)

                # å°è¯•ä»ç¼“å­˜çš„æ ‡é¢˜ä¿¡æ¯è·å–å¤„ç†åçš„æ–‡ä»¶å
                # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„æ–¹æ³•ï¼šç›´æ¥æ˜¾ç¤ºè§†é¢‘ID
                if "_p" in video_id:
                    # å¤šPè§†é¢‘ï¼šæ˜¾ç¤ºåˆ†é›†ä¿¡æ¯
                    parts = video_id.split("_p")
                    part_num = parts[1]
                    return f"p{part_num.zfill(2)} ä¸‹è½½ä¸­...{file_ext}"
                else:
                    # å•Pè§†é¢‘
                    return f"è§†é¢‘ä¸‹è½½ä¸­...{file_ext}"
            else:
                # å¦‚æœæ˜¯æœ€ç»ˆæ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†æ ‡é¢˜
                # è¿™é‡Œæˆ‘ä»¬å‡è®¾æ–‡ä»¶åå¯èƒ½åŒ…å«å®Œæ•´çš„æ ‡é¢˜
                if any(keyword in file_name for keyword in ["å°šç¡…è°·", "æ•™ç¨‹", "è¯¾ç¨‹"]):
                    # å°è¯•æå–pxxéƒ¨åˆ†
                    pattern = r'p(\d{1,3})\s+'
                    match = re.search(pattern, file_name, re.IGNORECASE)
                    if match:
                        # æ‰¾åˆ°pxxï¼Œå°è¯•æå–åç»­å†…å®¹
                        start_pos = match.start()
                        remaining = file_name[start_pos:]
                        # ç®€åŒ–å¤„ç†ï¼šåªå–å‰50ä¸ªå­—ç¬¦
                        if len(remaining) > 50:
                            remaining = remaining[:47] + "..."
                        return remaining

                # é»˜è®¤è¿”å›åŸæ–‡ä»¶å
                return file_name

        except Exception as e:
            logger.debug(f"å¤„ç†æ˜¾ç¤ºæ–‡ä»¶åå¤±è´¥: {e}")
            return Path(filename).name

    def _rename_bilibili_file_immediately(self, filename):
        """
        ç«‹å³é‡å‘½åBç«™å¤šPæ–‡ä»¶ï¼ˆåŸºäºæ‚¨çš„ä¼˜ç§€å»ºè®®çš„Pythonå®ç°ï¼‰

        åœ¨æ¯ä¸ªæ–‡ä»¶ä¸‹è½½å®Œæˆæ—¶ç«‹å³æ‰§è¡Œé‡å‘½åï¼Œé¿å…æ‰¹é‡å¤„ç†

        Args:
            filename: ä¸‹è½½å®Œæˆçš„æ–‡ä»¶è·¯å¾„
        """
        import re
        import os
        from pathlib import Path

        try:
            file_path = Path(filename)
            if not file_path.exists():
                logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
                return

            file_name = file_path.name
            file_ext = file_path.suffix
            raw_video_id = file_path.stem

            logger.info(f"ğŸ” åˆ†ææ–‡ä»¶: {file_name}")
            logger.info(f"ğŸ“ åŸå§‹è§†é¢‘ID: {raw_video_id}")

            # æ¸…ç†è§†é¢‘IDï¼Œå»é™¤æ ¼å¼ä»£ç 
            # ä¾‹å¦‚ï¼šBV1aDMezREUj_p2.f100026 -> BV1aDMezREUj_p2
            video_id = re.sub(r'\.f\d+.*$', '', raw_video_id)
            logger.info(f"ğŸ§¹ æ¸…ç†åè§†é¢‘ID: {video_id}")

            # æ„å»ºURLï¼ˆä»æ–‡ä»¶åæ¨å¯¼ï¼‰
            if "_p" in video_id:
                # å¤šPè§†é¢‘æ ¼å¼ï¼šBV1aDMezREUj_p1
                parts = video_id.split("_p")
                bv_id = parts[0]
                part_num = parts[1]
                video_url = f"https://www.bilibili.com/video/{bv_id}?p={part_num}"
            else:
                # å•Pè§†é¢‘æ ¼å¼ï¼šBV1aDMezREUj
                video_url = f"https://www.bilibili.com/video/{video_id}"

            logger.info(f"ğŸ”— æ„å»ºURL: {video_url}")

            # ä½¿ç”¨yt-dlpè·å–å®Œæ•´æ ‡é¢˜
            try:
                import subprocess
                result = subprocess.run(
                    ["yt-dlp", "--get-title", "--skip-download", video_url],
                    capture_output=True,
                    text=True,
                    timeout=30
                )

                if result.returncode == 0 and result.stdout.strip():
                    full_title = result.stdout.strip()
                    logger.info(f"ğŸ“‹ è·å–æ ‡é¢˜: {full_title}")

                    # æå–pxxåŠåç»­å†…å®¹
                    pattern = r'p(\d{1,3}).*'
                    match = re.search(pattern, full_title, re.IGNORECASE)

                    if match:
                        # ä»pxxå¼€å§‹æˆªå–
                        start_pos = match.start()
                        new_name = full_title[start_pos:]

                        # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
                        new_name = re.sub(r'[\\/:*?"<>|ã€ã€‘ï½œ]', '_', new_name)
                        new_name = re.sub(r'\s+', ' ', new_name).strip()

                        new_file_path = file_path.parent / f"{new_name}{file_ext}"

                        logger.info(f"ğŸ¯ æ–°æ–‡ä»¶å: {new_name}{file_ext}")

                        # æ‰§è¡Œé‡å‘½å
                        if file_path != new_file_path:
                            file_path.rename(new_file_path)
                            logger.info(f"âœ… æ™ºèƒ½é‡å‘½åæˆåŠŸ: {file_name} -> {new_name}{file_ext}")
                        else:
                            logger.info(f"ğŸ“ æ–‡ä»¶åå·²æ­£ç¡®: {new_name}{file_ext}")
                    else:
                        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°pxxæ¨¡å¼ï¼Œä¿æŒåŸæ–‡ä»¶å: {file_name}")
                else:
                    logger.warning(f"âš ï¸ æ— æ³•è·å–æ ‡é¢˜ï¼Œä¿æŒåŸæ–‡ä»¶å: {file_name}")
                    logger.warning(f"yt-dlpé”™è¯¯: {result.stderr}")

            except subprocess.TimeoutExpired:
                logger.warning(f"âš ï¸ è·å–æ ‡é¢˜è¶…æ—¶ï¼Œä¿æŒåŸæ–‡ä»¶å: {file_name}")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–æ ‡é¢˜å¤±è´¥: {e}ï¼Œä¿æŒåŸæ–‡ä»¶å: {file_name}")

        except Exception as e:
            logger.error(f"âŒ é‡å‘½åæ–‡ä»¶å¤±è´¥: {e}")

    def _rename_bilibili_multipart_files(self, download_path, expected_files):
        """
        é‡å‘½åBç«™å¤šPä¸‹è½½çš„æ–‡ä»¶ï¼Œä½¿å…¶åŒ¹é…é¢„æœŸæ–‡ä»¶å

        Args:
            download_path: ä¸‹è½½ç›®å½•è·¯å¾„
            expected_files: é¢„æœŸæ–‡ä»¶åˆ—è¡¨
        """
        import os
        from pathlib import Path

        logger.info(f"ğŸ”„ å¼€å§‹é‡å‘½åBç«™å¤šPæ–‡ä»¶ï¼Œç›®å½•: {download_path}")
        logger.info(f"ğŸ“‹ é¢„æœŸæ–‡ä»¶æ•°é‡: {len(expected_files)}")

        # è·å–ç›®å½•ä¸­æ‰€æœ‰è§†é¢‘æ–‡ä»¶
        video_extensions = ["*.mp4", "*.mkv", "*.webm", "*.avi", "*.mov", "*.flv"]
        all_video_files = []
        for ext in video_extensions:
            all_video_files.extend(list(Path(download_path).glob(ext)))

        logger.info(f"ğŸ“ æ‰¾åˆ°è§†é¢‘æ–‡ä»¶æ•°é‡: {len(all_video_files)}")

        renamed_count = 0
        for expected_file in expected_files:
            expected_filename = expected_file['filename']
            original_title = expected_file['title']

            # æŸ¥æ‰¾åŒ¹é…çš„å®é™…æ–‡ä»¶
            for actual_file in all_video_files:
                actual_filename = actual_file.name

                # ä½¿ç”¨æ™ºèƒ½åŒ¹é…é€»è¾‘æ£€æŸ¥æ˜¯å¦åŒ¹é…
                def clean_filename_for_matching(filename):
                    """æ¸…ç†æ–‡ä»¶åç”¨äºåŒ¹é…"""
                    import re
                    if not filename:
                        return ""

                    # åˆ é™¤yt-dlpçš„å„ç§æ ¼å¼ä»£ç 
                    cleaned = re.sub(r'\.[fm]\d+(\+\d+)*', '', filename)
                    cleaned = re.sub(r'\.f\d+', '', cleaned)
                    cleaned = re.sub(r'\.(webm|m4a|mp3)$', '.mp4', cleaned)
                    cleaned = re.sub(r'\.(webm|m4a|mp3)\.mp4$', '.mp4', cleaned)

                    # åˆ é™¤åºå·å‰ç¼€
                    cleaned = re.sub(r'^\d+\.\s*', '', cleaned)

                    # å¯¹Bç«™å¤šPæ ‡é¢˜è¿›è¡Œæ™ºèƒ½å¤„ç†
                    pattern = r'\s+[pP](\d{1,3})\s+'
                    match = re.search(pattern, cleaned)
                    if match:
                        start_pos = match.start() + 1
                        cleaned = cleaned[start_pos:]

                    # ç»Ÿä¸€ç‰¹æ®Šå­—ç¬¦ï¼ˆè§£å†³å…¨è§’/åŠè§’å·®å¼‚ï¼‰
                    # å°†å„ç§ç«–çº¿ç»Ÿä¸€ä¸ºä¸‹åˆ’çº¿ï¼Œä¸_sanitize_filenameä¿æŒä¸€è‡´
                    cleaned = re.sub(r'[|ï½œ]', '_', cleaned)
                    # ç»Ÿä¸€å…¶ä»–ç‰¹æ®Šå­—ç¬¦
                    cleaned = re.sub(r'[ã€ã€‘]', '_', cleaned)

                    # ç¡®ä¿ä»¥ .mp4 ç»“å°¾
                    if not cleaned.endswith('.mp4'):
                        cleaned = cleaned.rstrip('.') + '.mp4'

                    return cleaned

                cleaned_actual = clean_filename_for_matching(actual_filename)
                cleaned_expected = clean_filename_for_matching(expected_filename)

                if cleaned_actual == cleaned_expected:
                    # æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ï¼Œè¿›è¡Œé‡å‘½å
                    new_file_path = actual_file.parent / expected_filename

                    if actual_file != new_file_path:  # é¿å…é‡å‘½åä¸ºç›¸åŒåç§°
                        try:
                            actual_file.rename(new_file_path)
                            logger.info(f"âœ… é‡å‘½åæˆåŠŸ: {actual_filename} -> {expected_filename}")
                            renamed_count += 1
                        except Exception as e:
                            logger.warning(f"âš ï¸ é‡å‘½åå¤±è´¥: {actual_filename} -> {expected_filename}, é”™è¯¯: {e}")
                    else:
                        logger.info(f"ğŸ“ æ–‡ä»¶åå·²æ­£ç¡®: {expected_filename}")
                        renamed_count += 1
                    break
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…æ–‡ä»¶: {expected_filename}")

        logger.info(f"ğŸ‰ é‡å‘½åå®Œæˆ: {renamed_count}/{len(expected_files)} ä¸ªæ–‡ä»¶")

    def _process_bilibili_multipart_title(self, title):
        """
        æ™ºèƒ½å¤„ç†Bç«™å¤šPè§†é¢‘æ ‡é¢˜ï¼Œå»é™¤pxxå‰é¢çš„å†—é•¿å†…å®¹

        ä¾‹å¦‚ï¼š
        è¾“å…¥: "3å°æ—¶è¶…å¿«é€Ÿå…¥é—¨Python | åŠ¨ç”»æ•™å­¦ã€2025æ–°ç‰ˆã€‘ã€è‡ªå­¦Pythonæ•™ç¨‹ã€‘ã€é›¶åŸºç¡€Pythonã€‘ã€è®¡ç®—æœºäºŒçº§Pythonã€‘ã€PythonæœŸæœ«é€Ÿæˆã€‘ p01 å…ˆå¯¼ç¯‡ | ä¸ºä»€ä¹ˆåšè¿™ä¸ªæ•™ç¨‹"
        è¾“å‡º: "p01 å…ˆå¯¼ç¯‡ | ä¸ºä»€ä¹ˆåšè¿™ä¸ªæ•™ç¨‹"
        """
        if not title:
            return title

        import re

        # æŸ¥æ‰¾ pxx æ¨¡å¼ï¼ˆp + æ•°å­—ï¼‰
        # æ”¯æŒ p01, p1, P01, P1 ç­‰æ ¼å¼
        pattern = r'\s+[pP](\d{1,3})\s+'
        match = re.search(pattern, title)

        if match:
            # æ‰¾åˆ° pxxï¼Œä» pxx å¼€å§‹æˆªå–
            start_pos = match.start() + 1  # +1 æ˜¯ä¸ºäº†è·³è¿‡å‰é¢çš„ç©ºæ ¼
            processed_title = title[start_pos:]
            logger.info(f"ğŸ”§ Bç«™å¤šPæ ‡é¢˜å¤„ç†: '{title}' -> '{processed_title}'")
            return processed_title
        else:
            # æ²¡æœ‰æ‰¾åˆ° pxx æ¨¡å¼ï¼Œè¿”å›åŸæ ‡é¢˜
            return title

    def _basic_sanitize_filename(self, filename):
        """
        åŸºæœ¬çš„æ–‡ä»¶åæ¸…ç†ï¼Œä¸yt-dlpä¿æŒä¸€è‡´
        åªæ›¿æ¢æ–‡ä»¶ç³»ç»Ÿä¸æ”¯æŒçš„å­—ç¬¦ï¼Œä¿ç•™å…¶ä»–å­—ç¬¦

        æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°éœ€è¦å®Œå…¨æ¨¡æ‹Ÿyt-dlpçš„å­—ç¬¦å¤„ç†è¡Œä¸º
        """
        if not filename:
            return "video"

        # yt-dlpçš„å­—ç¬¦å¤„ç†è§„åˆ™ï¼ˆåŸºäºè§‚å¯Ÿåˆ°çš„å®é™…è¡Œä¸ºï¼‰ï¼š
        # 1. åŠè§’ | è½¬æ¢ä¸ºå…¨è§’ ï½œ
        filename = filename.replace('|', 'ï½œ')

        # 2. æ–œæ  / è½¬æ¢ä¸ºå¤§æ–œæ ç¬¦å· â§¸ ï¼ˆè¿™æ˜¯yt-dlpçš„å®é™…è¡Œä¸ºï¼‰
        filename = filename.replace('/', 'â§¸')

        # 3. åªæ›¿æ¢æ–‡ä»¶ç³»ç»Ÿç»å¯¹ä¸æ”¯æŒçš„å­—ç¬¦
        # ä¿ç•™ ï½œ ã€ã€‘ â§¸ ç­‰å­—ç¬¦ï¼Œå› ä¸ºyt-dlpä¹Ÿä¼šä¿ç•™å®ƒä»¬
        filename = re.sub(r'[\\:*?"<>]', '_', filename)

        # 3. å»é™¤å¤šä½™ç©ºæ ¼
        filename = re.sub(r'\s+', ' ', filename).strip()

        # 4. å»é™¤å¼€å¤´å’Œç»“å°¾çš„ä¸‹åˆ’çº¿å’Œç©ºæ ¼
        filename = re.sub(r'^[_\s]+|[_\s]+$', '', filename)

        # ç¡®ä¿æ–‡ä»¶åä¸ä¸ºç©º
        if not filename or filename.isspace():
            filename = "video"

        return filename

    def _detect_part_files(self, download_path):
        """æ£€æµ‹PARTæ–‡ä»¶"""
        from pathlib import Path
        part_files = list(Path(download_path).rglob("*.part"))
        return part_files

    def _analyze_failure_reason(self, part_file):
        """åˆ†æPARTæ–‡ä»¶å¤±è´¥åŸå› """
        try:
            file_size = part_file.stat().st_size
            if file_size == 0:
                return "ä¸‹è½½æœªå¼€å§‹æˆ–ç«‹å³å¤±è´¥"
            elif file_size < 1024 * 1024:  # < 1MB
                return "ä¸‹è½½åˆšå¼€å§‹å°±ä¸­æ–­ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜"
            elif file_size < 10 * 1024 * 1024:  # < 10MB
                return "ä¸‹è½½è¿›è¡Œä¸­è¢«ä¸­æ–­ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜"
            else:
                return "ä¸‹è½½è¿›è¡Œä¸­è¢«ä¸­æ–­ï¼Œå¯èƒ½æ˜¯ç½‘ç»œæˆ–ç£ç›˜é—®é¢˜"
        except Exception:
            return "æ— æ³•åˆ†æå¤±è´¥åŸå› "

    def _log_part_files_details(self, part_files):
        """åœ¨æ—¥å¿—ä¸­è®°å½•PARTæ–‡ä»¶è¯¦ç»†ä¿¡æ¯"""
        if part_files:
            logger.warning(f"âš ï¸ å‘ç° {len(part_files)} ä¸ªæœªå®Œæˆçš„PARTæ–‡ä»¶")
            logger.warning("âš ï¸ æœªå®Œæˆçš„æ–‡ä»¶åˆ—è¡¨ï¼š")
            for part_file in part_files:
                reason = self._analyze_failure_reason(part_file)
                logger.warning(f"   - {part_file.name} ({reason})")
        else:
            logger.info("âœ… æœªå‘ç°PARTæ–‡ä»¶ï¼Œæ‰€æœ‰ä¸‹è½½éƒ½å·²å®Œæˆ")

    def _get_enhanced_ydl_opts(self, base_opts=None):
        """è·å–å¢å¼ºçš„yt-dlpé…ç½®ï¼Œé¿å…PARTæ–‡ä»¶äº§ç”Ÿ"""
        enhanced_opts = {
            # åŸºç¡€é…ç½®
            'quiet': False,
            'no_warnings': False,

            # ç½‘ç»œå’Œé‡è¯•é…ç½® - é¿å…ç½‘ç»œä¸­æ–­å¯¼è‡´çš„PARTæ–‡ä»¶
            'socket_timeout': 60,           # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’
            'retries': 10,                  # å¢åŠ é‡è¯•æ¬¡æ•°
            'fragment_retries': 10,         # åˆ†ç‰‡é‡è¯•æ¬¡æ•°
            'retry_sleep_functions': {      # é‡è¯•é—´éš”é…ç½®
                'http': lambda n: min(5 * (2 ** n), 60),  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§60ç§’
                'fragment': lambda n: min(2 * (2 ** n), 30),  # åˆ†ç‰‡é‡è¯•é—´éš”
            },

            # ä¸‹è½½é…ç½® - ç¡®ä¿æ–‡ä»¶å®Œæ•´æ€§å’Œæ–­ç‚¹ç»­ä¼ 
            'skip_unavailable_fragments': False,  # ä¸è·³è¿‡ä¸å¯ç”¨åˆ†ç‰‡ï¼Œç¡®ä¿å®Œæ•´æ€§
            'abort_on_unavailable_fragment': False,  # å…è®¸éƒ¨åˆ†åˆ†ç‰‡å¤±è´¥ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
            'keep_fragments': False,        # ä¸ä¿ç•™åˆ†ç‰‡ï¼Œé¿å…ä¸´æ—¶æ–‡ä»¶å †ç§¯
            'continue_dl': True,            # å¯ç”¨æ–­ç‚¹ç»­ä¼ 
            'part': True,                   # å…è®¸ç”Ÿæˆ.partæ–‡ä»¶ç”¨äºæ–­ç‚¹ç»­ä¼ 
            'mtime': True,                  # ä¿æŒæ–‡ä»¶ä¿®æ”¹æ—¶é—´ï¼Œæœ‰åŠ©äºæ–­ç‚¹ç»­ä¼ 

            # åˆå¹¶é…ç½® - ç¡®ä¿åˆå¹¶æˆåŠŸ
            'merge_output_format': 'mp4',   # å¼ºåˆ¶åˆå¹¶ä¸ºmp4
            'postprocessor_args': {         # åå¤„ç†å‚æ•°
                'ffmpeg': ['-y']            # ffmpegå¼ºåˆ¶è¦†ç›–è¾“å‡ºæ–‡ä»¶
            },

            # é”™è¯¯å¤„ç†é…ç½®
            'ignoreerrors': False,          # ä¸å¿½ç•¥é”™è¯¯ï¼Œç¡®ä¿é—®é¢˜è¢«å‘ç°
            'abort_on_error': False,        # å•ä¸ªæ–‡ä»¶é”™è¯¯æ—¶ä¸ä¸­æ­¢æ•´ä¸ªä¸‹è½½

            # ä¸´æ—¶æ–‡ä»¶é…ç½®
            'writeinfojson': False,         # ä¸å†™å…¥info.jsonï¼Œå‡å°‘ä¸´æ—¶æ–‡ä»¶
            'writesubtitles': False,        # ä¸ä¸‹è½½å­—å¹•ï¼Œå‡å°‘å¤æ‚æ€§
            'writeautomaticsub': False,     # ä¸ä¸‹è½½è‡ªåŠ¨å­—å¹•
        }

        # åˆå¹¶åŸºç¡€é…ç½®
        if base_opts:
            enhanced_opts.update(base_opts)

        # æ·»åŠ ä»£ç†é…ç½®
        if self.proxy_host:
            enhanced_opts['proxy'] = self.proxy_host

        # æ·»åŠ cookiesé…ç½®
        if hasattr(self, 'youtube_cookies_path') and self.youtube_cookies_path and os.path.exists(self.youtube_cookies_path):
            enhanced_opts['cookiefile'] = self.youtube_cookies_path
        elif hasattr(self, 'x_cookies_path') and self.x_cookies_path and os.path.exists(self.x_cookies_path):
            enhanced_opts['cookiefile'] = self.x_cookies_path

        return enhanced_opts

    def _resume_part_files(self, download_path, original_url):
        """æ–­ç‚¹ç»­ä¼ PARTæ–‡ä»¶"""
        from pathlib import Path
        part_files = self._detect_part_files(download_path)
        resumed_count = 0

        if not part_files:
            return 0

        logger.info(f"ğŸ”„ å‘ç° {len(part_files)} ä¸ªPARTæ–‡ä»¶ï¼Œå°è¯•æ–­ç‚¹ç»­ä¼ ")

        for part_file in part_files:
            try:
                # è·å–PARTæ–‡ä»¶ä¿¡æ¯
                file_size = part_file.stat().st_size
                logger.info(f"ğŸ“¥ æ–­ç‚¹ç»­ä¼ : {part_file.name} (å·²ä¸‹è½½: {file_size / (1024*1024):.1f}MB)")

                # ä½¿ç”¨yt-dlpçš„æ–­ç‚¹ç»­ä¼ åŠŸèƒ½
                resume_opts = self._get_enhanced_ydl_opts({
                    'outtmpl': str(download_path / '%(title)s.%(ext)s'),
                    'format': 'best[height<=1080]',
                    'continue_dl': True,  # å¯ç”¨æ–­ç‚¹ç»­ä¼ 
                    'part': True,         # å…è®¸PARTæ–‡ä»¶
                })

                import yt_dlp
                with yt_dlp.YoutubeDL(resume_opts) as ydl:
                    ydl.download([original_url])

                resumed_count += 1
                logger.info(f"âœ… æ–­ç‚¹ç»­ä¼ æˆåŠŸ: {part_file.name}")

            except Exception as e:
                logger.warning(f"âš ï¸ æ–­ç‚¹ç»­ä¼ å¤±è´¥: {part_file.name}, é”™è¯¯: {e}")
                # å¦‚æœæ–­ç‚¹ç»­ä¼ å¤±è´¥ï¼Œå¯ä»¥é€‰æ‹©åˆ é™¤PARTæ–‡ä»¶é‡æ–°ä¸‹è½½
                try:
                    logger.info(f"ğŸ—‘ï¸ åˆ é™¤æŸåçš„PARTæ–‡ä»¶: {part_file.name}")
                    part_file.unlink()
                except Exception as del_e:
                    logger.warning(f"âš ï¸ åˆ é™¤PARTæ–‡ä»¶å¤±è´¥: {del_e}")

        if resumed_count > 0:
            logger.info(f"âœ… æˆåŠŸæ–­ç‚¹ç»­ä¼  {resumed_count} ä¸ªæ–‡ä»¶")

        return resumed_count

    def _resume_failed_downloads(self, download_path, original_url, max_retries=2):
        """æ£€æµ‹å¹¶æ–­ç‚¹ç»­ä¼ å¤±è´¥çš„ä¸‹è½½"""
        part_files = self._detect_part_files(download_path)

        if not part_files:
            return True  # æ²¡æœ‰PARTæ–‡ä»¶ï¼Œä¸‹è½½æˆåŠŸ

        if max_retries <= 0:
            logger.warning(f"âš ï¸ é‡è¯•æ¬¡æ•°å·²ç”¨å®Œï¼Œä»æœ‰ {len(part_files)} ä¸ªæœªå®Œæˆæ–‡ä»¶")
            return False

        logger.info(f"ğŸ”„ æ£€æµ‹åˆ° {len(part_files)} ä¸ªæœªå®Œæˆæ–‡ä»¶ï¼Œå°è¯•æ–­ç‚¹ç»­ä¼  (å‰©ä½™é‡è¯•: {max_retries})")

        # å°è¯•æ–­ç‚¹ç»­ä¼ PARTæ–‡ä»¶
        resumed_count = self._resume_part_files(download_path, original_url)

        # ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ£€æŸ¥
        import time
        time.sleep(1)

        # é€’å½’æ£€æŸ¥æ˜¯å¦è¿˜æœ‰PARTæ–‡ä»¶
        remaining_part_files = self._detect_part_files(download_path)

        if not remaining_part_files:
            logger.info("âœ… æ‰€æœ‰PARTæ–‡ä»¶å·²æˆåŠŸç»­ä¼ å®Œæˆ")
            return True
        elif len(remaining_part_files) < len(part_files):
            logger.info(f"ğŸ“ˆ éƒ¨åˆ†æ–‡ä»¶ç»­ä¼ æˆåŠŸï¼Œå‰©ä½™ {len(remaining_part_files)} ä¸ªæ–‡ä»¶")
            # ç»§ç»­å°è¯•å‰©ä½™æ–‡ä»¶
            return self._resume_failed_downloads(download_path, original_url, max_retries - 1)
        else:
            logger.warning(f"âš ï¸ æ–­ç‚¹ç»­ä¼ æœªèƒ½å‡å°‘PARTæ–‡ä»¶æ•°é‡ï¼Œå‰©ä½™é‡è¯•: {max_retries - 1}")
            if max_retries > 1:
                return self._resume_failed_downloads(download_path, original_url, max_retries - 1)
            else:
                return False

    def _sanitize_filename(self, filename, max_length=200):
        """æ¸…ç†æ–‡ä»¶åï¼Œå»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œé™åˆ¶é•¿åº¦"""
        if not filename:
            return "video"

        # å»é™¤ç‰¹æ®Šå­—ç¬¦
        filename = re.sub(r'[\\/:*?"<>|ã€ã€‘]', '_', filename)
        # å»é™¤å¤šä½™ç©ºæ ¼
        filename = re.sub(r'\s+', ' ', filename).strip()
        # å»é™¤å¼€å¤´å’Œç»“å°¾çš„ç‰¹æ®Šå­—ç¬¦
        filename = re.sub(r'^[_\s]+|[_\s]+$', '', filename)

        # å¦‚æœæ–‡ä»¶åå¤ªé•¿ï¼Œè¿›è¡Œæ™ºèƒ½æˆªæ–­
        if len(filename) > max_length:
            # ä¿ç•™æ‰©å±•åï¼ˆå¦‚æœæœ‰ï¼‰
            name, ext = os.path.splitext(filename)
            if ext:
                # å¦‚æœæœ‰æ‰©å±•åï¼Œä¿ç•™æ‰©å±•åï¼Œæˆªæ–­ä¸»æ–‡ä»¶å
                max_name_length = max_length - len(ext) - 3  # 3æ˜¯"..."çš„é•¿åº¦
                if max_name_length > 0:
                    filename = name[:max_name_length] + "..." + ext
                else:
                    # å¦‚æœæ‰©å±•åå¤ªé•¿ï¼Œåªä¿ç•™æ‰©å±•å
                    filename = "..." + ext
            else:
                # æ²¡æœ‰æ‰©å±•åï¼Œç›´æ¥æˆªæ–­
                filename = filename[:max_length-3] + "..."

        # ç¡®ä¿æ–‡ä»¶åä¸ä¸ºç©º
        if not filename or filename.isspace():
            filename = "video"

        return filename

    def _create_gallery_dl_config(self):
        """åˆ›å»º gallery-dl.conf é…ç½®æ–‡ä»¶"""
        import json

        config_path = Path(self.download_path / "gallery-dl.conf")

        # ä½¿ç”¨ GALLERY_DL_DOWNLOAD_PATH ç¯å¢ƒå˜é‡ï¼Œå¦‚æœæ²¡æœ‰è®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
        gallery_dl_download_path = os.environ.get("GALLERY_DL_DOWNLOAD_PATH")
        if not gallery_dl_download_path:
            # æœ¬åœ°å¼€å‘ç¯å¢ƒé»˜è®¤å€¼
            gallery_dl_download_path = str(self.download_path / "gallery")
            logger.info(f"âš ï¸ æœªè®¾ç½® GALLERY_DL_DOWNLOAD_PATH ç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨é»˜è®¤å€¼: {gallery_dl_download_path}")
        else:
            logger.info(f"âœ… ä½¿ç”¨ GALLERY_DL_DOWNLOAD_PATH ç¯å¢ƒå˜é‡: {gallery_dl_download_path}")
        
        logger.info(f"ğŸ¯ ä½¿ç”¨ GALLERY_DL_DOWNLOAD_PATH: {gallery_dl_download_path}")

        # ä»ç¯å¢ƒå˜é‡è·å–X_COOKIESè·¯å¾„
        x_cookies_env = os.environ.get("X_COOKIES")
        if x_cookies_env:
            cookies_path = x_cookies_env
            logger.info(f"ğŸª ä»ç¯å¢ƒå˜é‡è·å–X_COOKIES: {cookies_path}")
        else:
            cookies_path = str(self.x_cookies_path) if self.x_cookies_path else None
            logger.info(f"ğŸª ä½¿ç”¨åˆå§‹åŒ–å‚æ•°ä¸­çš„X cookies: {cookies_path}")

        config = {
            "base-directory": gallery_dl_download_path,
            "extractor": {
                "twitter": {
                    "cookies": cookies_path
                }
            },
            "downloader": {
                "http": {
                    "timeout": 120,
                    "retries": 15,
                    "sleep": 5,
                    "verify": False,
                    "headers": {
                        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
                        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                        "Accept-Encoding": "gzip, deflate, br",
                        "DNT": "1",
                        "Connection": "keep-alive",
                        "Upgrade-Insecure-Requests": "1",
                        "Sec-Fetch-Dest": "document",
                        "Sec-Fetch-Mode": "navigate",
                        "Sec-Fetch-Site": "cross-site",
                        "Sec-Fetch-User": "?1",
                        "Cache-Control": "max-age=0",
                        "Referer": "https://telegra.ph/",
                        "Origin": "https://telegra.ph"
                    },
                    "max_retries": 15,
                    "retry_delay": 5,
                    "connection_timeout": 60,
                    "read_timeout": 120,
                    "chunk_size": 8192,
                    "stream": True,
                    "allow_redirects": True,
                    "max_redirects": 10
                }
            }
        }

        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)

        logger.info(f"å·²æˆåŠŸåˆ›å»º gallery-dl.conf é…ç½®æ–‡ä»¶: {config_path}")
        logger.info(f"é…ç½®æ–‡ä»¶å†…å®¹:\n{json.dumps(config, indent=2, ensure_ascii=False)}")


class TelegramBot:
    def __init__(self, token: str, downloader: VideoDownloader):
        self.token = token
        self.downloader = downloader
        self.application = None
        self.bot_id = None
        self.qb_client = None
        
        # æ–°å¢ï¼šé…ç½®æŒä¹…åŒ– - åœ¨_load_configä¹‹å‰è®¾ç½®
        self.config_path = Path(os.getenv("CONFIG_PATH", "config/settings.json"))
        
        # åŠ è½½é…ç½®
        self.config = self._load_config()
        self.auto_download_enabled = self.config.get("auto_download_enabled", True)
        self.download_tasks = (
            {}
        )  # å­˜å‚¨ä¸‹è½½ä»»åŠ¡ {task_id: {'task': asyncio.Task, 'cancelled': bool}}
        self.task_lock = asyncio.Lock()  # ç”¨äºä¿æŠ¤ä»»åŠ¡å­—å…¸çš„é”
        self.user_client: TelegramClient | None = None

        # æ–°å¢ï¼šBç«™è‡ªåŠ¨ä¸‹è½½å…¨é›†é…ç½®
        self.bilibili_auto_playlist = self.config.get("bilibili_auto_playlist", False)  # é»˜è®¤å…³é—­è‡ªåŠ¨ä¸‹è½½å…¨é›†

        # qBittorrent é…ç½® - åªåœ¨æœ‰é…ç½®æ—¶æ‰å¯ç”¨
        self.qb_config = {
            "host": os.getenv("QB_HOST"),
            "port": os.getenv("QB_PORT"),
            "username": os.getenv("QB_USERNAME"),
            "password": os.getenv("QB_PASSWORD"),
            "enabled": False,  # é»˜è®¤ç¦ç”¨
        }

        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„ qBittorrent é…ç½®
        if all(
            [
                self.qb_config["host"],
                self.qb_config["port"],
                self.qb_config["username"],
                self.qb_config["password"],
            ]
        ):
            try:
                self.qb_config["port"] = int(self.qb_config["port"])
                self.qb_config["enabled"] = True
                logger.info(f"å·²é…ç½® qBittorrent: {self.qb_config['host']}:{self.qb_config['port']}")
            except (ValueError, TypeError):
                logger.warning("qBittorrent ç«¯å£é…ç½®æ— æ•ˆï¼Œè·³è¿‡è¿æ¥")
        else:
            logger.info("æœªé…ç½® qBittorrent")

        # æ–°å¢ï¼šæƒé™ç®¡ç†
        self.allowed_user_ids = self._parse_user_ids(os.getenv("TELEGRAM_BOT_ALLOWED_USER_IDS", ""))
        logger.info(f"ğŸ” å…è®¸çš„ç”¨æˆ·: {self.allowed_user_ids}")

    def _parse_user_ids(self, user_ids_str: str) -> list:
        """è§£æç”¨æˆ·IDå­—ç¬¦ä¸²ä¸ºåˆ—è¡¨"""
        if not user_ids_str:
            return []
        
        try:
            # æ”¯æŒé€—å·ã€åˆ†å·ã€ç©ºæ ¼åˆ†éš”çš„ç”¨æˆ·ID
            user_ids = []
            for user_id_str in re.split(r"[,;\s]+", user_ids_str.strip()):
                if user_id_str.strip():
                    user_ids.append(int(user_id_str.strip()))
            return user_ids
        except ValueError as e:
            logger.error(f"è§£æç”¨æˆ·IDå¤±è´¥: {e}")
            return []

    def _check_user_permission(self, user_id: int) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™ä½¿ç”¨æœºå™¨äºº"""
        # å¦‚æœæ²¡æœ‰é…ç½®å…è®¸çš„ç”¨æˆ·ï¼Œåˆ™å…è®¸æ‰€æœ‰ç”¨æˆ·ï¼ˆå‘åå…¼å®¹ï¼‰
        if not self.allowed_user_ids:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„ç”¨æˆ·åˆ—è¡¨ä¸­
        return user_id in self.allowed_user_ids

    def _load_config(self):
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            if self.config_path.exists():
                config_data = json.loads(self.config_path.read_text())
                logger.info(
                    f"ä» {self.config_path} åŠ è½½é…ç½®, Bç«™å¤šPè‡ªåŠ¨ä¸‹è½½æ¨¡å¼: {config_data.get('bilibili_auto_playlist', False)}"
                )
                return config_data
            else:
                # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
                default_config = {
                    "auto_download_enabled": True,
                    "bilibili_auto_playlist": False
                }
                self._save_config_sync(default_config)
                return default_config
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤é…ç½®
            return {
                "auto_download_enabled": True,
                "bilibili_auto_playlist": False
            }

    def _save_config_sync(self, config_data=None):
        """åŒæ­¥ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            if config_data is None:
                config_data = {
                    "auto_download_enabled": self.auto_download_enabled,
                    "bilibili_auto_playlist": self.bilibili_auto_playlist
                }
            
            self.config_path.parent.mkdir(parents=True, exist_ok=True)
            self.config_path.write_text(json.dumps(config_data, indent=4))
            logger.info(f"é…ç½®å·²ä¿å­˜åˆ° {self.config_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    async def _save_config_async(self):
        """å¼‚æ­¥ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        loop = asyncio.get_running_loop()
        await loop.run_in_executor(None, self._save_config_sync)

    def _make_progress_bar(self, percent: float) -> str:
        """ç”Ÿæˆè¿›åº¦æ¡"""
        bar_length = 20
        # ç¡®ä¿percentåœ¨0-100èŒƒå›´å†…
        percent = max(0, min(percent, 100))
        filled_length = int(bar_length * percent / 100)
        bar = "â–ˆ" * filled_length + "â–‘" * (bar_length - filled_length)
        return bar

    def _escape_markdown(self, text: str) -> str:
        """è½¬ä¹‰Markdownç‰¹æ®Šå­—ç¬¦"""
        if not text:
            return text

        # éœ€è¦è½¬ä¹‰çš„ç‰¹æ®Šå­—ç¬¦
        special_chars = [
            "_",
            "*",
            "[",
            "]",
            "(",
            ")",
            "~",
            "`",
            ">",
            "#",
            "+",
            "-",
            "=",
            "|",
            "{",
            "}",
            ".",
            "!",
        ]

        escaped_text = text
        for char in special_chars:
            escaped_text = escaped_text.replace(char, f"\\{char}")

        return escaped_text

    async def post_init(self, application: Application):
        """åœ¨åº”ç”¨å¯åŠ¨åè¿è¡Œçš„åˆå§‹åŒ–ä»»åŠ¡, è·å–æœºå™¨äººè‡ªèº« ID"""
        bot_info = await application.bot.get_me()
        self.bot_id = bot_info.id
        logger.info(f"æœºå™¨äººå·²å¯åŠ¨ï¼Œç”¨æˆ·åä¸º: @{bot_info.username} (ID: {self.bot_id})")

    def _connect_qbittorrent(self):
        """è¿æ¥åˆ° qBittorrent å®¢æˆ·ç«¯"""
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº† qBittorrent
            if not self.qb_config["enabled"]:
                return

            logger.info(
                f"æ­£åœ¨è¿æ¥ qBittorrent: {self.qb_config['host']}:{self.qb_config['port']}"
            )

            # åˆ›å»ºå®¢æˆ·ç«¯
            self.qbit_client = qbittorrentapi.Client(
                host=self.qb_config["host"],
                port=self.qb_config["port"],
                username=self.qb_config["username"],
                password=self.qb_config["password"],
                VERIFY_WEBUI_CERTIFICATE=False,  # ç¦ç”¨SSLè¯ä¹¦éªŒè¯
                REQUESTS_ARGS={"timeout": 10},  # è®¾ç½®10ç§’è¶…æ—¶
            )

            # å°è¯•ç™»å½•
            self.qbit_client.auth_log_in()

            # æ£€æŸ¥è¿æ¥çŠ¶æ€
            if not self.qbit_client.is_logged_in:
                logger.error("qBittorrent è¿æ¥å¤±è´¥")
                self.qbit_client = None
                return

            # è·å– qBittorrent ç‰ˆæœ¬ä¿¡æ¯
            try:
                version_info = self.qbit_client.app.version
                logger.info(f"qBittorrent è¿æ¥æˆåŠŸ (ç‰ˆæœ¬: {version_info})")
            except Exception as e:
                logger.info("qBittorrent è¿æ¥æˆåŠŸ")

            # åˆ›å»ºæ ‡ç­¾
            try:
                self.qbit_client.torrents_create_tags(tags="savextube")
            except Exception:
                pass

        except qbittorrentapi.LoginFailed as e:
            logger.error("qBittorrent è¿æ¥å¤±è´¥: ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
            self.qbit_client = None
        except qbittorrentapi.APIConnectionError as e:
            logger.error("qBittorrent è¿æ¥å¤±è´¥: æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
            self.qbit_client = None
        except Exception as e:
            logger.error(f"qBittorrent è¿æ¥å¤±è´¥: {e}")
            self.qbit_client = None

    def _is_magnet_link(self, text: str) -> bool:
        magnet_pattern = r"magnet:\?xt=urn:btih:[a-fA-F0-9]{32,40}"
        return bool(re.search(magnet_pattern, text))

    def _extract_magnet_links(self, text: str):
        # æ”¯æŒå¤šæ¡ç£åŠ›é“¾æ¥ï¼Œå¿½ç•¥å‰åå…¶å®ƒæ–‡å­—
        magnet_pattern = r"(magnet:\?xt=urn:btih:[a-fA-F0-9]{32,40}[^\s]*)"
        return re.findall(magnet_pattern, text)

    async def add_magnet_to_qb(self, magnet_link: str) -> bool:
        """æ·»åŠ ç£åŠ›é“¾æ¥åˆ° qBittorrent"""
        try:
            # æ£€æŸ¥ qBittorrent å®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨
            if not self.qbit_client:
                logger.error("qBittorrent å®¢æˆ·ç«¯æœªè¿æ¥")
                return False

            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            if not self.qbit_client.is_logged_in:
                logger.error("qBittorrent æœªç™»å½•")
                return False

            # éªŒè¯ç£åŠ›é“¾æ¥æ ¼å¼
            if not self._is_magnet_link(magnet_link):
                logger.error(f"æ— æ•ˆçš„ç£åŠ›é“¾æ¥æ ¼å¼: {magnet_link}")
                return False

            logger.info(f"æ­£åœ¨æ·»åŠ ç£åŠ›é“¾æ¥åˆ° qBittorrent: {magnet_link[:50]}...")

            # æ·»åŠ ç£åŠ›é“¾æ¥
            self.qbit_client.torrents_add(urls=magnet_link, tags="savextube")

            logger.info("âœ… æˆåŠŸæ·»åŠ ç£åŠ›é“¾æ¥åˆ° qBittorrent")
            return True

        except qbittorrentapi.APIConnectionError as e:
            logger.error(f"qBittorrent API è¿æ¥é”™è¯¯: {e}")
            return False
        except qbittorrentapi.LoginFailed as e:
            logger.error(f"qBittorrent ç™»å½•å¤±è´¥: {e}")
            return False
        except Exception as e:
            logger.error(f"æ·»åŠ ç£åŠ›é“¾æ¥å¤±è´¥: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            return False

    async def add_torrent_file_to_qb(self, torrent_data: bytes, filename: str) -> bool:
        """æ·»åŠ ç§å­æ–‡ä»¶åˆ° qBittorrent"""
        try:
            # æ£€æŸ¥ qBittorrent å®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨
            if not self.qbit_client:
                logger.error("qBittorrent å®¢æˆ·ç«¯æœªè¿æ¥")
                return False

            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            if not self.qbit_client.is_logged_in:
                logger.error("qBittorrent æœªç™»å½•")
                return False

            logger.info(f"æ­£åœ¨æ·»åŠ ç§å­æ–‡ä»¶åˆ° qBittorrent: {filename}")

            # å°†å­—èŠ‚æ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶
            import tempfile
            import os
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.torrent') as temp_file:
                temp_file.write(torrent_data)
                temp_file_path = temp_file.name

            try:
                # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è·¯å¾„æ·»åŠ ç§å­
                self.qbit_client.torrents_add(torrent_files=temp_file_path, tags="savextube")
                logger.info("âœ… æˆåŠŸæ·»åŠ ç§å­æ–‡ä»¶åˆ° qBittorrent")
                return True
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_file_path)
                except Exception as e:
                    logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

        except qbittorrentapi.APIConnectionError as e:
            logger.error(f"qBittorrent API è¿æ¥é”™è¯¯: {e}")
            return False
        except qbittorrentapi.LoginFailed as e:
            logger.error(f"qBittorrent ç™»å½•å¤±è´¥: {e}")
            return False
        except Exception as e:
            logger.error(f"æ·»åŠ ç§å­æ–‡ä»¶å¤±è´¥: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            return False

    def _clean_filename_for_display(self, filename):
        """æ¸…ç†æ–‡ä»¶åç”¨äºæ˜¾ç¤º"""
        try:
            # ç§»é™¤æ—¶é—´æˆ³å‰ç¼€å¦‚æœå­˜åœ¨
            import re

            if re.match(r"^\d{10}_", filename):
                display_name = filename[11:]
            else:
                display_name = filename

            # å¦‚æœæ–‡ä»¶åå¤ªé•¿ï¼Œè¿›è¡Œæ™ºèƒ½æˆªæ–­
            if len(display_name) > 35:
                name, ext = os.path.splitext(display_name)
                display_name = name[:30] + "..." + ext

            return display_name
        except BaseException:
            return filename if len(filename) <= 35 else filename[:32] + "..."

    def _get_resolution_quality(self, resolution):
        """æ ¹æ®åˆ†è¾¨ç‡ç”Ÿæˆè´¨é‡æ ‡è¯†"""
        if not resolution or resolution == 'æœªçŸ¥':
            return ''
        
        # æå–åˆ†è¾¨ç‡æ•°å­—
        import re
        match = re.search(r'(\d+)x(\d+)', resolution)
        if not match:
            return ''
        
        width = int(match.group(1))
        height = int(match.group(2))
        
        # æ ¹æ®é«˜åº¦åˆ¤æ–­è´¨é‡
        if height >= 4320:
            return ' (8K)'
        elif height >= 2160:
            return ' (4K)'
        elif height >= 1440:
            return ' (2K)'
        elif height >= 1080:
            return ' (1080p)'
        elif height >= 720:
            return ' (720p)'
        elif height >= 480:
            return ' (480p)'
        elif height >= 360:
            return ' (360p)'
        else:
            return ' (ä½ç”»è´¨)'

    def _create_progress_bar(self, percent: float, length: int = 20) -> str:
        """åˆ›å»ºè¿›åº¦æ¡"""
        filled_length = int(length * percent / 100)
        bar = "â–ˆ" * filled_length + "â–‘" * (length - filled_length)
        return bar

    def _signal_handler(self, signum, frame):
        """å¤„ç†ç³»ç»Ÿä¿¡å·"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
        if self.user_client:
            asyncio.create_task(self.user_client.disconnect())
        self.executor.shutdown(wait=True)
        sys.exit(0)

    def _setup_handlers(self):
        """è®¾ç½®æ‰€æœ‰çš„å‘½ä»¤å’Œæ¶ˆæ¯å¤„ç†å™¨"""
        if not self.application:
            return

        self.application.add_handler(CommandHandler("start", self.start_command))
        self.application.add_handler(CommandHandler("version", self.version_command))
        self.application.add_handler(CommandHandler("status", self.status_command))
        # self.application.add_handler(CommandHandler("sxt", self.sxt_command))
        # # å·²åˆ é™¤ï¼šsxtå‘½ä»¤å¤„ç†å™¨
        self.application.add_handler(CommandHandler("settings", self.settings_command))
        self.application.add_handler(
            CallbackQueryHandler(self.settings_button_handler, pattern="toggle_autop")
        )
        self.application.add_handler(
            CallbackQueryHandler(self.cancel_task_callback, pattern="cancel:")
        )
        # ç»Ÿä¸€çš„åª’ä½“å¤„ç†å™¨ï¼Œæ˜ç¡®æŒ‡å‘æ–°å‡½æ•°
        media_filter = (
            filters.AUDIO | filters.VIDEO | filters.Document.ALL
        ) & ~filters.COMMAND
        # self.application.add_handler(MessageHandler(media_filter,
        # self.handle_media)) # ç¦ç”¨æ—§çš„å¤„ç†å™¨
        self.application.add_handler(
            MessageHandler(media_filter, self.download_user_media)
        )  # å¯ç”¨æ–°å¤„ç†å™¨

        # æ–‡æœ¬æ¶ˆæ¯å¤„ç†å™¨ - ä¿æŒä¸å˜
        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message)
        )

        # é”™è¯¯å¤„ç†å™¨
        self.application.add_error_handler(self.error_handler)
        logger.info("æ‰€æœ‰å¤„ç†å™¨å·²è®¾ç½®ã€‚")

    async def run(self):
        """å¯åŠ¨æœºå™¨äººå’Œæ‰€æœ‰å®¢æˆ·ç«¯"""
        # 1. è¿æ¥ qBittorrent
        self._connect_qbittorrent()
        # 2. åˆå§‹åŒ–å¹¶è¿æ¥ Telethon å®¢æˆ·ç«¯
        api_id = os.getenv("TELEGRAM_BOT_API_ID")
        api_hash = os.getenv("TELEGRAM_BOT_API_HASH")
        session_string = os.getenv("TELEGRAM_SESSION_STRING")
        logger.info("--- Telethon é…ç½®è¯Šæ–­ ---")
        logger.info(f"è¯»å– TELEGRAM_BOT_API_ID: {'å·²æ‰¾åˆ°' if api_id else 'æœªæ‰¾åˆ°'}")
        logger.info(
            f"è¯»å– TELEGRAM_BOT_API_HASH: {'å·²æ‰¾åˆ°' if api_hash else 'æœªæ‰¾åˆ°'}"
        )
        logger.info(
            f"è¯»å– TELEGRAM_SESSION_STRING: {'å·²æ‰¾åˆ°' if session_string else 'æœªæ‰¾åˆ°'}"
        )
        logger.info("--------------------------")
        if all([api_id, api_hash, session_string]):
            try:
                self.user_client = TelegramClient(
                    StringSession(session_string), int(api_id), api_hash
                )
                if self.downloader.proxy_host:
                    p_url = urlparse(self.downloader.proxy_host)
                    proxy_config = (p_url.scheme, p_url.hostname, p_url.port)
                    self.user_client.set_proxy(proxy_config)
                    logger.info(
                        f"Telethon å®¢æˆ·ç«¯ä½¿ç”¨ä»£ç†: {self.downloader.proxy_host}"
                    )
                logger.info("æ­£åœ¨è¿æ¥ Telethon å®¢æˆ·ç«¯...")
                await self.user_client.start()
                logger.info("Telethon å®¢æˆ·ç«¯è¿æ¥æˆåŠŸã€‚")
            except Exception as e:
                logger.error(f"Telethon å®¢æˆ·ç«¯å¯åŠ¨å¤±è´¥: {e}", exc_info=True)
                self.user_client = None
        else:
            logger.warning("Telethon æœªå®Œæ•´é…ç½®ï¼Œåª’ä½“è½¬å­˜åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
        # 3. è®¾ç½®å¹¶å¯åŠ¨ PTB Application
        if self.downloader.proxy_host:
            logger.info(f"Telegram Bot ä½¿ç”¨ä»£ç†: {self.downloader.proxy_host}")
            self.application = (
                Application.builder().token(self.token).proxy(self.downloader.proxy_host).post_init(self.post_init).build()
            )
        else:
            logger.info("Telegram Bot ç›´æ¥è¿æ¥")
            self.application = (
                Application.builder().token(self.token).post_init(self.post_init).build()
            )
        self._setup_handlers()

        logger.info("å¯åŠ¨ Telegram Bot (PTB)...")

        # å¢å¼ºçš„ç½‘ç»œé‡è¯•æœºåˆ¶
        max_retries = int(os.getenv("TELEGRAM_MAX_RETRIES", "10"))
        base_delay = float(os.getenv("TELEGRAM_BASE_DELAY", "5.0"))
        max_delay = float(os.getenv("TELEGRAM_MAX_DELAY", "300.0"))

        retry_count = 0
        while retry_count <= max_retries:
            try:
                async with self.application:
                    await self.application.initialize()
                    await self.application.start()

                    # é…ç½®æ›´å¼ºçš„ç½‘ç»œå‚æ•°
                    await self.application.updater.start_polling(
                        timeout=30,  # å¢åŠ è¶…æ—¶æ—¶é—´
                        read_timeout=30,
                        write_timeout=30,
                        connect_timeout=30,
                        pool_timeout=30
                    )

                    logger.info("æœºå™¨äººå·²æˆåŠŸå¯åŠ¨å¹¶æ­£åœ¨è¿è¡Œã€‚")

                    # æ·»åŠ å®šæœŸå¥åº·æ£€æŸ¥å’Œç½‘ç»œç›‘æ§
                    if os.getenv("ENABLE_HEALTH_CHECK", "true").lower() == "true":
                        asyncio.create_task(self._periodic_health_check())
                        asyncio.create_task(self._network_monitor())
                        asyncio.create_task(self._keep_alive_heartbeat())

                    await asyncio.Event().wait()
                    break  # æˆåŠŸå¯åŠ¨ï¼Œé€€å‡ºé‡è¯•å¾ªç¯

            except (NetworkError, TimedOut, RetryAfter, httpx.RemoteProtocolError,
                   httpx.ConnectError, httpx.TimeoutException, ConnectionError) as e:
                retry_count += 1
                if retry_count <= max_retries:
                    # è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿ
                    delay = min(base_delay * (2 ** (retry_count - 1)), max_delay)
                    logger.warning(f"ğŸŒ Telegram Botç½‘ç»œé”™è¯¯: {e}")
                    logger.warning(f"ğŸ”„ {delay:.1f}ç§’åé‡è¯• ({retry_count}/{max_retries})")
                    await asyncio.sleep(delay)
                else:
                    logger.error(f"âŒ Telegram Botç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    raise e
            except Exception as e:
                logger.error(f"âŒ Telegram Botå¯åŠ¨å¤±è´¥: {e}")
                raise e

    async def _periodic_health_check(self):
        """å®šæœŸå¥åº·æ£€æŸ¥ï¼Œç›‘æ§ç½‘ç»œè¿æ¥çŠ¶æ€å¹¶è‡ªåŠ¨æ¢å¤"""
        check_interval = int(os.getenv("HEALTH_CHECK_INTERVAL", "30"))  # ç¼©çŸ­åˆ°30ç§’æ£€æŸ¥ä¸€æ¬¡
        max_failures = int(os.getenv("HEALTH_CHECK_MAX_FAILURES", "3"))  # æœ€å¤§å¤±è´¥æ¬¡æ•°
        failure_count = 0
        last_success_time = time.time()

        while True:
            try:
                await asyncio.sleep(check_interval)

                # æ£€æŸ¥ Telegram API è¿æ¥
                try:
                    await self.application.bot.get_me()
                    if failure_count > 0:
                        logger.info(f"ğŸŸ¢ ç½‘ç»œè¿æ¥å·²æ¢å¤ï¼è¿ç»­å¤±è´¥ {failure_count} æ¬¡åæ¢å¤æ­£å¸¸")
                    failure_count = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                    last_success_time = time.time()
                    logger.debug("ğŸŸ¢ å¥åº·æ£€æŸ¥é€šè¿‡ - Telegram API è¿æ¥æ­£å¸¸")

                except Exception as e:
                    failure_count += 1
                    current_time = time.time()
                    offline_duration = current_time - last_success_time

                    logger.warning(f"ğŸŸ¡ å¥åº·æ£€æŸ¥å¤±è´¥ ({failure_count}/{max_failures}): {e}")
                    logger.warning(f"â±ï¸ ç¦»çº¿æ—¶é•¿: {offline_duration:.0f}ç§’")

                    if failure_count >= max_failures:
                        logger.error(f"ğŸ”´ å¥åº·æ£€æŸ¥è¿ç»­å¤±è´¥ {max_failures} æ¬¡ï¼Œå°è¯•é‡å¯Botè¿æ¥")

                        # å°è¯•é‡å¯Botè¿æ¥
                        try:
                            await self._restart_bot_connection()
                            logger.info("âœ… Botè¿æ¥é‡å¯æˆåŠŸ")
                            failure_count = 0  # é‡ç½®è®¡æ•°å™¨
                        except Exception as restart_error:
                            logger.error(f"âŒ Botè¿æ¥é‡å¯å¤±è´¥: {restart_error}")
                            # ç»§ç»­ç›‘æ§ï¼Œä¸è¦åœæ­¢å¥åº·æ£€æŸ¥

            except Exception as e:
                logger.error(f"âŒ å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
                await asyncio.sleep(10)  # å¼‚å¸¸æ—¶çŸ­æš‚ç­‰å¾…åç»§ç»­

    async def _restart_bot_connection(self):
        """é‡å¯Botè¿æ¥"""
        logger.info("ğŸ”„ å¼€å§‹é‡å¯Botè¿æ¥...")

        try:
            # åœæ­¢å½“å‰çš„polling
            if self.application.updater.running:
                await self.application.updater.stop()
                logger.info("ğŸ“´ å·²åœæ­¢å½“å‰polling")

            # ç­‰å¾…ä¸€æ®µæ—¶é—´
            await asyncio.sleep(5)

            # é‡æ–°å¯åŠ¨polling
            await self.application.updater.start_polling(
                timeout=30,
                read_timeout=30,
                write_timeout=30,
                connect_timeout=30,
                pool_timeout=30
            )
            logger.info("ğŸ“¡ å·²é‡æ–°å¯åŠ¨polling")

        except Exception as e:
            logger.error(f"âŒ é‡å¯Botè¿æ¥å¤±è´¥: {e}")
            raise e

    async def _network_monitor(self):
        """ç½‘ç»œçŠ¶æ€ç›‘æ§ï¼Œæ£€æµ‹é•¿æ—¶é—´çš„ç½‘ç»œä¸­æ–­"""
        monitor_interval = int(os.getenv("NETWORK_MONITOR_INTERVAL", "120"))  # 2åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        max_offline_time = int(os.getenv("MAX_OFFLINE_TIME", "600"))  # æœ€å¤§ç¦»çº¿æ—¶é—´10åˆ†é’Ÿ

        last_successful_check = time.time()
        consecutive_failures = 0

        while True:
            try:
                await asyncio.sleep(monitor_interval)

                # æµ‹è¯•ç½‘ç»œè¿æ¥
                network_ok = await test_network_connectivity()
                current_time = time.time()

                if network_ok:
                    if consecutive_failures > 0:
                        offline_duration = current_time - last_successful_check
                        logger.info(f"ğŸŸ¢ ç½‘ç»œè¿æ¥å·²æ¢å¤ï¼ç¦»çº¿æ—¶é•¿: {offline_duration:.0f}ç§’")
                    consecutive_failures = 0
                    last_successful_check = current_time
                else:
                    consecutive_failures += 1
                    offline_duration = current_time - last_successful_check

                    logger.warning(f"ğŸ”´ ç½‘ç»œç›‘æ§æ£€æµ‹åˆ°è¿æ¥é—®é¢˜ (è¿ç»­å¤±è´¥ {consecutive_failures} æ¬¡)")
                    logger.warning(f"â±ï¸ ç¦»çº¿æ—¶é•¿: {offline_duration:.0f}ç§’")

                    # å¦‚æœç¦»çº¿æ—¶é—´è¿‡é•¿ï¼Œå°è¯•é‡å¯æ•´ä¸ªåº”ç”¨
                    if offline_duration > max_offline_time:
                        logger.error(f"ğŸ’€ ç½‘ç»œç¦»çº¿æ—¶é—´è¶…è¿‡ {max_offline_time} ç§’ï¼Œè€ƒè™‘é‡å¯åº”ç”¨")
                        # è¿™é‡Œå¯ä»¥æ·»åŠ é‡å¯é€»è¾‘ï¼Œä½†è¦è°¨æ…

            except Exception as e:
                logger.error(f"âŒ ç½‘ç»œç›‘æ§å¼‚å¸¸: {e}")
                await asyncio.sleep(30)  # å¼‚å¸¸æ—¶çŸ­æš‚ç­‰å¾…

    async def _keep_alive_heartbeat(self):
        """ä¿æŒè¿æ¥æ´»è·ƒçš„å¿ƒè·³æœºåˆ¶"""
        heartbeat_interval = int(os.getenv("HEARTBEAT_INTERVAL", "300"))  # 5åˆ†é’Ÿå‘é€ä¸€æ¬¡å¿ƒè·³

        while True:
            try:
                await asyncio.sleep(heartbeat_interval)

                # å‘é€ä¸€ä¸ªè½»é‡çº§çš„APIè°ƒç”¨æ¥ä¿æŒè¿æ¥æ´»è·ƒ
                try:
                    await self.application.bot.get_me()
                    logger.debug("ğŸ’“ å¿ƒè·³ä¿æŒè¿æ¥æ´»è·ƒ")
                except Exception as e:
                    logger.warning(f"ğŸ’” å¿ƒè·³å¤±è´¥: {e}")
                    # å¿ƒè·³å¤±è´¥ä¸éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå¥åº·æ£€æŸ¥ä¼šå¤„ç†

            except Exception as e:
                logger.error(f"âŒ å¿ƒè·³æœºåˆ¶å¼‚å¸¸: {e}")
                await asyncio.sleep(60)  # å¼‚å¸¸æ—¶ç­‰å¾…1åˆ†é’Ÿ

    async def version_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¤„ç† /version å‘½ä»¤ - æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
        user_id = update.message.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await update.message.reply_text("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        update_heartbeat()
        try:
            version_text = (
                f"âš™ï¸ <b>ç³»ç»Ÿç‰ˆæœ¬ä¿¡æ¯</b>\n\n"
                f"  - <b>æœºå™¨äºº</b>: <code>{BOT_VERSION}</code>"
            )
            await update.message.reply_text(version_text, parse_mode="HTML")
        except Exception as e:
            await update.message.reply_text(f"âŒ è·å–ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")

    async def formats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¤„ç† /formats å‘½ä»¤ - æ£€æŸ¥è§†é¢‘æ ¼å¼"""
        user_id = update.message.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await update.message.reply_text("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        update_heartbeat()

        try:
            # è·å–ç”¨æˆ·å‘é€çš„URL
            if not context.args:
                await update.message.reply_text(
                    """æ ¼å¼æ£€æŸ¥å‘½ä»¤
ä½¿ç”¨æ–¹æ³•ï¼š
/formats <è§†é¢‘é“¾æ¥>
ç¤ºä¾‹ï¼š
/formats https://www.youtube.com/watch?v=xxx
æ­¤å‘½ä»¤ä¼šæ˜¾ç¤ºè§†é¢‘çš„å¯ç”¨æ ¼å¼ï¼Œå¸®åŠ©è°ƒè¯•ä¸‹è½½é—®é¢˜ã€‚"""
                )
                return

            url = context.args[0]

            # éªŒè¯URL
            if not url.startswith(("http://", "https://")):
                await update.message.reply_text("è¯·æä¾›æœ‰æ•ˆçš„è§†é¢‘é“¾æ¥")
                return

            check_message = await update.message.reply_text("æ­£åœ¨æ£€æŸ¥è§†é¢‘æ ¼å¼...")

            # æ£€æŸ¥æ ¼å¼
            result = self.downloader.check_video_formats(url)

            if result["success"]:
                formats_text = f"""è§†é¢‘æ ¼å¼ä¿¡æ¯
æ ‡é¢˜ï¼š{result['title']}
å¯ç”¨æ ¼å¼ï¼ˆå‰10ä¸ªï¼‰ï¼š
"""
                for i, fmt in enumerate(result["video_formats"], 1):
                    size_info = ""
                    if fmt["filesize"] and fmt["filesize"] > 0:
                        size_mb = fmt["filesize"] / (1024 * 1024)
                        size_info = f" ({size_mb:.1f}MB)"

                    formats_text += f"{i}. ID: {fmt['id']} | {fmt['ext']} | {fmt['quality']}{size_info}\n"

                formats_text += "\néŸ³é¢‘æ ¼å¼ï¼ˆå‰5ä¸ªï¼‰ï¼š\n"
                for i, fmt in enumerate(result["audio_formats"], 1):
                    size_info = ""
                    if fmt["filesize"] and fmt["filesize"] > 0:
                        size_mb = fmt["filesize"] / (1024 * 1024)
                        size_info = f" ({size_mb:.1f}MB)"

                    formats_text += f"{i}. ID: {fmt['id']} | {fmt['ext']} | {fmt['quality']}{size_info}\n"

                formats_text += "\nå¦‚æœä¸‹è½½å¤±è´¥ï¼Œå¯ä»¥å°è¯•å…¶ä»–è§†é¢‘æˆ–æŠ¥å‘Šæ­¤ä¿¡æ¯ã€‚"

                await check_message.edit_text(formats_text)
            else:
                await check_message.edit_text(f"æ ¼å¼æ£€æŸ¥å¤±è´¥: {result['error']}")

        except Exception as e:
            await update.message.reply_text(f"æ ¼å¼æ£€æŸ¥å‡ºé”™: {str(e)}")

    async def cleanup_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¤„ç† /cleanup å‘½ä»¤"""
        user_id = update.message.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await update.message.reply_text("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        update_heartbeat()

        cleanup_message = await update.message.reply_text("å¼€å§‹æ¸…ç†é‡å¤æ–‡ä»¶...")

        try:
            cleaned_count = self.downloader.cleanup_duplicates()
            if cleaned_count > 0:
                completion_text = f"""æ¸…ç†å®Œæˆ!
åˆ é™¤äº† {cleaned_count} ä¸ªé‡å¤æ–‡ä»¶
é‡Šæ”¾äº†å­˜å‚¨ç©ºé—´"""
            else:
                completion_text = "æ¸…ç†å®Œæˆ! æœªå‘ç°é‡å¤æ–‡ä»¶"

            await cleanup_message.edit_text(completion_text)
        except Exception as e:
            await cleanup_message.edit_text(f"æ¸…ç†å¤±è´¥: {str(e)}")

    async def status_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¤„ç† /status å‘½ä»¤"""
        user_id = update.message.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await update.message.reply_text("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        update_heartbeat()
        try:
            # ç»Ÿè®¡æ–‡ä»¶
            video_extensions = ["*.mp4", "*.mkv", "*.webm", "*.mov", "*.avi"]
            x_files = []
            if self.downloader.x_download_path.exists():
                for ext in video_extensions:
                    x_files.extend(self.downloader.x_download_path.glob(ext))
            youtube_files = []
            if self.downloader.youtube_download_path.exists():
                for ext in video_extensions:
                    youtube_files.extend(
                        self.downloader.youtube_download_path.glob(ext)
                    )
            bilibili_files = []
            if self.downloader.bilibili_download_path.exists():
                for ext in video_extensions:
                    bilibili_files.extend(
                        self.downloader.bilibili_download_path.glob(ext)
                    )
            douyin_files = []
            if self.downloader.douyin_download_path.exists():
                for ext in video_extensions:
                    douyin_files.extend(
                        self.downloader.douyin_download_path.glob(ext)
                    )
            total_files = len(x_files) + len(youtube_files) + len(bilibili_files) + len(douyin_files)
            status_text = (
                f"ğŸ“Š <b>ä¸‹è½½çŠ¶æ€</b>\n\n"
                f"  - <b>X (Twitter)</b>: {len(x_files)} ä¸ªæ–‡ä»¶\n"
                f"  - <b>YouTube</b>: {len(youtube_files)} ä¸ªæ–‡ä»¶\n"
                f"  - <b>Bilibili</b>: {len(bilibili_files)} ä¸ªæ–‡ä»¶\n"
                f"  - <b>æ€»è®¡</b>: {total_files} ä¸ªæ–‡ä»¶\n\n"
            )
            # qBittorrent çŠ¶æ€
            if self.qbit_client and self.qbit_client.is_logged_in:
                torrents = self.qbit_client.torrents_info(tag="savextube")
                active_torrents = [
                    t for t in torrents if t.state not in ["completed", "pausedUP"]
                ]
                status_text += f"<b>qBittorrent ä»»åŠ¡</b>: {len(torrents)} (æ´»åŠ¨: {len(active_torrents)})"
            else:
                status_text += "<b>qBittorrent</b>: æœªè¿æ¥"
            await update.message.reply_text(status_text, parse_mode="HTML")
        except Exception as e:
            await update.message.reply_text(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {str(e)}")

    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¤„ç†æ–‡æœ¬æ¶ˆæ¯ï¼Œä¸»è¦æ˜¯è§†é¢‘é“¾æ¥"""
        user_id = update.message.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await update.message.reply_text("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        # æ›´æ–°å¿ƒè·³
        update_heartbeat()

        message = update.message
        url = None
        
        # æ£€æŸ¥æ¶ˆæ¯ç±»å‹å¹¶æå–URL
        if message.text and message.text.startswith("http"):
            # æ™®é€šæ–‡æœ¬é“¾æ¥
            url = message.text
        elif message.text and (message.text.startswith("magnet:") or message.text.endswith(".torrent")):
            # ç£åŠ›é“¾æ¥æˆ–ç§å­æ–‡ä»¶ - æ–°å¢æ”¯æŒ
            url = message.text
        elif message.text and "magnet:" in message.text:
            # ä»æ··åˆæ–‡æœ¬ä¸­æå–ç£åŠ›é“¾æ¥
            import re
            magnet_match = re.search(r'magnet:\?xt=urn:btih:[a-fA-F0-9]{32,40}[^\s]*', message.text)
            if magnet_match:
                url = magnet_match.group(0)
                logger.info(f"ğŸ”§ ä»æ··åˆæ–‡æœ¬ä¸­æå–ç£åŠ›é“¾æ¥: {message.text} -> {url}")
        elif message.text and ".torrent" in message.text:
            # ä»æ··åˆæ–‡æœ¬ä¸­æå–ç§å­æ–‡ä»¶é“¾æ¥
            import re
            torrent_match = re.search(r'https?://[^\s]*\.torrent[^\s]*', message.text)
            if torrent_match:
                url = torrent_match.group(0)
                logger.info(f"ğŸ”§ ä»æ··åˆæ–‡æœ¬ä¸­æå–ç§å­æ–‡ä»¶é“¾æ¥: {message.text} -> {url}")
        elif message.entities:
            # æ£€æŸ¥æ˜¯å¦æœ‰é“¾æ¥å®ä½“
            for entity in message.entities:
                if entity.type == "url":
                    url = message.text[entity.offset:entity.offset + entity.length]
                    break
                elif entity.type == "text_link":
                    url = entity.url
                    break
        elif message.text and ("http" in message.text or "tp://" in message.text or "kuaishou.com" in message.text or "douyin.com" in message.text):
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–URLï¼ŒåŒ…æ‹¬ä¿®å¤é”™è¯¯çš„åè®®å’Œæ™ºèƒ½æå–
            import re

            # é¦–å…ˆä½¿ç”¨æ™ºèƒ½æå–æ–¹æ³•
            extracted_urls = self.downloader.extract_urls_from_text(message.text)
            if extracted_urls:
                url = extracted_urls[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„URL
                logger.info(f"ğŸ”§ æ™ºèƒ½æå–URL: {message.text} -> {url}")
            else:
                # å¤‡é€‰æ–¹æ¡ˆï¼šä¿®å¤é”™è¯¯çš„åè®®
                fixed_text = message.text.replace("tp://", "http://")
                url_match = re.search(r'https?://[^\s]+', fixed_text)
                if url_match:
                    url = url_match.group(0)
                    logger.info(f"ğŸ”§ ä¿®å¤äº†é”™è¯¯çš„URLåè®®: {message.text} -> {url}")
        
        # æ£€æŸ¥è½¬å‘æ¶ˆæ¯
        if not url and message.forward_from_chat:
            # å¤„ç†è½¬å‘çš„é¢‘é“/ç¾¤ç»„æ¶ˆæ¯
            if message.text and ("http" in message.text or "tp://" in message.text or "magnet:" in message.text):
                import re
                # é¦–å…ˆå°è¯•æå–ç£åŠ›é“¾æ¥
                magnet_match = re.search(r'magnet:\?xt=urn:btih:[a-fA-F0-9]{32,40}[^\s]*', message.text)
                if magnet_match:
                    url = magnet_match.group(0)
                    logger.info(f"ğŸ”§ è½¬å‘æ¶ˆæ¯ä¸­æå–ç£åŠ›é“¾æ¥: {message.text} -> {url}")
                else:
                    # å°è¯•æå–ç§å­æ–‡ä»¶é“¾æ¥
                    torrent_match = re.search(r'https?://[^\s]*\.torrent[^\s]*', message.text)
                    if torrent_match:
                        url = torrent_match.group(0)
                        logger.info(f"ğŸ”§ è½¬å‘æ¶ˆæ¯ä¸­æå–ç§å­æ–‡ä»¶é“¾æ¥: {message.text} -> {url}")
                    else:
                        # ä¿®å¤é”™è¯¯çš„åè®®
                        fixed_text = message.text.replace("tp://", "http://")
                        url_match = re.search(r'https?://[^\s]+', fixed_text)
                        if url_match:
                            url = url_match.group(0)
                            logger.info(f"ğŸ”§ è½¬å‘æ¶ˆæ¯ä¸­ä¿®å¤äº†é”™è¯¯çš„URLåè®®: {message.text} -> {url}")
        
        # æ£€æŸ¥å›å¤çš„æ¶ˆæ¯
        if not url and message.reply_to_message:
            reply_msg = message.reply_to_message
            if reply_msg.text and ("http" in reply_msg.text or "tp://" in reply_msg.text or "magnet:" in reply_msg.text):
                import re
                # é¦–å…ˆå°è¯•æå–ç£åŠ›é“¾æ¥
                magnet_match = re.search(r'magnet:\?xt=urn:btih:[a-fA-F0-9]{32,40}[^\s]*', reply_msg.text)
                if magnet_match:
                    url = magnet_match.group(0)
                    logger.info(f"ğŸ”§ å›å¤æ¶ˆæ¯ä¸­æå–ç£åŠ›é“¾æ¥: {reply_msg.text} -> {url}")
                else:
                    # å°è¯•æå–ç§å­æ–‡ä»¶é“¾æ¥
                    torrent_match = re.search(r'https?://[^\s]*\.torrent[^\s]*', reply_msg.text)
                    if torrent_match:
                        url = torrent_match.group(0)
                        logger.info(f"ğŸ”§ å›å¤æ¶ˆæ¯ä¸­æå–ç§å­æ–‡ä»¶é“¾æ¥: {reply_msg.text} -> {url}")
                    else:
                        # ä¿®å¤é”™è¯¯çš„åè®®
                        fixed_text = reply_msg.text.replace("tp://", "http://")
                        url_match = re.search(r'https?://[^\s]+', fixed_text)
                        if url_match:
                            url = url_match.group(0)
                            logger.info(f"ğŸ”§ å›å¤æ¶ˆæ¯ä¸­ä¿®å¤äº†é”™è¯¯çš„URLåè®®: {reply_msg.text} -> {url}")
            elif reply_msg.entities:
                for entity in reply_msg.entities:
                    if entity.type == "url":
                        url = reply_msg.text[entity.offset:entity.offset + entity.length]
                        break
                    elif entity.type == "text_link":
                        url = entity.url
                        break
        
        if not url:
            await message.reply_text("ğŸ¤” è¯·å‘é€ä¸€ä¸ªæœ‰æ•ˆçš„é“¾æ¥æˆ–åŒ…å«é“¾æ¥çš„æ¶ˆæ¯ã€‚\n\nğŸ’¡ æç¤ºï¼š\nâ€¢ ç›´æ¥å‘é€é“¾æ¥\nâ€¢ è½¬å‘åŒ…å«é“¾æ¥çš„æ¶ˆæ¯\nâ€¢ å›å¤åŒ…å«é“¾æ¥çš„æ¶ˆæ¯")
            return
            
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"æ”¶åˆ°æ¶ˆæ¯: {url}")

        # ç«‹å³å‘é€å¿«é€Ÿå“åº”
        status_message = await message.reply_text("ğŸš€ æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...")

        # å¼‚æ­¥å¤„ç†ä¸‹è½½ä»»åŠ¡ï¼Œä¸é˜»å¡å“åº”
        asyncio.create_task(
            self._process_download_async(update, context, url, status_message)
        )

    async def handle_qbittorrent_links(self, update: Update, context: ContextTypes.DEFAULT_TYPE, url: str, status_message):
        """ä¸“é—¨å¤„ç†qBittorrentç›¸å…³çš„é“¾æ¥ï¼ˆç£åŠ›é“¾æ¥å’Œç§å­æ–‡ä»¶ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç£åŠ›é“¾æ¥æˆ–ç§å­æ–‡ä»¶
            if self._is_magnet_link(url) or url.endswith(".torrent"):
                logger.info(f"ğŸ”— æ£€æµ‹åˆ°ç£åŠ›é“¾æ¥æˆ–ç§å­æ–‡ä»¶: {url[:50]}...")
                await status_message.edit_text("ğŸ”— æ­£åœ¨æ·»åŠ åˆ° qBittorrent...")
                
                # å°è¯•æ·»åŠ åˆ° qBittorrent
                success = await self.add_magnet_to_qb(url)
                
                if success:
                    await status_message.edit_text(
                        "âœ… **ç£åŠ›é“¾æ¥/ç§å­æ–‡ä»¶å·²æˆåŠŸæ·»åŠ åˆ° qBittorrentï¼**\n\n"
                        "ğŸ“ ä»»åŠ¡å·²æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—\n"
                        "ğŸ” æ‚¨å¯ä»¥åœ¨ qBittorrent ä¸­æŸ¥çœ‹ä¸‹è½½è¿›åº¦\n"
                        "ğŸ’¡ æç¤ºï¼šä¸‹è½½å®Œæˆåæ–‡ä»¶ä¼šä¿å­˜åˆ°é…ç½®çš„ä¸‹è½½ç›®å½•"
                    )
                else:
                    await status_message.edit_text(
                        "âŒ **æ·»åŠ ç£åŠ›é“¾æ¥/ç§å­æ–‡ä»¶å¤±è´¥**\n\n"
                        "å¯èƒ½çš„åŸå› ï¼š\n"
                        "â€¢ qBittorrent æœªè¿æ¥æˆ–æœªé…ç½®\n"
                        "â€¢ é“¾æ¥æ ¼å¼æ— æ•ˆ\n"
                        "â€¢ qBittorrent æœåŠ¡å¼‚å¸¸\n\n"
                        "è¯·æ£€æŸ¥ qBittorrent é…ç½®å’Œè¿æ¥çŠ¶æ€"
                    )
                return True  # è¡¨ç¤ºå·²å¤„ç†
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºåª’ä½“æ¶ˆæ¯ï¼Œä»åª’ä½“æ¶ˆæ¯æ–‡æœ¬ä¸­æå–ç£åŠ›é“¾æ¥
            message = update.message
            if message.photo or message.video or message.document or message.audio:
                if message.caption:
                    caption_text = message.caption
                    logger.info(f"ğŸ” æ£€æµ‹åˆ°åª’ä½“æ¶ˆæ¯ï¼Œæ–‡æœ¬å†…å®¹: {caption_text}")
                    
                    # ä»åª’ä½“æ¶ˆæ¯æ–‡æœ¬ä¸­æå–ç£åŠ›é“¾æ¥
                    import re
                    magnet_match = re.search(r'magnet:\?xt=urn:btih:[a-fA-F0-9]{32,40}[^\s]*', caption_text)
                    if magnet_match:
                        magnet_url = magnet_match.group(0)
                        logger.info(f"ğŸ”§ ä»åª’ä½“æ¶ˆæ¯æ–‡æœ¬ä¸­æå–ç£åŠ›é“¾æ¥: {caption_text} -> {magnet_url}")
                        await status_message.edit_text("ğŸ”— æ­£åœ¨æ·»åŠ åˆ° qBittorrent...")
                        
                        # å°è¯•æ·»åŠ åˆ° qBittorrent
                        success = await self.add_magnet_to_qb(magnet_url)
                        
                        if success:
                            await status_message.edit_text(
                                "âœ… **ç£åŠ›é“¾æ¥å·²æˆåŠŸæ·»åŠ åˆ° qBittorrentï¼**\n\n"
                                "ğŸ“ ä»»åŠ¡å·²æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—\n"
                                "ğŸ” æ‚¨å¯ä»¥åœ¨ qBittorrent ä¸­æŸ¥çœ‹ä¸‹è½½è¿›åº¦\n"
                                "ğŸ’¡ æç¤ºï¼šä¸‹è½½å®Œæˆåæ–‡ä»¶ä¼šä¿å­˜åˆ°é…ç½®çš„ä¸‹è½½ç›®å½•"
                            )
                        else:
                            await status_message.edit_text(
                                "âŒ **æ·»åŠ ç£åŠ›é“¾æ¥å¤±è´¥**\n\n"
                                "å¯èƒ½çš„åŸå› ï¼š\n"
                                "â€¢ qBittorrent æœªè¿æ¥æˆ–æœªé…ç½®\n"
                                "â€¢ é“¾æ¥æ ¼å¼æ— æ•ˆ\n"
                                "â€¢ qBittorrent æœåŠ¡å¼‚å¸¸\n\n"
                                "è¯·æ£€æŸ¥ qBittorrent é…ç½®å’Œè¿æ¥çŠ¶æ€"
                            )
                        return True  # è¡¨ç¤ºå·²å¤„ç†
                    
                    # å°è¯•æå–ç§å­æ–‡ä»¶é“¾æ¥
                    torrent_match = re.search(r'https?://[^\s]*\.torrent[^\s]*', caption_text)
                    if torrent_match:
                        torrent_url = torrent_match.group(0)
                        logger.info(f"ğŸ”§ ä»åª’ä½“æ¶ˆæ¯æ–‡æœ¬ä¸­æå–ç§å­æ–‡ä»¶é“¾æ¥: {caption_text} -> {torrent_url}")
                        await status_message.edit_text("ğŸ”— æ­£åœ¨æ·»åŠ åˆ° qBittorrent...")
                        
                        # å°è¯•æ·»åŠ åˆ° qBittorrent
                        success = await self.add_magnet_to_qb(torrent_url)
                        
                        if success:
                            await status_message.edit_text(
                                "âœ… **ç§å­æ–‡ä»¶å·²æˆåŠŸæ·»åŠ åˆ° qBittorrentï¼**\n\n"
                                "ğŸ“ ä»»åŠ¡å·²æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—\n"
                                "ğŸ” æ‚¨å¯ä»¥åœ¨ qBittorrent ä¸­æŸ¥çœ‹ä¸‹è½½è¿›åº¦\n"
                                "ğŸ’¡ æç¤ºï¼šä¸‹è½½å®Œæˆåæ–‡ä»¶ä¼šä¿å­˜åˆ°é…ç½®çš„ä¸‹è½½ç›®å½•"
                            )
                        else:
                            await status_message.edit_text(
                                "âŒ **æ·»åŠ ç§å­æ–‡ä»¶å¤±è´¥**\n\n"
                                "å¯èƒ½çš„åŸå› ï¼š\n"
                                "â€¢ qBittorrent æœªè¿æ¥æˆ–æœªé…ç½®\n"
                                "â€¢ é“¾æ¥æ ¼å¼æ— æ•ˆ\n"
                                "â€¢ qBittorrent æœåŠ¡å¼‚å¸¸\n\n"
                                "è¯·æ£€æŸ¥ qBittorrent é…ç½®å’Œè¿æ¥çŠ¶æ€"
                            )
                        return True  # è¡¨ç¤ºå·²å¤„ç†
            
            return False  # è¡¨ç¤ºæœªå¤„ç†ï¼Œç»§ç»­å…¶ä»–æµç¨‹
        except Exception as e:
            logger.error(f"å¤„ç†qBittorrenté“¾æ¥æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            await status_message.edit_text(f"âŒ å¤„ç†qBittorrenté“¾æ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return True  # è¡¨ç¤ºå·²å¤„ç†ï¼ˆå‡ºé”™ä¹Ÿç®—å¤„ç†äº†ï¼‰

    async def _process_download_async(
        self,
        update: Update,
        context: ContextTypes.DEFAULT_TYPE,
        url: str,
        status_message,
    ):
        """å¼‚æ­¥å¤„ç†ä¸‹è½½ä»»åŠ¡"""
        # åœ¨æ–¹æ³•å¼€å§‹æ—¶å®šä¹‰chat_idï¼Œç¡®ä¿åœ¨æ‰€æœ‰å¼‚å¸¸å¤„ç†è·¯å¾„ä¸­éƒ½å¯è®¿é—®
        chat_id = status_message.chat_id
        
        try:
            # é¦–å…ˆå°è¯•å¤„ç†qBittorrentç›¸å…³é“¾æ¥
            if await self.handle_qbittorrent_links(update, context, url, status_message):
                return  # å¦‚æœæ˜¯qBç›¸å…³é“¾æ¥ï¼Œå¤„ç†å®Œå°±è¿”å›
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºBç«™è‡ªå®šä¹‰åˆ—è¡¨URL
            is_list, uid, list_id = self.downloader.is_bilibili_list_url(url)
            if is_list:
                logger.info(f"ğŸ”§ æ£€æµ‹åˆ°Bç«™ç”¨æˆ·åˆ—è¡¨URL: ç”¨æˆ·{uid}, åˆ—è¡¨{list_id}")
            # é“¾æ¥æœ‰æ•ˆæ€§æ£€æŸ¥
            platform_name = self.downloader.get_platform_name(url)
            if platform_name == "æœªçŸ¥":
                await status_message.edit_text("ğŸ™ æŠ±æ­‰ï¼Œæš‚ä¸æ”¯æŒæ‚¨å‘é€çš„ç½‘ç«™ã€‚")
                return
            
            # è·å–å¹³å°ä¿¡æ¯ç”¨äºåç»­åˆ¤æ–­
            platform = platform_name.lower()
        except Exception as e:
            logger.error(f"å¤„ç†ä¸‹è½½æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", exc_info=True)
            await context.bot.edit_message_text(
                text=f"âŒ å¤„ç†ä¸‹è½½æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼š\n`{self._escape_markdown(str(e))}`",
                chat_id=chat_id,
                message_id=status_message.message_id,
                parse_mode="MarkdownV2",
            )
            return

        # ç¼“å­˜ä¸Šæ¬¡å‘é€çš„å†…å®¹ï¼Œé¿å…é‡å¤å‘é€
        last_progress_text = {"text": None}
        
        # --- è¿›åº¦å›è°ƒ ---
        last_update_time = {"time": time.time()}
        last_progress_percent = {"value": 0}
        progress_state = {"last_stage": None, "last_percent": 0, "finished_shown": False}  # è·Ÿè¸ªä¸Šä¸€æ¬¡çš„çŠ¶æ€å’Œæ˜¯å¦å·²æ˜¾ç¤ºå®Œæˆ
        last_progress_text = {"text": ""}  # è·Ÿè¸ªä¸Šä¸€æ¬¡çš„æ–‡æœ¬å†…å®¹
        
        # åˆ›å»ºå¢å¼ºç‰ˆçš„æ¶ˆæ¯æ›´æ–°å™¨å‡½æ•°ï¼Œæ”¯æŒä¼ é€’ status_message å’Œ context ç»™ single_video_progress_hook
        # å¢åŠ å¯¹Bç«™å¤šPä¸‹è½½çš„æ”¯æŒï¼Œä½†ä¿æŒYouTubeåŠŸèƒ½å®Œå…¨ä¸å˜
        async def message_updater(text_or_dict, bilibili_progress_data=None):
            try:
                logger.info(f"ğŸ” message_updater è¢«è°ƒç”¨ï¼Œå‚æ•°ç±»å‹: {type(text_or_dict)}")
                logger.info(f"ğŸ” message_updater å‚æ•°å†…å®¹: {text_or_dict}")
                
                # å¦‚æœå·²ç»æ˜¾ç¤ºå®ŒæˆçŠ¶æ€ï¼Œå¿½ç•¥æ‰€æœ‰åç»­è°ƒç”¨
                if progress_state["finished_shown"]:
                    logger.info("ä¸‹è½½å·²å®Œæˆï¼Œå¿½ç•¥message_updateråç»­è°ƒç”¨")
                    return
                
                # å¤„ç†å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…é‡å¤å‘é€ç›¸åŒå†…å®¹
                if isinstance(text_or_dict, str):
                    if text_or_dict == last_progress_text["text"]:
                        logger.info("ğŸ” è·³è¿‡é‡å¤å†…å®¹")
                        return  # è·³è¿‡é‡å¤å†…å®¹
                    last_progress_text["text"] = text_or_dict
                    await status_message.edit_text(text_or_dict)
                    return
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå­—å…¸ç±»å‹ï¼ˆæ¥è‡ªprogress_hookçš„è¿›åº¦æ•°æ®ï¼‰
                if isinstance(text_or_dict, dict):
                    logger.info(f"ğŸ” æ£€æµ‹åˆ°å­—å…¸ç±»å‹ï¼ŒçŠ¶æ€: {text_or_dict.get('status')}")
                    
                    # è®°å½•æ–‡ä»¶åï¼ˆç”¨äºæ–‡ä»¶æŸ¥æ‰¾ï¼‰
                    if text_or_dict.get("status") == "finished":
                        filename = text_or_dict.get('filename', '')
                        if filename:
                            # å¦‚æœæä¾›äº†bilibili_progress_dataï¼Œè®°å½•Bç«™ä¸‹è½½çš„æ–‡ä»¶
                            if bilibili_progress_data is not None:
                                if 'downloaded_files' not in bilibili_progress_data:
                                    bilibili_progress_data['downloaded_files'] = []
                                bilibili_progress_data['downloaded_files'].append(filename)
                                logger.info(f"ğŸ“ Bç«™æ–‡ä»¶è®°å½•: {filename}")
                            else:
                                # YouTubeæˆ–å…¶ä»–å¹³å°çš„å¤„ç†ä¿æŒä¸å˜
                                logger.info(f"ğŸ“ æ£€æµ‹åˆ°finishedçŠ¶æ€ï¼Œæ–‡ä»¶å: {filename}")
                    
                    if text_or_dict.get("status") == "finished":
                        # å¯¹äºfinishedçŠ¶æ€ï¼Œä¸è°ƒç”¨update_progressï¼Œé¿å…æ˜¾ç¤ºé”™è¯¯çš„è¿›åº¦ä¿¡æ¯
                        logger.info("ğŸ” æ£€æµ‹åˆ°finishedçŠ¶æ€ï¼Œè·³è¿‡update_progressè°ƒç”¨")
                        return
                    elif text_or_dict.get("status") == "downloading":
                        # è¿™æ˜¯æ¥è‡ªprogress_hookçš„ä¸‹è½½è¿›åº¦æ•°æ®
                        logger.info("ğŸ” æ£€æµ‹åˆ°ä¸‹è½½è¿›åº¦æ•°æ®ï¼Œå‡†å¤‡è°ƒç”¨ update_progress...")
                        # ç›´æ¥è°ƒç”¨update_progresså‡½æ•°å¤„ç†
                        update_progress(text_or_dict)
                        logger.info("âœ… update_progress è°ƒç”¨å®Œæˆ")
                    else:
                        # å…¶ä»–å­—å…¸çŠ¶æ€ï¼Œè½¬æ¢ä¸ºæ–‡æœ¬
                        logger.info(f"ğŸ” å…¶ä»–å­—å…¸çŠ¶æ€: {text_or_dict}")
                        dict_text = str(text_or_dict)
                        if dict_text == last_progress_text["text"]:
                            logger.info("ğŸ” è·³è¿‡é‡å¤å­—å…¸å†…å®¹")
                            return  # è·³è¿‡é‡å¤å†…å®¹
                        last_progress_text["text"] = dict_text
                        await status_message.edit_text(dict_text)
                else:
                    # æ™®é€šæ–‡æœ¬æ¶ˆæ¯
                    logger.info(f"ğŸ” æ™®é€šæ–‡æœ¬æ¶ˆæ¯: {text_or_dict}")
                    text_str = str(text_or_dict)
                    if text_str == last_progress_text["text"]:
                        logger.info("ğŸ” è·³è¿‡é‡å¤æ–‡æœ¬å†…å®¹")
                        return  # è·³è¿‡é‡å¤å†…å®¹
                    last_progress_text["text"] = text_str
                    await status_message.edit_text(text_str)
            except Exception as e:
                logger.error(f"âŒ message_updater å¤„ç†é”™è¯¯: {e}")
                logger.error(f"âŒ å¼‚å¸¸ç±»å‹: {type(e)}")
                import traceback
                logger.error(f"âŒ å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                if "Message is not modified" not in str(e):
                    logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
        
        # åˆ›å»ºå¢å¼ºç‰ˆçš„è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ”¯æŒä¼ é€’ status_message å’Œ context
        def enhanced_progress_callback(progress_data_dict):
            """å¢å¼ºç‰ˆè¿›åº¦å›è°ƒï¼Œæ”¯æŒä¼ é€’ status_message å’Œ context ç»™ single_video_progress_hook"""
            # åˆ›å»º single_video_progress_hook çš„å¢å¼ºç‰ˆæœ¬
            progress_hook = single_video_progress_hook(
                message_updater=None,  # ä¸ä½¿ç”¨ç®€å•çš„ message_updater
                progress_data=progress_data_dict,
                status_message=status_message,
                context=context
            )
            return progress_hook

        # æ›´æ–°çŠ¶æ€æ¶ˆæ¯
        try:
            if message_updater:
                logger.debug(f'message_updater type: {type(message_updater)}, value: {message_updater}')
                if asyncio.iscoroutinefunction(message_updater):
                    await message_updater("ğŸ” æ­£åœ¨åˆ†æé“¾æ¥...")
                else:
                    message_updater("ğŸ” æ­£åœ¨åˆ†æé“¾æ¥...")
        except Exception as e:
            logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
        # ç›´æ¥å¼€å§‹ä¸‹è½½ï¼Œè·³è¿‡é¢„å…ˆè·å–ä¿¡æ¯ï¼ˆé¿å…ç”¨æˆ·ç­‰å¾…ï¼‰
        try:
            if message_updater:
                logger.debug(f'message_updater type: {type(message_updater)}, value: {message_updater}')
                if asyncio.iscoroutinefunction(message_updater):
                    await message_updater("ğŸš€ æ­£åœ¨å¯åŠ¨ä¸‹è½½...")
                else:
                    message_updater("ğŸš€ æ­£åœ¨å¯åŠ¨ä¸‹è½½...")
        except Exception as e:
            logger.warning(f"æ›´æ–°çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")
        # è·å–å½“å‰äº‹ä»¶å¾ªç¯
        loop = asyncio.get_running_loop()
        
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = f"{update.effective_user.id}_{int(time.time())}"
        
        # æ·»åŠ  progress_data æ”¯æŒï¼ˆå‚è€ƒ main.v0.3.pyï¼‰
        progress_data = {
            'filename': '',
            'total_bytes': 0,
            'downloaded_bytes': 0,
            'speed': 0,
            'status': 'downloading',
            'final_filename': '',
            'last_update': 0,
            'progress': 0.0
        }

        # --- ä½¿ç”¨å…¨å±€è¿›åº¦ç®¡ç†å™¨ ---
        await global_progress_manager.update_progress(task_id, {}, context, status_message)
        def update_progress(d):
            import os
            logger.debug(f"update_progress è¢«è°ƒç”¨: {type(d)}, å†…å®¹: {d}")
            # æ”¯æŒå­—ç¬¦ä¸²ç±»å‹ï¼Œç›´æ¥å‘åˆ°Telegram
            if isinstance(d, str):
                try:
                    asyncio.run_coroutine_threadsafe(
                        status_message.edit_text(d, parse_mode="MarkdownV2"),
                        loop
                    )
                except Exception as e:
                    logger.warning(f"å‘é€å­—ç¬¦ä¸²è¿›åº¦åˆ°TGå¤±è´¥: {e}")
                return
            # æ·»åŠ ç±»å‹æ£€æŸ¥ï¼Œç¡®ä¿dæ˜¯å­—å…¸ç±»å‹
            if not isinstance(d, dict):
                logger.warning(f"update_progressæ¥æ”¶åˆ°éå­—å…¸ç±»å‹å‚æ•°: {type(d)}, å†…å®¹: {d}")
                return
            
            # æ›´æ–° progress_dataï¼ˆå‚è€ƒ main.v0.3.pyï¼‰
            try:
                if d['status'] == 'downloading':
                    raw_filename = d.get('filename', '')
                    display_filename = os.path.basename(raw_filename) if raw_filename else 'video.mp4'
                    progress_data.update({
                        'filename': display_filename,
                        'total_bytes': d.get('total_bytes') or d.get('total_bytes_estimate', 0),
                        'downloaded_bytes': d.get('downloaded_bytes', 0),
                        'speed': d.get('speed', 0),
                        'status': 'downloading',
                        'progress': (d.get('downloaded_bytes', 0) / (d.get('total_bytes') or d.get('total_bytes_estimate', 1))) * 100 if (d.get('total_bytes') or d.get('total_bytes_estimate', 0)) > 0 else 0.0
                    })
                elif d['status'] == 'finished':
                    final_filename = d.get('filename', '')
                    display_filename = os.path.basename(final_filename) if final_filename else 'video.mp4'
                    progress_data.update({
                        'filename': display_filename,
                        'status': 'finished',
                        'final_filename': final_filename,
                        'progress': 100.0
                    })
            except Exception as e:
                logger.error(f"æ›´æ–° progress_data é”™è¯¯: {str(e)}")
                
            now = time.time()
            # ä½¿ç”¨ main.v0.3.py çš„æ–¹å¼ï¼šæ¯1ç§’æ›´æ–°ä¸€æ¬¡
            if now - last_update_time['time'] < 1.0:
                return
            # å¤„ç†Bç«™åˆé›†ä¸‹è½½è¿›åº¦
            if d.get('status') == 'downloading' and d.get('bv'):
                # Bç«™åˆé›†ä¸‹è½½è¿›åº¦
                last_update_time['time'] = now
                bv = d.get('bv', '')
                filename = d.get('filename', '')
                template = d.get('template', '')
                index = d.get('index', 0)
                total = d.get('total', 0)
                
                progress_text = (
                    f"ğŸš€ **æ­£åœ¨ä¸‹è½½ç¬¬{index}ä¸ª**: `{bv}` - `{filename}`\n"
                    f"ğŸ“ **æ–‡ä»¶åæ¨¡æ¿**: `{template}`\n"
                    f"ğŸ“Š **è¿›åº¦**: {index}/{total}"
                )
                
                async def do_update():
                    try:
                        await asyncio.wait_for(
                            context.bot.edit_message_text(
                                text=progress_text,
                                chat_id=status_message.chat_id,
                                message_id=status_message.message_id,
                                parse_mode=ParseMode.MARKDOWN_V2
                            ),
                            timeout=10.0  # å¢åŠ åˆ°10ç§’è¶…æ—¶ï¼Œå‡å°‘è¶…æ—¶é”™è¯¯
                        )
                        logger.info(f"Bç«™åˆé›†è¿›åº¦æ›´æ–°: ç¬¬{index}/{total}ä¸ª")
                    except asyncio.TimeoutError:
                        logger.warning(f"Bç«™åˆé›†è¿›åº¦æ›´æ–°è¶…æ—¶: ç¬¬{index}/{total}ä¸ª")
                    except Exception as e:
                        if "Message is not modified" not in str(e):
                            logger.warning(f"æ›´æ–°Bç«™åˆé›†è¿›åº¦å¤±è´¥: {e}")
                
                asyncio.run_coroutine_threadsafe(do_update(), loop)
                return
            
            # å¤„ç†Bç«™åˆé›†ä¸‹è½½å®Œæˆ/å¤±è´¥
            if d.get('status') in ['finished', 'error'] and d.get('bv'):
                # Bç«™åˆé›†ä¸‹è½½å®Œæˆ/å¤±è´¥
                last_update_time['time'] = now
                bv = d.get('bv', '')
                filename = d.get('filename', '')
                index = d.get('index', 0)
                total = d.get('total', 0)
                status_emoji = "âœ…" if d.get('status') == 'finished' else "âŒ"
                status_text = "ä¸‹è½½æˆåŠŸ" if d.get('status') == 'finished' else "ä¸‹è½½å¤±è´¥"
                
                progress_text = (
                    f"{status_emoji} **ç¬¬{index}ä¸ª{status_text}**: `{filename}`\n"
                    f"ğŸ“Š **è¿›åº¦**: {index}/{total}"
                )
                
                async def do_update():
                    try:
                        await asyncio.wait_for(
                            context.bot.edit_message_text(
                                text=progress_text,
                                chat_id=status_message.chat_id,
                                message_id=status_message.message_id,
                                parse_mode=ParseMode.MARKDOWN_V2
                            ),
                            timeout=10.0  # å¢åŠ åˆ°10ç§’è¶…æ—¶ï¼Œå‡å°‘è¶…æ—¶é”™è¯¯
                        )
                        logger.info(f"Bç«™åˆé›†çŠ¶æ€æ›´æ–°: ç¬¬{index}ä¸ª{status_text}")
                    except asyncio.TimeoutError:
                        logger.warning(f"Bç«™åˆé›†çŠ¶æ€æ›´æ–°è¶…æ—¶: ç¬¬{index}ä¸ª{status_text}")
                    except Exception as e:
                        if "Message is not modified" not in str(e):
                            logger.warning(f"æ›´æ–°Bç«™åˆé›†çŠ¶æ€å¤±è´¥: {e}")
                
                asyncio.run_coroutine_threadsafe(do_update(), loop)
                return

            # å¤„ç†ä¸‹è½½å®ŒæˆçŠ¶æ€ - ç›´æ¥æ˜¾ç¤ºå®Œæˆä¿¡æ¯å¹¶è¿”å›ï¼ˆå‚è€ƒ main.v0.3.pyï¼‰
            elif d.get('status') == 'finished':
                logger.info("yt-dlpä¸‹è½½å®Œæˆï¼Œæ˜¾ç¤ºå®Œæˆä¿¡æ¯")

                # è·å–è¿›åº¦ä¿¡æ¯
                filename = progress_data.get('filename', 'video.mp4')
                total_bytes = progress_data.get('total_bytes', 0)
                downloaded_bytes = progress_data.get('downloaded_bytes', 0)

                # ç›‘æ§æ–‡ä»¶åˆå¹¶çŠ¶æ€
                actual_filename = d.get('filename', filename)
                if actual_filename.endswith('.part'):
                    logger.warning(f"âš ï¸ æ–‡ä»¶åˆå¹¶å¯èƒ½å¤±è´¥: {actual_filename}")
                else:
                    logger.info(f"âœ… æ–‡ä»¶ä¸‹è½½å¹¶åˆå¹¶æˆåŠŸ: {actual_filename}")
                
                # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
                display_filename = self._clean_filename_for_display(filename)
                progress_bar = self._create_progress_bar(100.0)
                size_mb = total_bytes / (1024 * 1024) if total_bytes > 0 else downloaded_bytes / (1024 * 1024)
                
                completion_text = (
                    f"ğŸ“ æ–‡ä»¶ï¼š{display_filename}\n"
                    f"ğŸ’¾ å¤§å°ï¼š{size_mb:.2f}MB\n"
                    f"âš¡ é€Ÿåº¦ï¼šå®Œæˆ\n"
                    f"â³ é¢„è®¡å‰©ä½™ï¼š0ç§’\n"
                    f"ğŸ“Š è¿›åº¦ï¼š{progress_bar} (100.0%)"
                )
                
                async def do_update():
                    try:
                        await status_message.edit_text(completion_text)
                        logger.info("æ˜¾ç¤ºä¸‹è½½å®Œæˆè¿›åº¦ä¿¡æ¯")
                    except Exception as e:
                        logger.warning(f"æ˜¾ç¤ºå®Œæˆè¿›åº¦ä¿¡æ¯å¤±è´¥: {e}")
                
                asyncio.run_coroutine_threadsafe(do_update(), loop)
                return
                
            if d.get('status') == 'downloading':
                logger.debug(f"æ”¶åˆ°ä¸‹è½½è¿›åº¦å›è°ƒ: {d}")
                last_update_time['time'] = now
                
                total_bytes = d.get('total_bytes') or d.get('total_bytes_estimate', 0)
                downloaded_bytes = d.get('downloaded_bytes', 0)
                speed_bytes_s = d.get('speed', 0)
                eta_seconds = d.get('eta', 0)
                filename = d.get('filename', '') or "æ­£åœ¨ä¸‹è½½..."
                
                # ä½¿ç”¨ main.v0.3.py çš„ç®€å•é€»è¾‘
                if total_bytes > 0:
                    progress = (downloaded_bytes / total_bytes) * 100
                    progress_bar = self._create_progress_bar(progress)
                    size_mb = total_bytes / (1024 * 1024)
                    speed_mb = (speed_bytes_s or 0) / (1024 * 1024)
                    
                    # è®¡ç®—é¢„è®¡å‰©ä½™æ—¶é—´
                    eta_text = ""
                    if speed_bytes_s and total_bytes and downloaded_bytes < total_bytes:
                        remaining = total_bytes - downloaded_bytes
                        eta = int(remaining / speed_bytes_s)
                        mins, secs = divmod(eta, 60)
                        if mins > 0:
                            eta_text = f"{mins}åˆ†{secs}ç§’"
                        else:
                            eta_text = f"{secs}ç§’"
                    elif speed_bytes_s:
                        eta_text = "è®¡ç®—ä¸­"
                    else:
                        eta_text = "æœªçŸ¥"
                    
                    # ç¡®ä¿æ–‡ä»¶åä¸åŒ…å«è·¯å¾„
                    display_filename = os.path.basename(filename) if filename else 'video.mp4'
                    display_filename = self._clean_filename_for_display(display_filename)
                    downloaded_mb = downloaded_bytes / (1024 * 1024)
                    progress_text = (
                        f"ğŸ“¥ ä¸‹è½½ä¸­\n"
                        f"ğŸ“ æ–‡ä»¶åï¼š{display_filename}\n"
                        f"ğŸ’¾ å¤§å°ï¼š{downloaded_mb:.2f}MB / {size_mb:.2f}MB\n"
                        f"âš¡ é€Ÿåº¦ï¼š{speed_mb:.2f}MB/s\n"
                        f"â³ é¢„è®¡å‰©ä½™ï¼š{eta_text}\n"
                        f"ğŸ“Š è¿›åº¦ï¼š{progress_bar} {progress:.1f}%"
                    )
                    
                    async def do_update():
                        try:
                            await status_message.edit_text(progress_text)
                        except Exception as e:
                            if "Message is not modified" not in str(e):
                                logger.warning(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
                    
                    asyncio.run_coroutine_threadsafe(do_update(), loop)
                else:
                    # æ²¡æœ‰æ€»å¤§å°ä¿¡æ¯æ—¶çš„å¤„ç†
                    downloaded_mb = downloaded_bytes / (1024 * 1024) if downloaded_bytes > 0 else 0
                    speed_mb = (speed_bytes_s or 0) / (1024 * 1024)
                    # ç¡®ä¿æ–‡ä»¶åä¸åŒ…å«è·¯å¾„
                    display_filename = os.path.basename(filename) if filename else 'video.mp4'
                    display_filename = self._clean_filename_for_display(display_filename)
                    progress_text = (
                        f"ğŸ“¥ ä¸‹è½½ä¸­\n"
                        f"ğŸ“ æ–‡ä»¶åï¼š{display_filename}\n"
                        f"ğŸ’¾ å¤§å°ï¼š{downloaded_mb:.2f}MB\n"
                        f"âš¡ é€Ÿåº¦ï¼š{speed_mb:.2f}MB/s\n"
                        f"â³ é¢„è®¡å‰©ä½™ï¼šæœªçŸ¥\n"
                        f"ğŸ“Š è¿›åº¦ï¼šä¸‹è½½ä¸­..."
                    )
                    
                    async def do_update():
                        try:
                            await status_message.edit_text(progress_text)
                        except Exception as e:
                            if "Message is not modified" not in str(e):
                                logger.warning(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
                    
                    asyncio.run_coroutine_threadsafe(do_update(), loop)

        # --- æ‰§è¡Œä¸‹è½½ ---
        # åˆ›å»ºä¸‹è½½ä»»åŠ¡ï¼Œä½¿ç”¨å¢å¼ºç‰ˆçš„è¿›åº¦å›è°ƒ
        download_task = asyncio.create_task(
            self.downloader.download_video(
                url, update_progress, self.bilibili_auto_playlist
            )
        )

        # æ·»åŠ åˆ°ä»»åŠ¡ç®¡ç†å™¨
        await self.add_download_task(task_id, download_task)

        try:
            # ç­‰å¾…ä¸‹è½½å®Œæˆ
            result = await download_task
        except asyncio.CancelledError:
            logger.info(f"ğŸš« ä¸‹è½½ä»»åŠ¡è¢«å–æ¶ˆ: {task_id}")
            await status_message.edit_text("ğŸš« ä¸‹è½½ä»»åŠ¡å·²å–æ¶ˆ")
            return
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
            await status_message.edit_text(f"âŒ ä¸‹è½½å¤±è´¥: `{self._escape_markdown(str(e))}`")
            return
        finally:
            # ä»ä»»åŠ¡ç®¡ç†å™¨ä¸­ç§»é™¤ä»»åŠ¡
            await self.remove_download_task(task_id)
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¸‹è½½å®Œæˆåç«‹å³é”æ­»è¿›åº¦å›è°ƒï¼Œé˜²æ­¢åç»­å›è°ƒè¦†ç›–å®Œæˆä¿¡æ¯
            progress_state["finished_shown"] = True
            logger.info("ğŸ”’ ä¸‹è½½ä»»åŠ¡å®Œæˆï¼Œé”æ­»è¿›åº¦å›è°ƒ")
        
        # æ£€æŸ¥resultæ˜¯å¦ä¸ºNone
        if not result:
            logger.error("âŒ ä¸‹è½½ä»»åŠ¡è¿”å›Noneç»“æœ")
            await status_message.edit_text("âŒ ä¸‹è½½å¤±è´¥: æœªçŸ¥é”™è¯¯")
            return
            
        # å…¼å®¹ä¸åŒçš„è¿”å›æ ¼å¼ï¼šæœ‰äº›è¿”å›"success"ï¼Œæœ‰äº›è¿”å›"status"
        if result.get("success") or result.get("status") == "success":
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logger.info(f"ä¸‹è½½å®Œæˆï¼Œç»“æœ: {result}")
            logger.info(f"is_playlist: {result.get('is_playlist')}")
            logger.info(f"platform: {result.get('platform')}")
            logger.info(f"video_type: {result.get('video_type')}")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºBç«™åˆé›†ä¸‹è½½
            platform_value = result.get("platform", "")
            logger.info(f"Platformå€¼: '{platform_value}'")
            logger.info(f"æ˜¯å¦åŒ…å«Bilibili: {'Bilibili' in platform_value}")
            
            if (result.get("is_playlist") and "bilibili" in platform_value.lower()) or (result.get("video_type") == "playlist" and "bilibili" in platform_value.lower()):
                # Bç«™è‡ªå®šä¹‰åˆ—è¡¨ä¸‹è½½å®Œæˆï¼Œç›´æ¥ä½¿ç”¨è¿”å›çš„ç»“æœï¼Œä¸è¿›è¡Œç›®å½•éå†
                # å‚è€ƒ main.mp.py çš„é€»è¾‘
                file_count = result.get("file_count", 0)
                total_size_mb = result.get("total_size_mb", 0)
                filename_display = result.get("filename", "")
                resolution_display = result.get("resolution", "æœªçŸ¥")
                episode_count = result.get("episode_count", 0)
                download_path = result.get("download_path", "")

                title = "ğŸ¬ **è§†é¢‘ä¸‹è½½å®Œæˆ**"
                escaped_title = self._escape_markdown(title)

                # åŠ¨æ€å¤„ç†æ–‡ä»¶åæ˜¾ç¤ºï¼Œæœ€å¤§åŒ–åˆ©ç”¨TGæ¶ˆæ¯ç©ºé—´
                filename_display = self.downloader._optimize_filename_display_for_telegram(
                    filename_display, file_count, total_size_mb, resolution_display, download_path
                )

                # è½¬ä¹‰å„ä¸ªå­—æ®µ
                escaped_filename = self._escape_markdown(filename_display)
                escaped_resolution = self._escape_markdown(resolution_display)
                escaped_download_path = self._escape_markdown(download_path)
                
                # ä¸º MarkdownV2 è½¬ä¹‰æ•°å­—ä¸­çš„å°æ•°ç‚¹
                total_size_str = f"{total_size_mb:.2f}".replace('.', r'\.')
                episode_count_str = str(episode_count)

                # è·å–PARTæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
                success_count = result.get("success_count", episode_count)
                part_count = result.get("part_count", 0)

                # æ„å»ºç»Ÿè®¡ä¿¡æ¯
                stats_text = f"âœ… **æˆåŠŸ**: `{success_count} ä¸ª`"
                if part_count > 0:
                    stats_text += f"\nâš ï¸ **æœªå®Œæˆ**: `{part_count} ä¸ª`"
                    stats_text += f"\nğŸ’¡ **æç¤º**: å‘ç°æœªå®Œæˆæ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦é‡æ–°ä¸‹è½½"

                success_text = (
                    f"{escaped_title}\n\n"
                    f"ğŸ“ **æ–‡ä»¶å**:\n{escaped_filename}\n\n"
                    f"ğŸ’¾ **æ–‡ä»¶å¤§å°**: `{total_size_str} MB`\n"
                    f"ğŸ“Š **ä¸‹è½½ç»Ÿè®¡**:\n{stats_text}\n"
                    f"ğŸ–¼ï¸ **åˆ†è¾¨ç‡**: `{escaped_resolution}`\n"
                    f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{escaped_download_path}`"
                )

                try:
                    await status_message.edit_text(
                        text=success_text, parse_mode="MarkdownV2"
                    )
                except Exception as e:
                    if "Flood control" in str(e):
                        logger.warning(
                            "Bç«™åˆé›†ä¸‹è½½å®Œæˆæ¶ˆæ¯é‡åˆ°Flood controlï¼Œç­‰å¾…5ç§’åé‡è¯•..."
                        )
                        await asyncio.sleep(5)
                        try:
                            await status_message.edit_text(
                                text=success_text, parse_mode="MarkdownV2"
                            )
                        except Exception as retry_error:
                            logger.error(
                                f"é‡è¯•å‘é€Bç«™åˆé›†å®Œæˆæ¶ˆæ¯å¤±è´¥: {retry_error}"
                            )
                    else:
                        logger.error(f"å‘é€Bç«™åˆé›†å®Œæˆæ¶ˆæ¯å¤±è´¥: {e}")
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ’­æ”¾åˆ—è¡¨æˆ–é¢‘é“ä¸‹è½½
            elif result.get("is_playlist") or result.get("is_channel") or result.get("downloaded_files"):
                # æ’­æ”¾åˆ—è¡¨æˆ–é¢‘é“ä¸‹è½½å®Œæˆ
                if result.get("is_channel"):
                    title = "ğŸ“º YouTubeé¢‘é“æ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆ"
                    channel_title = result.get("channel_title", "æœªçŸ¥é¢‘é“")
                    playlists = result.get("playlists_downloaded", [])
                    playlist_stats = result.get("playlist_stats", [])
                    download_path = result.get("download_path", "")

                    # è®¡ç®—æ€»æ–‡ä»¶å¤§å°å’ŒPARTæ–‡ä»¶ç»Ÿè®¡
                    total_size_mb = sum(stat.get('total_size_mb', 0) for stat in playlist_stats)
                    total_size_gb = total_size_mb / 1024

                    # è®¡ç®—æ€»çš„æˆåŠŸå’Œæœªå®Œæˆæ–‡ä»¶æ•°é‡
                    total_success_count = sum(stat.get('success_count', stat.get('video_count', 0)) for stat in playlist_stats)
                    total_part_count = sum(stat.get('part_count', 0) for stat in playlist_stats)

                    # æ ¼å¼åŒ–æ€»å¤§å°æ˜¾ç¤º - åªæ˜¾ç¤ºä¸€ä¸ªå•ä½
                    if total_size_gb >= 1.0:
                        total_size_str = f"{total_size_gb:.2f}GB"
                    else:
                        total_size_str = f"{total_size_mb:.2f}MB"

                    success_text = (
                        f"{self._escape_markdown(title)}\n\n"
                        f"ğŸ“º é¢‘é“: `{self._escape_markdown(channel_title)}`\n"
                        f"ğŸ“Š æ’­æ”¾åˆ—è¡¨æ•°é‡: `{self._escape_markdown(str(len(playlists)))}`\n\n"
                        f"å·²ä¸‹è½½çš„æ’­æ”¾åˆ—è¡¨:\n"
                    )

                    # ä½¿ç”¨playlist_statsæ¥æ˜¾ç¤ºé›†æ•°ä¿¡æ¯
                    for i, stat in enumerate(playlist_stats, 1):
                        playlist_title = stat.get("title", f"æ’­æ”¾åˆ—è¡¨{i}")
                        video_count = stat.get("video_count", 0)
                        success_text += f"  {self._escape_markdown(str(i))}\\. {self._escape_markdown(playlist_title)} \\({self._escape_markdown(str(video_count))} é›†\\)\n"

                    # æ„å»ºä¸‹è½½ç»Ÿè®¡ä¿¡æ¯
                    stats_text = f"âœ… æˆåŠŸ: `{total_success_count} ä¸ª`"
                    if total_part_count > 0:
                        stats_text += f"\nâš ï¸ æœªå®Œæˆ: `{total_part_count} ä¸ª`"
                        stats_text += f"\nğŸ’¡ æç¤º: å‘ç°æœªå®Œæˆæ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦é‡æ–°ä¸‹è½½"

                    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ã€æ€»å¤§å°å’Œä¿å­˜ä½ç½®ï¼ˆæ”¾åœ¨æœ€åï¼‰
                    success_text += (
                        f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡:\n{stats_text}\n"
                        f"ğŸ’¾ æ–‡ä»¶æ€»å¤§å°: `{self._escape_markdown(total_size_str)}`\n"
                        f"ğŸ“‚ ä¿å­˜ä½ç½®: `{self._escape_markdown(download_path)}`"
                    )
                else:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºXæ’­æ”¾åˆ—è¡¨
                    platform = result.get("platform", "")
                    if platform == "X" and result.get("is_playlist"):
                        # Xæ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆ
                        title = "ğŸ¬ **Xæ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆ**"
                        file_count = result.get("file_count", 0)
                        episode_count = result.get("episode_count", 0)
                        total_size_mb = result.get("total_size_mb", 0)
                        resolution = result.get("resolution", "æœªçŸ¥")
                        download_path = result.get("download_path", "")
                        filename_display = result.get("filename", "")
                        
                        success_text = (
                            f"{self._escape_markdown(title)}\n\n"
                            f"ğŸ“ **æ–‡ä»¶å**:\n{self._escape_markdown(filename_display)}\n\n"
                            f"ğŸ’¾ **æ–‡ä»¶å¤§å°**: `{self._escape_markdown(f'{total_size_mb:.2f}')} MB`\n"
                            f"ğŸ“Š **é›†æ•°**: `{self._escape_markdown(str(episode_count))} é›†`\n"
                            f"ğŸ–¼ï¸ **åˆ†è¾¨ç‡**: `{self._escape_markdown(resolution)}`\n"
                            f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{self._escape_markdown(download_path)}`"
                        )
                    else:
                        # YouTubeæ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆ
                        # æ£€æŸ¥æ˜¯å¦æœ‰è¯¦ç»†çš„æ–‡ä»¶ä¿¡æ¯
                        downloaded_files = result.get("downloaded_files", [])
                        if downloaded_files:
                            # æœ‰è¯¦ç»†æ–‡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨å¢å¼ºæ˜¾ç¤º
                            title = "ğŸ¬ **è§†é¢‘ä¸‹è½½å®Œæˆ**"
                            playlist_title = result.get("playlist_title", "YouTubeæ’­æ”¾åˆ—è¡¨")
                            video_count = result.get("video_count", len(downloaded_files))
                            total_size_mb = result.get("total_size_mb", 0)
                            resolution = result.get("resolution", "æœªçŸ¥")
                            download_path = result.get("download_path", "")

                            # æ„å»ºæ–‡ä»¶åæ˜¾ç¤ºåˆ—è¡¨
                            filename_lines = []
                            for i, file_info in enumerate(downloaded_files, 1):
                                filename = file_info.get("filename", f"æ–‡ä»¶{i}")
                                filename_lines.append(f"  {i:02d}. {filename}")
                            filename_display = '\n'.join(filename_lines)

                            # åŠ¨æ€å¤„ç†æ–‡ä»¶åæ˜¾ç¤ºï¼Œæœ€å¤§åŒ–åˆ©ç”¨TGæ¶ˆæ¯ç©ºé—´
                            filename_display = self.downloader._optimize_filename_display_for_telegram(
                                filename_display, video_count, total_size_mb, resolution, download_path
                            )

                            # è·å–PARTæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
                            success_count = result.get("success_count", video_count)
                            part_count = result.get("part_count", 0)

                            # æ„å»ºç»Ÿè®¡ä¿¡æ¯
                            stats_text = f"âœ… **æˆåŠŸ**: `{success_count} ä¸ª`"
                            if part_count > 0:
                                stats_text += f"\nâš ï¸ **æœªå®Œæˆ**: `{part_count} ä¸ª`"
                                stats_text += f"\nğŸ’¡ **æç¤º**: å‘ç°æœªå®Œæˆæ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦é‡æ–°ä¸‹è½½"

                            # è½¬ä¹‰å„ä¸ªå­—æ®µ
                            escaped_title = self._escape_markdown(title)
                            escaped_filename = self._escape_markdown(filename_display)
                            escaped_resolution = self._escape_markdown(resolution)
                            escaped_download_path = self._escape_markdown(download_path)
                            size_str = f"{total_size_mb:.2f}".replace('.', r'\.')

                            success_text = (
                                f"{escaped_title}\n\n"
                                f"ğŸ“ **æ–‡ä»¶å**:\n{escaped_filename}\n\n"
                                f"ğŸ’¾ **æ–‡ä»¶å¤§å°**: `{size_str} MB`\n"
                                f"ğŸ“Š **ä¸‹è½½ç»Ÿè®¡**:\n{stats_text}\n"
                                f"ğŸ–¼ï¸ **åˆ†è¾¨ç‡**: `{escaped_resolution}`\n"
                                f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{escaped_download_path}`"
                            )
                        else:
                            # æ²¡æœ‰è¯¦ç»†æ–‡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ç®€å•æ˜¾ç¤º
                            title = "ğŸ“‹ **YouTubeæ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆ**"
                            playlist_title = result.get("playlist_title", "æœªçŸ¥æ’­æ”¾åˆ—è¡¨")
                            video_count = result.get("video_count", 0)
                            download_path = result.get("download_path", "")

                            # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡
                            if result.get("already_downloaded", False):
                                title = "ğŸ“‹ **YouTubeæ’­æ”¾åˆ—è¡¨å·²å­˜åœ¨**"
                                completion_rate = result.get("completion_rate", 100)
                                completion_str = f"{completion_rate:.1f}".replace('.', r'\.')

                                success_text = (
                                    f"{self._escape_markdown(title)}\n\n"
                                    f"ğŸ“‹ **æ’­æ”¾åˆ—è¡¨**: `{self._escape_markdown(playlist_title)}`\n"
                                    f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{self._escape_markdown(download_path)}`\n"
                                    f"ğŸ“Š **è§†é¢‘æ•°é‡**: `{self._escape_markdown(str(video_count))}`\n"
                                    f"âœ… **å®Œæˆåº¦**: `{completion_str}%`\n"
                                    f"ğŸ’¡ **çŠ¶æ€**: æœ¬åœ°æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤ä¸‹è½½"
                                )
                            else:
                                # æ£€æŸ¥æ˜¯å¦ä¸ºé›¶æ–‡ä»¶æƒ…å†µï¼ˆæ‰€æœ‰è§†é¢‘ä¸å¯ç”¨ï¼‰
                                if video_count == 0:
                                    title = "âš ï¸ **YouTubeæ’­æ”¾åˆ—è¡¨æ— å¯ç”¨è§†é¢‘**"
                                    success_text = (
                                        f"{self._escape_markdown(title)}\n\n"
                                        f"ğŸ“‹ **æ’­æ”¾åˆ—è¡¨**: `{self._escape_markdown(playlist_title)}`\n"
                                        f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{self._escape_markdown(download_path)}`\n"
                                        f"âŒ **çŠ¶æ€**: æ’­æ”¾åˆ—è¡¨ä¸­çš„æ‰€æœ‰è§†é¢‘éƒ½ä¸å¯ç”¨\n"
                                        f"ğŸ’¡ **å¯èƒ½åŸå› **: è§†é¢‘è¢«åˆ é™¤ã€è´¦å·è¢«ç»ˆæ­¢æˆ–åœ°åŒºé™åˆ¶"
                                    )
                                else:
                                    success_text = (
                                        f"{self._escape_markdown(title)}\n\n"
                                        f"ğŸ“‹ **æ’­æ”¾åˆ—è¡¨**: `{self._escape_markdown(playlist_title)}`\n"
                                        f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{self._escape_markdown(download_path)}`\n"
                                        f"ğŸ“Š **è§†é¢‘æ•°é‡**: `{self._escape_markdown(str(video_count))}`"
                                    )

                try:
                    await status_message.edit_text(
                        text=success_text, parse_mode="MarkdownV2"
                    )
                except Exception as e:
                    if "Flood control" in str(e):
                        logger.warning(
                            "æ’­æ”¾åˆ—è¡¨ä¸‹è½½å®Œæˆæ¶ˆæ¯é‡åˆ°Flood controlï¼Œç­‰å¾…5ç§’åé‡è¯•..."
                        )
                        await asyncio.sleep(5)
                        try:
                            await status_message.edit_text(
                                text=success_text, parse_mode="MarkdownV2"
                            )
                        except Exception as retry_error:
                            logger.error(
                                f"é‡è¯•å‘é€æ’­æ”¾åˆ—è¡¨å®Œæˆæ¶ˆæ¯å¤±è´¥: {retry_error}"
                            )
                    else:
                        logger.error(f"å‘é€æ’­æ”¾åˆ—è¡¨å®Œæˆæ¶ˆæ¯å¤±è´¥: {e}")
            else:
                # å•æ–‡ä»¶ä¸‹è½½ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
                # æ ¹æ®ç»“æœæ„å»ºæˆåŠŸæ¶ˆæ¯
                resolution = result.get("resolution", "æœªçŸ¥")
                abr = result.get("abr")

                # æ ¹æ®åˆ†è¾¨ç‡åˆ¤æ–­æ˜¯è§†é¢‘è¿˜æ˜¯éŸ³é¢‘
                if resolution and resolution != "æœªçŸ¥" and resolution == "å›¾ç‰‡":
                    # å›¾ç‰‡ç±»å‹
                    title = "ğŸ–¼ï¸ **å›¾ç‰‡ä¸‹è½½å®Œæˆ**"
                    size_str = f"{result['size_mb']:.2f}".replace('.', r'\.')
                    files_count = result.get("files_count", 1)
                    file_formats = result.get("file_formats", [])
                    format_str = ", ".join(file_formats) if file_formats else "æœªçŸ¥æ ¼å¼"
                    
                    success_text = (
                        f"{self._escape_markdown(title)}\n\n"
                        f"ğŸ–¼ï¸ **å›¾ç‰‡æ•°é‡**: `{files_count} å¼ `\n"
                        f"ğŸ’¾ **æ–‡ä»¶å¤§å°**: `{size_str} MB`\n"
                        f"ğŸ“„ **æ–‡ä»¶æ ¼å¼**: `{self._escape_markdown(format_str)}`\n"
                        f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{self._escape_markdown(result['download_path'])}`"
                    )
                    
                    # ç›´æ¥å‘é€å›¾ç‰‡å®Œæˆæ¶ˆæ¯ï¼Œä¸è¿›å…¥åç»­çš„é€šç”¨å¤„ç†é€»è¾‘
                    try:
                        await status_message.edit_text(success_text, parse_mode="MarkdownV2")
                        logger.info("æ˜¾ç¤ºå›¾ç‰‡ä¸‹è½½å®Œæˆä¿¡æ¯")
                    except Exception as e:
                        if "Flood control" in str(e):
                            logger.warning("å›¾ç‰‡ä¸‹è½½å®Œæˆæ¶ˆæ¯é‡åˆ°Flood controlï¼Œç­‰å¾…5ç§’åé‡è¯•...")
                            await asyncio.sleep(5)
                            try:
                                await status_message.edit_text(success_text, parse_mode="MarkdownV2")
                            except Exception as retry_error:
                                logger.error(f"é‡è¯•å‘é€å›¾ç‰‡ä¸‹è½½å®Œæˆæ¶ˆæ¯å¤±è´¥: {retry_error}")
                        else:
                            logger.error(f"å‘é€å›¾ç‰‡ä¸‹è½½å®Œæˆæ¶ˆæ¯å¤±è´¥: {e}")
                    return
                elif resolution and resolution != "æœªçŸ¥" and "x" in resolution:
                    # æœ‰åˆ†è¾¨ç‡ä¿¡æ¯ï¼Œè¯´æ˜æ˜¯è§†é¢‘
                    # è§£æåˆ†è¾¨ç‡å¹¶æ·»åŠ è´¨é‡æ ‡è¯†
                    try:
                        width, height = resolution.split("x")
                        width, height = int(width), int(height)

                        # æ ¹æ®é«˜åº¦åˆ¤æ–­è´¨é‡
                        if height >= 4320:
                            quality = "8K"
                        elif height >= 2160:
                            quality = "4K"
                        elif height >= 1440:
                            quality = "2K"
                        elif height >= 1080:
                            quality = "1080p"
                        elif height >= 720:
                            quality = "720p"
                        elif height >= 480:
                            quality = "480p"
                        else:
                            quality = f"{height}p"

                        quality_info = f" ({quality})"
                    except (ValueError, TypeError):
                        quality_info = ""

                    # è½¬ä¹‰quality_info
                    # escaped_quality_info =
                    # self._escape_markdown(quality_info)

                    # æ„å»ºå®Œæ•´çš„titleï¼Œç„¶åä¸€æ¬¡æ€§è½¬ä¹‰
                    title = "ğŸ¬ **è§†é¢‘ä¸‹è½½å®Œæˆ**"
                    escaped_title = self._escape_markdown(title)
                    # å°†è´¨é‡æ ‡è¯†æ·»åŠ åˆ°åˆ†è¾¨ç‡åé¢
                    resolution_with_quality = f"{resolution}{quality_info}"
                    size_str = f"{result['size_mb']:.2f}".replace('.', r'\.')
                    success_text = (
                        f"{escaped_title}\n\n"
                        f"ğŸ“ **æ–‡ä»¶å**: `{self._escape_markdown(result['filename'])}`\n"
                        f"ğŸ’¾ **æ–‡ä»¶å¤§å°**: `{size_str} MB`\n"
                        f"ğŸ“º **åˆ†è¾¨ç‡**: `{self._escape_markdown(resolution_with_quality)}`\n"
                        f"ğŸ“‚ **ä¿å­˜ä½ç½®**: `{self._escape_markdown(result['download_path'])}`"
                    )
                # ä½¿ç”¨ç®€å•æ ¼å¼æ˜¾ç¤ºå®Œæˆä¿¡æ¯ï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡ï¼‰
                try:
                    # è·å–è¿›åº¦ä¿¡æ¯ç”¨äºæ˜¾ç¤º
                    display_filename = self._clean_filename_for_display(result.get('filename', progress_data.get('filename', 'video.mp4')))
                    resolution = result.get('resolution', 'æœªçŸ¥')
                    platform = result.get('platform', 'æœªçŸ¥')
                    size_mb = result.get('size_mb', 0)
                    
                    # è·å–åˆ†è¾¨ç‡è´¨é‡æ ‡è¯†
                    quality_suffix = self._get_resolution_quality(resolution)
                    
                    # è·å–ä¸‹è½½è·¯å¾„
                    download_path = result.get('download_path', 'æœªçŸ¥è·¯å¾„')
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºBç«™åˆé›†ä¸‹è½½
                    video_type = result.get('video_type', '')
                    count = result.get('count', 0)
                    playlist_title = result.get('playlist_title', '')
                    
                    if video_type == 'playlist' and count > 1 and 'Bilibili' in platform:
                        # Bç«™åˆé›†ä¸‹è½½å®Œæˆï¼Œä½¿ç”¨ç‰¹æ®Šæ ¼å¼
                        # ä½¿ç”¨resultä¸­çš„æ–‡ä»¶ä¿¡æ¯ï¼Œè€Œä¸æ˜¯éå†ç›®å½•
                        import os

                        try:
                            # æ£€æŸ¥resultä¸­æ˜¯å¦æœ‰æ–‡ä»¶ä¿¡æ¯
                            if result.get('is_playlist') and result.get('files'):
                                # ä½¿ç”¨yt-dlpè®°å½•çš„æ–‡ä»¶ä¿¡æ¯
                                file_info_list = result['files']

                                # æ„å»ºæ–‡ä»¶ååˆ—è¡¨
                                file_list = []
                                for i, file_info in enumerate(file_info_list, 1):
                                    filename = file_info['filename']
                                    file_list.append(f"  {i:02d}. {filename}")

                                # ä½¿ç”¨å·²è®¡ç®—çš„æ€»æ–‡ä»¶å¤§å°
                                total_size = result.get('total_size_mb', 0)
                            else:
                                # å›é€€æ–¹æ¡ˆï¼šå¦‚æœresultä¸­æ²¡æœ‰æ–‡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ç›®å½•éå†
                                logger.warning("âš ï¸ resultä¸­æ²¡æœ‰æ–‡ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ç›®å½•éå†å›é€€æ–¹æ¡ˆ")
                                download_dir = Path(download_path)
                                video_files = sorted(download_dir.glob("*.mp4"))

                                # æ„å»ºæ–‡ä»¶ååˆ—è¡¨
                                file_list = []
                                for i, file_path in enumerate(video_files, 1):
                                    filename = file_path.name
                                    file_list.append(f"  {i:02d}. {filename}")

                                # è®¡ç®—æ€»æ–‡ä»¶å¤§å°
                                total_size = sum(f.stat().st_size for f in video_files) / (1024 * 1024)
                            
                            # è·å–åˆ†è¾¨ç‡ä¿¡æ¯
                            if result.get('is_playlist') and result.get('files'):
                                # ä½¿ç”¨resultä¸­çš„åˆ†è¾¨ç‡ä¿¡æ¯
                                resolutions = set()
                                for file_info in file_info_list:
                                    resolution = file_info.get('resolution', 'æœªçŸ¥')
                                    if resolution != 'æœªçŸ¥':
                                        resolutions.add(resolution)
                                resolution_str = ', '.join(sorted(resolutions)) if resolutions else 'æœªçŸ¥'
                            else:
                                # å›é€€æ–¹æ¡ˆï¼šä½¿ç”¨ffprobeæ£€æµ‹åˆ†è¾¨ç‡
                                resolutions = set()
                                for file_path in video_files[:3]:  # åªæ£€æŸ¥å‰3ä¸ªæ–‡ä»¶
                                    try:
                                        import subprocess
                                        result_cmd = subprocess.run([
                                            'ffprobe', '-v', 'quiet', '-select_streams', 'v:0',
                                            '-show_entries', 'stream=width,height', '-of', 'csv=p=0',
                                            str(file_path)
                                        ], capture_output=True, text=True)
                                        if result_cmd.returncode == 0:
                                            width, height = result_cmd.stdout.strip().split(',')
                                            resolutions.add(f"{width}x{height}")
                                    except:
                                        pass
                                resolution_str = ', '.join(sorted(resolutions)) if resolutions else 'æœªçŸ¥'
                            
                            completion_text = f"""ğŸ¬ **è§†é¢‘ä¸‹è½½å®Œæˆ**

ğŸ“ æ–‡ä»¶å:
{chr(10).join(file_list)}

ğŸ’¾ æ–‡ä»¶å¤§å°: {total_size:.2f} MB
ğŸ“Š é›†æ•°: {count} é›†
ğŸ–¼ï¸ åˆ†è¾¨ç‡: {resolution_str}
ğŸ“‚ ä¿å­˜ä½ç½®: {download_path}"""
                            
                        except Exception as e:
                            logger.error(f"æ„å»ºBç«™åˆé›†å®Œæˆä¿¡æ¯æ—¶å‡ºé”™: {e}")
                            # å¦‚æœå‡ºé”™ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
                            completion_text = f"""ğŸ¬ **è§†é¢‘ä¸‹è½½å®Œæˆ**

ğŸ“ æ–‡ä»¶å: {display_filename}
ğŸ’¾ æ–‡ä»¶å¤§å°: {size_mb:.2f} MB
ğŸ“Š é›†æ•°: {count} é›†
ğŸ–¼ï¸ åˆ†è¾¨ç‡: {resolution}{quality_suffix}
ğŸ“‚ ä¿å­˜ä½ç½®: {download_path}"""
                    else:
                        # ä½¿ç”¨æ–°çš„æ ¼å¼ï¼šå»æ‰è¿›åº¦æ¡ï¼Œæ·»åŠ è´¨é‡æ ‡è¯†
                        completion_text = f"""ğŸ¬ **è§†é¢‘ä¸‹è½½å®Œæˆ**

ğŸ“ æ–‡ä»¶å: {display_filename}
ğŸ’¾ æ–‡ä»¶å¤§å°: {size_mb:.2f} MB
ğŸ¥ åˆ†è¾¨ç‡: {resolution}{quality_suffix}
ğŸ“‚ ä¿å­˜ä½ç½®: {download_path}"""
                    
                    await status_message.edit_text(completion_text)
                    logger.info("æ˜¾ç¤ºä¸‹è½½å®Œæˆä¿¡æ¯")
                except Exception as e:
                    if "Flood control" in str(e):
                        logger.warning(
                            "ä¸‹è½½å®Œæˆæ¶ˆæ¯é‡åˆ°Flood controlï¼Œç­‰å¾…5ç§’åé‡è¯•..."
                        )
                        await asyncio.sleep(5)
                        try:
                            await status_message.edit_text(completion_text)
                        except Exception as retry_error:
                            logger.error(
                                f"é‡è¯•å‘é€ä¸‹è½½å®Œæˆæ¶ˆæ¯å¤±è´¥: {retry_error}"
                            )
                    else:
                        logger.error(f"å‘é€ä¸‹è½½å®Œæˆæ¶ˆæ¯å¤±è´¥: {e}")
        else:
            # ç¡®ä¿resultä¸ä¸ºNone
            if result:
                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
            else:
                error_msg = "ä¸‹è½½ä»»åŠ¡è¿”å›ç©ºç»“æœ"
                
            try:
                await status_message.edit_text(
                    f"âŒ ä¸‹è½½å¤±è´¥: `{self._escape_markdown(error_msg)}`",
                    parse_mode="MarkdownV2",
                )
            except Exception as retry_error:
                logger.error(f"é‡è¯•å‘é€ä¸‹è½½å¤±è´¥æ¶ˆæ¯å¤±è´¥: {retry_error}")
            return


    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """å¤„ç† /start å‘½ä»¤ - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        user_id = update.message.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await update.message.reply_text("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        welcome_message = (
            "ğŸ¤– <b>SaveXTube å·²å¯åŠ¨ï¼</b>\n"
            "<b>æ”¯æŒçš„å¹³å°:</b>\n"
            "â€¢ X (Twitter)\n"
            "â€¢ YouTubeï¼ˆåŒ…æ‹¬æ’­æ”¾åˆ—è¡¨å’Œé¢‘é“ï¼‰\n"
            "â€¢ Bilibili\n"
            "â€¢ Xvideos\n"
            "â€¢ Pornhub\n\n"
            "<b>ä½¿ç”¨æ–¹æ³•ï¼š</b>\n"
            "ç›´æ¥å‘é€è§†é¢‘é“¾æ¥å³å¯å¼€å§‹ä¸‹è½½\n\n"
            "<b>å‘½ä»¤ï¼š</b>\n"
            "<b>/start</b> - ğŸ æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯\n"
            "<b>/status</b> - ğŸ“Š æŸ¥çœ‹ä¸‹è½½ç»Ÿè®¡\n"
            "<b>/version</b> - âš™ï¸ æŸ¥çœ‹ç‰ˆæœ¬ä¿¡æ¯\n"
            "<b>/settings</b> - ğŸ›  åŠŸèƒ½è®¾ç½®ï¼ˆå¤šPè‡ªåŠ¨ä¸‹è½½å¼€å…³ï¼‰\n\n"
            "<b>ç‰¹æ€§ï¼š</b>\n"
            "âœ… å®æ—¶ä¸‹è½½è¿›åº¦æ˜¾ç¤º\n"
            "âœ… æ™ºèƒ½æ ¼å¼é€‰æ‹©å’Œå¤‡ç”¨æ–¹æ¡ˆ\n"
            "âœ… è‡ªåŠ¨æ ¼å¼è½¬æ¢ï¼ˆYouTube webm â†’ mp4ï¼‰\n"
            "âœ… æŒ‰å¹³å°åˆ†ç±»å­˜å‚¨\n"
            "âœ… æ”¯æŒ NSFW å†…å®¹ä¸‹è½½\n"
            "âœ… å”¯ä¸€æ–‡ä»¶åï¼Œé¿å…è¦†ç›–\n"
            "âœ… YouTube æ’­æ”¾åˆ—è¡¨å’Œé¢‘é“ä¸‹è½½"
        )
        await update.message.reply_text(welcome_message, parse_mode="HTML")

    async def settings_command(
        self, update: Update, context: ContextTypes.DEFAULT_TYPE
    ):
        """/settings å‘½ä»¤ï¼Œæ˜¾ç¤ºè‡ªåŠ¨ä¸‹è½½å¼€å…³æŒ‰é’®"""
        user_id = update.message.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await update.message.reply_text("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        current = self.bilibili_auto_playlist
        text = "âœ… å¤šPè‡ªåŠ¨ä¸‹è½½ï¼šå¼€å¯" if current else "âŒ  å¤šPè‡ªåŠ¨ä¸‹è½½ï¼šå…³é—­"
        toggle_button = InlineKeyboardButton(text, callback_data="toggle_autop")
        reply_markup = InlineKeyboardMarkup([[toggle_button]])
        await update.message.reply_text("ğŸ›  åŠŸèƒ½è®¾ç½®", reply_markup=reply_markup)

    async def settings_button_handler(
        self, update: Update, context: ContextTypes.DEFAULT_TYPE
    ):
        query = update.callback_query
        user_id = query.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await query.answer("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        current = self.bilibili_auto_playlist
        self.bilibili_auto_playlist = not current
        await self._save_config_async()
        new_text = "âœ… è‡ªåŠ¨ä¸‹è½½ï¼šå¼€å¯" if not current else "âŒ è‡ªåŠ¨ä¸‹è½½ï¼šå…³é—­"
        reply_markup = InlineKeyboardMarkup(
            [[InlineKeyboardButton(new_text, callback_data="toggle_autop")]]
        )
        await query.edit_message_reply_markup(reply_markup=reply_markup)
        await query.answer("å·²åˆ‡æ¢è‡ªåŠ¨ä¸‹è½½çŠ¶æ€")

    async def cancel_task_callback(
        self, update: Update, context: ContextTypes.DEFAULT_TYPE
    ):
        """å¤„ç†å–æ¶ˆä¸‹è½½ä»»åŠ¡çš„æŒ‰é’®ç‚¹å‡»"""
        query = update.callback_query
        user_id = query.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await query.answer("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        await query.answer()

        # è·å–ä»»åŠ¡ ID
        task_id = query.data.split(":")[1]

        # å–æ¶ˆå¯¹åº”çš„ä¸‹è½½ä»»åŠ¡
        cancelled = await self.cancel_download_task(task_id)

        if cancelled:
            # ç¼–è¾‘åŸæ¶ˆæ¯ä¸ºå·²å–æ¶ˆ
            await query.edit_message_text(f"ğŸš« ä¸‹è½½ä»»åŠ¡å·²å–æ¶ˆï¼ˆID: {task_id}ï¼‰")
        else:
            # ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²ç»è¢«å–æ¶ˆ
            await query.edit_message_text(f"âš ï¸ ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²è¢«å–æ¶ˆï¼ˆID: {task_id}ï¼‰")

    async def add_download_task(self, task_id: str, task: asyncio.Task):
        """æ·»åŠ ä¸‹è½½ä»»åŠ¡åˆ°ç®¡ç†å™¨ä¸­"""
        async with self.task_lock:
            self.download_tasks[task_id] = {
                "task": task,
                "cancelled": False,
                "start_time": time.time(),
            }
            logger.info(f"ğŸ“ æ·»åŠ ä¸‹è½½ä»»åŠ¡: {task_id}")

    async def cancel_download_task(self, task_id: str) -> bool:
        """å–æ¶ˆæŒ‡å®šçš„ä¸‹è½½ä»»åŠ¡"""
        async with self.task_lock:
            if task_id in self.download_tasks:
                task_info = self.download_tasks[task_id]
                if not task_info["cancelled"]:
                    task_info["cancelled"] = True
                    task_info["task"].cancel()
                    logger.info(f"ğŸš« å–æ¶ˆä¸‹è½½ä»»åŠ¡: {task_id}")
                    return True
                else:
                    logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} å·²ç»è¢«å–æ¶ˆ")
                    return False
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡: {task_id}")
                return False

    async def remove_download_task(self, task_id: str):
        """ä»ç®¡ç†å™¨ä¸­ç§»é™¤ä¸‹è½½ä»»åŠ¡"""
        async with self.task_lock:
            if task_id in self.download_tasks:
                del self.download_tasks[task_id]
                logger.info(f"ğŸ—‘ï¸ ç§»é™¤ä¸‹è½½ä»»åŠ¡: {task_id}")

    def is_task_cancelled(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²è¢«å–æ¶ˆ"""
        if task_id in self.download_tasks:
            return self.download_tasks[task_id]["cancelled"]
        return False

    async def download_user_media(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        é€šè¿‡ Telethon å¤„ç†ç”¨æˆ·å‘é€æˆ–è½¬å‘çš„åª’ä½“æ–‡ä»¶ï¼Œä»¥æ”¯æŒå¤§æ–‡ä»¶ä¸‹è½½ã€‚
        """
        user_id = update.message.from_user.id
        
        # æƒé™æ£€æŸ¥
        if not self._check_user_permission(user_id):
            await update.message.reply_text("âŒ æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
            return
        
        message = update.message
        chat_id = message.chat_id
        
        if not self.user_client:
            await message.reply_text("âŒ åª’ä½“ä¸‹è½½åŠŸèƒ½æœªå¯ç”¨ï¼ˆTelethon æœªé…ç½®ï¼‰ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚")
            return
        
        # --- ç´§æ€¥ä¿®å¤: ç¡®ä¿ self.bot_id å·²è®¾ç½® ---
        if not self.bot_id:
            try:
                logger.warning("self.bot_id æœªè®¾ç½®ï¼Œæ­£åœ¨å°è¯•è·å–...")
                bot_info = await context.bot.get_me()
                self.bot_id = bot_info.id
                logger.info(f"æˆåŠŸè·å–åˆ° bot_id: {self.bot_id}")
            except Exception as e:
                logger.error(f"ç´§æ€¥è·å– bot_id å¤±è´¥: {e}", exc_info=True)
                await message.reply_text(f"âŒ å†…éƒ¨åˆå§‹åŒ–é”™è¯¯ï¼šæ— æ³•è·å–æœºå™¨äººè‡ªèº«IDã€‚è¯·ç¨åé‡è¯•ã€‚")
                return
        # æå–åª’ä½“ä¿¡æ¯
        attachment = message.effective_attachment
        if not attachment:
            await message.reply_text("â“ è¯·å‘é€æˆ–è½¬å‘ä¸€ä¸ªåª’ä½“æ–‡ä»¶ã€‚")
            return
        
        file_name = getattr(attachment, 'file_name', 'unknown_file')
        # ä¼˜å…ˆå¤„ç†.torrentæ–‡ä»¶
        if file_name and file_name.lower().endswith('.torrent'):
            logger.info(f"ğŸ”— æ£€æµ‹åˆ°ç§å­æ–‡ä»¶: {file_name}")
            status_message = await message.reply_text("ğŸ”— æ­£åœ¨å¤„ç†ç§å­æ–‡ä»¶...")
            try:
                file_path = await context.bot.get_file(attachment.file_id)
                torrent_data = await file_path.download_as_bytearray()
                success = await self.add_torrent_file_to_qb(torrent_data, file_name)
                if success:
                    await status_message.edit_text("âœ… **ç£åŠ›é“¾æ¥/ç§å­æ–‡ä»¶å·²æˆåŠŸæ·»åŠ åˆ° qBittorrentï¼**\n\nğŸ“ ä»»åŠ¡å·²æ·»åŠ åˆ°ä¸‹è½½é˜Ÿåˆ—\nğŸ” æ‚¨å¯ä»¥åœ¨ qBittorrent ä¸­æŸ¥çœ‹ä¸‹è½½è¿›åº¦\nğŸ’¡ æç¤ºï¼šä¸‹è½½å®Œæˆåæ–‡ä»¶ä¼šä¿å­˜åˆ°é…ç½®çš„ä¸‹è½½ç›®å½•")
                else:
                    await status_message.edit_text("âŒ æ·»åŠ åˆ°qBittorrentå¤±è´¥ï¼")
            except Exception as e:
                logger.exception(f"æ·»åŠ ç§å­æ–‡ä»¶åˆ°qBittorrentå‡ºé”™: {e}")
                await status_message.edit_text(f"âŒ æ·»åŠ ç§å­æ–‡ä»¶å‡ºé”™: {e}")
            return
        # å¦‚æœ Bot API æ²¡æœ‰æ–‡ä»¶åï¼Œå°è¯•ä»æ¶ˆæ¯æ–‡æœ¬ä¸­æå–
        if not file_name or file_name == 'unknown_file':
            logger.info(f"Bot API æ¶ˆæ¯æ–‡æœ¬: '{message.text}'")
            if message.text and message.text.strip():
                file_name = message.text.strip()
                logger.info(f"ä»æ¶ˆæ¯æ–‡æœ¬ä¸­æå–æ–‡ä»¶å: {file_name}")
            else:
                logger.info("Bot API æ¶ˆæ¯æ–‡æœ¬ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½å­—ç¬¦")
        
        # æ–‡ä»¶åå¤„ç†ï¼šé¦–è¡Œå»#ï¼Œç©ºæ ¼å˜_ï¼›æ­£æ–‡ç©ºæ ¼å˜_ï¼›æœ«è¡Œå…¨#æ ‡ç­¾åˆ™å»#æ‹¼æ¥ï¼Œæ‰€æœ‰éƒ¨åˆ†ç”¨_æ‹¼æ¥
        if file_name and file_name != 'unknown_file':
            lines = file_name.splitlines()
            parts = []
            # å¤„ç†é¦–è¡Œ
            if lines:
                first = lines[0].lstrip('#').strip().replace(' ', '_')
                if first:
                    parts.append(first)
            # å¤„ç†æ­£æ–‡
            for l in lines[1:-1]:
                l = l.strip().replace(' ', '_')
                if l:
                    parts.append(l)
            # å¤„ç†æœ«è¡Œï¼ˆå…¨æ˜¯#æ ‡ç­¾ï¼‰
            if len(lines) > 1 and all(x.startswith('#') for x in lines[-1].split()):
                tags = [x.lstrip('#').strip().replace(' ', '_') for x in lines[-1].split() if x.lstrip('#').strip()]
                if tags:
                    parts.extend(tags)
            else:
                # æœ«è¡Œä¸æ˜¯å…¨#æ ‡ç­¾ï¼Œä¹Ÿå½“æ­£æ–‡å¤„ç†
                if len(lines) > 1:
                    last = lines[-1].strip().replace(' ', '_')
                    if last:
                        parts.append(last)
            file_name = '_'.join(parts)
        if not file_name:
            file_name = 'unknown_file'
        file_size = getattr(attachment, 'file_size', 0)
        file_unique_id = getattr(attachment, 'file_unique_id', 'unknown_id')
        total_mb = file_size / (1024 * 1024) if file_size else 0
        
        # è®°å½• bot ç«¯æ”¶åˆ°çš„æ¶ˆæ¯ä¿¡æ¯
        bot_message_timestamp = message.date
        logger.info(
            f"Bot API æ”¶åˆ°åª’ä½“: name='{file_name}', size={file_size}, "
            f"time={bot_message_timestamp.isoformat()}, unique_id='{file_unique_id}'"
        )
        status_message = await message.reply_text("æ­£åœ¨åˆ†ææ¶ˆæ¯ï¼Œè¯·ç¨å€™...")
        try:
            # åœ¨ç”¨æˆ·å®¢æˆ·ç«¯ï¼ˆuser_clientï¼‰ä¸­æŸ¥æ‰¾åŒ¹é…çš„æ¶ˆæ¯
            telethon_message = None
            audio_bitrate = None
            audio_duration = None
            video_width = None
            video_height = None
            video_duration = None
            time_window_seconds = 5 # å…è®¸5ç§’çš„æ—¶é—´è¯¯å·®
            
            # ç›®æ ‡æ˜¯ä¸æœºå™¨äººçš„ç§èŠ
            try:
                # é¦–å…ˆå°è¯•ä½¿ç”¨bot_idè·å–å®ä½“
                target_entity = await self.user_client.get_entity(self.bot_id)
            except ValueError as e:
                logger.warning(f"æ— æ³•é€šè¿‡bot_idè·å–å®ä½“: {e}")
                try:
                    # å¤‡ç”¨æ–¹æ¡ˆ1: å°è¯•ä½¿ç”¨botç”¨æˆ·å
                    bot_info = await context.bot.get_me()
                    bot_username = bot_info.username
                    if bot_username:
                        logger.info(f"å°è¯•ä½¿ç”¨botç”¨æˆ·åè·å–å®ä½“: @{bot_username}")
                        target_entity = await self.user_client.get_entity(bot_username)
                    else:
                        raise ValueError("Botæ²¡æœ‰ç”¨æˆ·å")
                except Exception as e2:
                    logger.warning(f"æ— æ³•é€šè¿‡ç”¨æˆ·åè·å–å®ä½“: {e2}")
                    try:
                        # å¤‡ç”¨æ–¹æ¡ˆ2: ä½¿ç”¨ "me" è·å–ä¸è‡ªå·±çš„å¯¹è¯
                        logger.info("å°è¯•ä½¿ç”¨ 'me' è·å–å¯¹è¯")
                        target_entity = await self.user_client.get_entity("me")
                    except Exception as e3:
                        logger.error(f"æ‰€æœ‰è·å–å®ä½“çš„æ–¹æ³•éƒ½å¤±è´¥äº†: {e3}")
                        await status_message.edit_text(
                            "âŒ æ— æ³•è®¿é—®æ¶ˆæ¯å†å²ï¼Œå¯èƒ½æ˜¯Telethonä¼šè¯é—®é¢˜ã€‚è¯·è”ç³»ç®¡ç†å‘˜ã€‚"
                        )
                        return
            
            async for msg in self.user_client.iter_messages(target_entity, limit=20):
                # å…¼å®¹ä¸¤ç§åª’ä½“ç±»å‹: document (è§†é¢‘/æ–‡ä»¶) å’Œ audio (ä½œä¸ºéŸ³é¢‘å‘é€)
                media_to_check = msg.media.document if hasattr(msg.media, 'document') else msg.media
                
                if media_to_check and hasattr(media_to_check, 'size') and media_to_check.size == file_size:
                    if abs((msg.date - bot_message_timestamp).total_seconds()) < time_window_seconds:
                        telethon_message = msg
                        logger.info(f"æ‰¾åˆ°åŒ¹é…æ¶ˆæ¯ï¼Œå¼€å§‹æå–åª’ä½“å±æ€§...")
                        logger.info(f"Telethon æ¶ˆæ¯å®Œæ•´ä¿¡æ¯: {telethon_message}")
                        logger.info(f"Telethon æ¶ˆæ¯æ–‡æœ¬å±æ€§: '{telethon_message.text}'")
                        logger.info(f"Telethon æ¶ˆæ¯åŸå§‹æ–‡æœ¬: '{telethon_message.raw_text}'")
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºéŸ³é¢‘å¹¶æå–å…ƒæ•°æ®
                        if hasattr(media_to_check, 'attributes'):
                            logger.info(f"åª’ä½“å±æ€§åˆ—è¡¨: {[type(attr).__name__ for attr in media_to_check.attributes]}")
                            
                            for attr in media_to_check.attributes:
                                logger.info(f"æ£€æŸ¥å±æ€§: {type(attr).__name__} - {attr}")
                                
                                # éŸ³é¢‘å±æ€§
                                if isinstance(attr, types.DocumentAttributeAudio):
                                    if hasattr(attr, 'bitrate'):
                                        audio_bitrate = attr.bitrate
                                    if hasattr(attr, 'duration'):
                                        audio_duration = attr.duration
                                    logger.info(f"æå–åˆ°éŸ³é¢‘å…ƒæ•°æ®: ç ç‡={audio_bitrate}, æ—¶é•¿={audio_duration}")
                                
                                # è§†é¢‘å±æ€§
                                elif isinstance(attr, types.DocumentAttributeVideo):
                                    if hasattr(attr, 'w') and hasattr(attr, 'h'):
                                        video_width = attr.w
                                        video_height = attr.h
                                        logger.info(f"æå–åˆ°è§†é¢‘å…ƒæ•°æ®: åˆ†è¾¨ç‡={video_width}x{video_height}")

                                    if hasattr(attr, 'duration'):
                                        video_duration = attr.duration
                                        logger.info(f"æå–åˆ°è§†é¢‘æ—¶é•¿: {video_duration}ç§’")
                                
                                # æ–‡æ¡£å±æ€§ï¼ˆå¯èƒ½åŒ…å«æ–‡ä»¶åç­‰ä¿¡æ¯ï¼‰
                                elif isinstance(attr, types.DocumentAttributeFilename):
                                    logger.info(f"æå–åˆ°æ–‡ä»¶å: {attr.file_name}")
                                    # ä½¿ç”¨ä» Telethon æå–çš„æ–‡ä»¶åï¼Œå¦‚æœä¹‹å‰æ²¡æœ‰è·å–åˆ°æ–‡ä»¶å
                                    if not file_name or file_name == 'unknown_file':
                                        file_name = attr.file_name
                                        logger.info(f"ä½¿ç”¨ Telethon æ–‡ä»¶å: {file_name}")
                                
                                # éŸ³é¢‘å±æ€§
                                if isinstance(attr, types.DocumentAttributeAudio):
                                    if hasattr(attr, 'bitrate'):
                                        audio_bitrate = attr.bitrate
                                    if hasattr(attr, 'duration'):
                                        audio_duration = attr.duration
                                    logger.info(f"æå–åˆ°éŸ³é¢‘å…ƒæ•°æ®: ç ç‡={audio_bitrate}, æ—¶é•¿={audio_duration}")
                                
                                # è§†é¢‘å±æ€§
                                elif isinstance(attr, types.DocumentAttributeVideo):
                                    if hasattr(attr, 'w') and hasattr(attr, 'h'):
                                        video_width = attr.w
                                        video_height = attr.h
                                        logger.info(f"æå–åˆ°è§†é¢‘å…ƒæ•°æ®: åˆ†è¾¨ç‡={video_width}x{video_height}")

                                    if hasattr(attr, 'duration'):
                                        video_duration = attr.duration
                                        logger.info(f"æå–åˆ°è§†é¢‘æ—¶é•¿: {video_duration}ç§’")
                        
                        break # æ‰¾åˆ°åŒ¹é…é¡¹ï¼Œè·³å‡ºå¾ªç¯
            
            # å¦‚æœè¿˜æ²¡æœ‰æ–‡ä»¶åï¼Œå°è¯•ä» Telethon æ¶ˆæ¯æ–‡æœ¬ä¸­æå–
            if (not file_name or file_name == 'unknown_file') and telethon_message:
                logger.info(f"Telethon æ¶ˆæ¯æ–‡æœ¬: '{telethon_message.text}'")
                if telethon_message.text and telethon_message.text.strip():
                    file_name = telethon_message.text.strip()
                    logger.info(f"ä» Telethon æ¶ˆæ¯æ–‡æœ¬ä¸­æå–æ–‡ä»¶å: {file_name}")
                    # å¯¹ä» Telethon è·å–çš„æ–‡ä»¶åä¹Ÿåº”ç”¨ # å·å¤„ç†
                    if file_name:
                        lines = file_name.splitlines()
                        parts = []
                        # å¤„ç†é¦–è¡Œ
                        if lines:
                            first = lines[0].lstrip('#').strip().replace(' ', '_')
                            if first:
                                parts.append(first)
                        # å¤„ç†æ­£æ–‡
                        for l in lines[1:-1]:
                            l = l.strip().replace(' ', '_')
                            if l:
                                parts.append(l)
                        # å¤„ç†æœ«è¡Œï¼ˆå…¨æ˜¯#æ ‡ç­¾ï¼‰
                        if len(lines) > 1 and all(x.startswith('#') for x in lines[-1].split()):
                            tags = [x.lstrip('#').strip().replace(' ', '_') for x in lines[-1].split() if x.lstrip('#').strip()]
                            if tags:
                                parts.extend(tags)
                        else:
                            # æœ«è¡Œä¸æ˜¯å…¨#æ ‡ç­¾ï¼Œä¹Ÿå½“æ­£æ–‡å¤„ç†
                            if len(lines) > 1:
                                last = lines[-1].strip().replace(' ', '_')
                                if last:
                                    parts.append(last)
                        file_name = '_'.join(parts)
                    if not file_name:
                        file_name = 'unknown_file'
                    logger.info(f"å¤„ç†åçš„æ–‡ä»¶å: {file_name}")
                else:
                    logger.info("Telethon æ¶ˆæ¯æ–‡æœ¬ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½å­—ç¬¦")
            
            # å…œåº•æœºåˆ¶ï¼šå¦‚æœè¿˜æ˜¯æ²¡æœ‰æ–‡ä»¶åï¼Œä½¿ç”¨è§†é¢‘æ–‡ä»¶ ID
            if not file_name or file_name == 'unknown_file':
                if telethon_message and hasattr(telethon_message.media, 'document'):
                    # ä½¿ç”¨æ–‡æ¡£ ID ä½œä¸ºæ–‡ä»¶å
                    doc_id = telethon_message.media.document.id
                    logger.info(f"å…œåº•æœºåˆ¶è§¦å‘ - æ–‡ä»¶å¤§å°: {file_size} bytes, è§†é¢‘åˆ†è¾¨ç‡: {video_width}x{video_height}, éŸ³é¢‘æ—¶é•¿: {audio_duration}")
                    # æ ¹æ®æ£€æµ‹åˆ°çš„æ–‡ä»¶ç±»å‹æ·»åŠ æ‰©å±•å
                    if video_width is not None and video_height is not None:
                        file_name = f"video_{doc_id}.mp4"
                        logger.info(f"æ£€æµ‹åˆ°è§†é¢‘å±æ€§ï¼Œä½¿ç”¨ .mp4 æ‰©å±•å")
                    elif audio_duration is not None and audio_bitrate is not None:
                        file_name = f"audio_{doc_id}.mp3"
                        logger.info(f"æ£€æµ‹åˆ°éŸ³é¢‘å±æ€§ï¼Œä½¿ç”¨ .mp3 æ‰©å±•å")
                    else:
                        # å¦‚æœæ— æ³•ç¡®å®šç±»å‹ï¼Œä½†æ–‡ä»¶å¤§å°è¾ƒå¤§ï¼Œå¾ˆå¯èƒ½æ˜¯è§†é¢‘æ–‡ä»¶
                        if file_size > 1024 * 1024:  # å¤§äº1MB
                            file_name = f"video_{doc_id}.mp4"
                            logger.info(f"æ–‡ä»¶å¤§å°è¾ƒå¤§({file_size} bytes)ï¼Œæ¨æµ‹ä¸ºè§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨ .mp4 æ‰©å±•å")
                        else:
                            file_name = f"file_{doc_id}.bin"
                            logger.info(f"æ–‡ä»¶å¤§å°è¾ƒå°({file_size} bytes)ï¼Œä½¿ç”¨ .bin æ‰©å±•å")
                    logger.info(f"ä½¿ç”¨æ–‡ä»¶ ID ä½œä¸ºæ–‡ä»¶å: {file_name}")
            
            # æ ¹æ®åª’ä½“ç±»å‹ç¡®å®šä¸‹è½½è·¯å¾„
            # æ”¹è¿›éŸ³é¢‘æ£€æµ‹ï¼šä¸ä»…æ£€æŸ¥DocumentAttributeAudioï¼Œä¹Ÿæ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            is_audio_file = False
            if audio_duration is not None and audio_bitrate is not None:
                is_audio_file = True
            elif file_name and any(file_name.lower().endswith(ext) for ext in ['.mp3', '.m4a', '.flac', '.wav', '.ogg', '.aac', '.wma', '.opus']):
                is_audio_file = True
                logger.info(f"é€šè¿‡æ–‡ä»¶æ‰©å±•åæ£€æµ‹åˆ°éŸ³é¢‘æ–‡ä»¶: {file_name}")
            
            # æ”¹è¿›è§†é¢‘æ£€æµ‹ï¼šä¸ä»…æ£€æŸ¥DocumentAttributeVideoï¼Œä¹Ÿæ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            is_video_file = False
            if video_width is not None and video_height is not None:
                is_video_file = True
            elif file_name and any(file_name.lower().endswith(ext) for ext in ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.3gp', '.ts']):
                is_video_file = True
                logger.info(f"é€šè¿‡æ–‡ä»¶æ‰©å±•åæ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶: {file_name}")
            
            if is_audio_file:
                # éŸ³é¢‘æ–‡ä»¶æ”¾åœ¨telegram/musicæ–‡ä»¶å¤¹
                download_path = os.path.join(self.downloader.download_path, "telegram", "music")
                logger.info(f"æ£€æµ‹åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œä¸‹è½½è·¯å¾„: {download_path}")
            elif is_video_file:
                # è§†é¢‘æ–‡ä»¶æ”¾åœ¨telegram/videosæ–‡ä»¶å¤¹
                download_path = os.path.join(self.downloader.download_path, "telegram", "videos")
                logger.info(f"æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶ï¼Œä¸‹è½½è·¯å¾„: {download_path}")
            else:
                # å…¶ä»–æ–‡ä»¶æ”¾åœ¨telegramæ–‡ä»¶å¤¹
                download_path = os.path.join(self.downloader.download_path, "telegram")
                logger.info(f"æ£€æµ‹åˆ°å…¶ä»–åª’ä½“æ–‡ä»¶ï¼Œä¸‹è½½è·¯å¾„: {download_path}")
            
            os.makedirs(download_path, exist_ok=True)
            if telethon_message:
                logger.info(f"æ‰¾åˆ°åŒ¹é…çš„Telethonæ¶ˆæ¯: {telethon_message.id}ï¼Œå¼€å§‹ä¸‹è½½...")
                
                # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
                logger.info(f"æ¶ˆæ¯ç±»å‹: {type(telethon_message)}")
                logger.info(f"æ¶ˆæ¯åª’ä½“: {type(telethon_message.media) if telethon_message.media else 'None'}")
                if telethon_message.media:
                    logger.info(f"åª’ä½“å±æ€§: {dir(telethon_message.media)}")
                    if hasattr(telethon_message.media, 'document'):
                        logger.info(f"Document: {telethon_message.media.document}")
                    else:
                        logger.info(f"ç›´æ¥åª’ä½“: {telethon_message.media}")
                
                # --- ä¸‹è½½å›è°ƒ (ç»Ÿä¸€ä¸ºè¯¦ç»†æ ·å¼) ---
                last_update_time = time.time()
                last_downloaded = 0
                async def progress(current, total):
                    nonlocal last_update_time, last_downloaded
                    now = time.time()
                    
                    if now - last_update_time < 5 and current != total:
                        return
                    
                    diff_time = now - last_update_time
                    diff_bytes = current - last_downloaded
                    last_update_time = now
                    last_downloaded = current
                    
                    speed_bytes_s = diff_bytes / diff_time if diff_time > 0 else 0
                    speed_mb_s = speed_bytes_s / (1024 * 1024)
                    eta_str = "æœªçŸ¥"
                    if speed_bytes_s > 0:
                        remaining_bytes = total - current
                        try:
                            eta_seconds = remaining_bytes / speed_bytes_s
                            minutes, seconds = divmod(int(eta_seconds), 60)
                            eta_str = f"{minutes:02d}:{seconds:02d}"
                        except (OverflowError, ValueError):
                            eta_str = "æœªçŸ¥"
                    
                    downloaded_mb = current / (1024 * 1024)
                    total_mb = total / (1024 * 1024)
                    # ä¿®å¤ï¼šæ£€æŸ¥file_nameæ˜¯å¦ä¸ºNone
                    display_filename = file_name if file_name else "æœªçŸ¥æ–‡ä»¶"
                    safe_filename = self._escape_markdown(display_filename)
                    percent = current * 100 / total if total > 0 else 0
                    bar = self._make_progress_bar(percent)
                    # ä¸º MarkdownV2 è½¬ä¹‰æ•°å­—ä¸­çš„å°æ•°ç‚¹
                    downloaded_mb_str = f"{downloaded_mb:.2f}".replace('.', r'\.')
                    total_mb_str = f"{total_mb:.2f}".replace('.', r'\.')
                    speed_mb_s_str = f"{speed_mb_s:.2f}".replace('.', r'\.')
                    percent_str = f"{percent:.1f}".replace('.', r'\.')
                    
                    # è½¬ä¹‰eta_str
                    escaped_eta_str = self._escape_markdown(eta_str)
                    progress_text = (
                        f"ğŸ“ æ–‡ä»¶ï¼š`{safe_filename}`\n"
                        f"ğŸ’¾ å¤§å°ï¼š{downloaded_mb_str}MB / {total_mb_str}MB\n"
                        f"âš¡ é€Ÿåº¦ï¼š{speed_mb_s_str}MB/s\n"
                        f"â³ é¢„è®¡å‰©ä½™ï¼š{escaped_eta_str}\n"
                        f"ğŸ“Š è¿›åº¦ï¼š{bar} {percent_str}%"
                    )
                    try:
                        if current != total:
                            await context.bot.edit_message_text(
                                text=progress_text,
                                chat_id=chat_id,
                                message_id=status_message.message_id,
                                parse_mode=ParseMode.MARKDOWN_V2
                            )
                    except Exception as e:
                        if "Message is not modified" not in str(e):
                            logger.warning(f"æ›´æ–°TGä¸‹è½½è¿›åº¦æ—¶å‡ºé”™: {e}")
                
                try:
                    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼Œé˜²æ­¢è¦†ç›–
                    def get_unique_filename(base_path, filename):
                        name, ext = os.path.splitext(filename)
                        counter = 1
                        unique_filename = filename
                        while os.path.exists(os.path.join(base_path, unique_filename)):
                            unique_filename = f"{name}_{counter}{ext}"
                            counter += 1
                        return unique_filename
                
                    unique_file_name = get_unique_filename(download_path, file_name)
                    downloaded_file = await self.user_client.download_media(
                        telethon_message,
                        file=os.path.join(download_path, unique_file_name),
                        progress_callback=progress
                    )
                    if downloaded_file:
                        # ä¸‹è½½æˆåŠŸï¼Œè·å–æ–‡ä»¶ä¿¡æ¯
                        file_size_mb = os.path.getsize(downloaded_file) / (1024 * 1024)

                        # æ£€æŸ¥æ˜¯å¦ä¸ºéŸ³é¢‘æ–‡ä»¶
                        file_extension = os.path.splitext(downloaded_file)[1].lower()
                        is_audio_file = file_extension in ['.mp3', '.flac', '.wav', '.aac', '.ogg', '.m4a', '.wma']

                        logger.info(f"ğŸµ éŸ³é¢‘æ–‡ä»¶æ£€æµ‹: æ–‡ä»¶æ‰©å±•å={file_extension}, æ˜¯å¦ä¸ºéŸ³é¢‘æ–‡ä»¶={is_audio_file}")
                        logger.info(f"ğŸµ Telegramå…ƒæ•°æ®: ç ç‡={audio_bitrate}, æ—¶é•¿={audio_duration}")

                        # å¯¹äºéŸ³é¢‘æ–‡ä»¶ï¼Œå¼ºåˆ¶å°è¯•è·å–éŸ³é¢‘ä¿¡æ¯
                        if is_audio_file:
                            try:
                                logger.info(f"ğŸµ å¼€å§‹æå–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯: {downloaded_file}")
                                media_info = self.downloader.get_media_info(downloaded_file)
                                logger.info(f"ğŸµ get_media_infoè¿”å›: {media_info}")

                                # å¦‚æœæ²¡æœ‰ç ç‡ä¿¡æ¯ï¼Œä»æ–‡ä»¶ä¸­æå–
                                if not audio_bitrate and media_info.get('bit_rate'):
                                    # ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—ï¼Œå¦‚ "320 kbps" -> 320
                                    bit_rate_str = str(media_info.get('bit_rate', ''))
                                    import re
                                    match = re.search(r'(\d+)', bit_rate_str)
                                    if match:
                                        audio_bitrate = int(match.group(1))
                                        logger.info(f"âœ… ä»æ–‡ä»¶æå–åˆ°éŸ³é¢‘ç ç‡: {audio_bitrate}kbps")
                                    else:
                                        logger.warning(f"âš ï¸ æ— æ³•ä»ç ç‡å­—ç¬¦ä¸²æå–æ•°å­—: {bit_rate_str}")

                                # å¦‚æœæ²¡æœ‰æ—¶é•¿ä¿¡æ¯ï¼Œä»æ–‡ä»¶ä¸­æå–
                                if not audio_duration and media_info.get('duration'):
                                    duration_from_file = media_info.get('duration')
                                    # æ£€æŸ¥æ˜¯å¦ä¸ºæ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²ï¼ˆå¦‚ "03:47"ï¼‰
                                    if isinstance(duration_from_file, str) and ':' in duration_from_file:
                                        # è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºç§’æ•°
                                        try:
                                            time_parts = duration_from_file.split(':')
                                            if len(time_parts) == 2:  # MM:SS
                                                minutes, seconds = map(int, time_parts)
                                                audio_duration = minutes * 60 + seconds
                                            elif len(time_parts) == 3:  # HH:MM:SS
                                                hours, minutes, seconds = map(int, time_parts)
                                                audio_duration = hours * 3600 + minutes * 60 + seconds
                                            else:
                                                audio_duration = float(duration_from_file)
                                        except ValueError:
                                            logger.warning(f"âš ï¸ æ— æ³•è§£ææ—¶é•¿å­—ç¬¦ä¸²: {duration_from_file}")
                                    else:
                                        # ç›´æ¥ä½¿ç”¨æ•°å­—æ—¶é•¿
                                        audio_duration = float(duration_from_file)
                                    logger.info(f"âœ… ä»æ–‡ä»¶æå–åˆ°éŸ³é¢‘æ—¶é•¿: {audio_duration}ç§’")

                                # å¦‚æœä»ç„¶æ²¡æœ‰è·å–åˆ°ä¿¡æ¯ï¼Œå°è¯•ä½¿ç”¨ffprobe
                                if not audio_bitrate or not audio_duration:
                                    logger.info(f"ğŸ” å°è¯•ä½¿ç”¨ffprobeè·å–éŸ³é¢‘ä¿¡æ¯")
                                    try:
                                        import subprocess
                                        import json

                                        cmd = [
                                            'ffprobe', '-v', 'quiet', '-print_format', 'json',
                                            '-show_format', '-show_streams', downloaded_file
                                        ]
                                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)

                                        if result.returncode == 0:
                                            probe_data = json.loads(result.stdout)
                                            logger.info(f"ğŸ” ffprobeè¿”å›æ•°æ®: {probe_data}")

                                            # ä»streamsä¸­è·å–éŸ³é¢‘ä¿¡æ¯
                                            for stream in probe_data.get('streams', []):
                                                if stream.get('codec_type') == 'audio':
                                                    if not audio_bitrate and 'bit_rate' in stream:
                                                        audio_bitrate = int(int(stream['bit_rate']) / 1000)  # è½¬æ¢ä¸ºkbps
                                                        logger.info(f"âœ… ffprobeä»streamsè·å–åˆ°ç ç‡: {audio_bitrate}kbps")
                                                    break

                                            # ä»formatä¸­è·å–ç ç‡å’Œæ—¶é•¿ä¿¡æ¯
                                            if 'format' in probe_data:
                                                format_info = probe_data['format']

                                                # å¦‚æœstreamsä¸­æ²¡æœ‰ç ç‡ä¿¡æ¯ï¼Œå°è¯•ä»formatä¸­è·å–
                                                if not audio_bitrate and 'bit_rate' in format_info:
                                                    audio_bitrate = int(int(format_info['bit_rate']) / 1000)  # è½¬æ¢ä¸ºkbps
                                                    logger.info(f"âœ… ffprobeä»formatè·å–åˆ°ç ç‡: {audio_bitrate}kbps")

                                                # è·å–æ—¶é•¿ä¿¡æ¯
                                                if (not audio_duration or not isinstance(audio_duration, (int, float))) and 'duration' in format_info:
                                                    audio_duration = float(format_info['duration'])
                                                    logger.info(f"âœ… ffprobeè·å–åˆ°æ—¶é•¿: {audio_duration}ç§’")
                                        else:
                                            logger.warning(f"âš ï¸ ffprobeæ‰§è¡Œå¤±è´¥: {result.stderr}")
                                    except Exception as ffprobe_error:
                                        logger.warning(f"âš ï¸ ffprobeæ‰§è¡Œå¼‚å¸¸: {ffprobe_error}")

                            except Exception as e:
                                logger.warning(f"âŒ æ— æ³•ä»æ–‡ä»¶æå–éŸ³é¢‘ä¿¡æ¯: {e}")

                        # ç¡®ä¿ audio_duration æ˜¯æ•°å­—ç±»å‹
                        if audio_duration and isinstance(audio_duration, str) and ':' in audio_duration:
                            # å¦‚æœæ˜¯æ—¶é—´å­—ç¬¦ä¸²æ ¼å¼ï¼Œè§£æä¸ºç§’æ•°
                            try:
                                time_parts = audio_duration.split(':')
                                if len(time_parts) == 2:  # MM:SS
                                    minutes, seconds = map(int, time_parts)
                                    audio_duration = minutes * 60 + seconds
                                elif len(time_parts) == 3:  # HH:MM:SS
                                    hours, minutes, seconds = map(int, time_parts)
                                    audio_duration = hours * 3600 + minutes * 60 + seconds
                                logger.info(f"ğŸ”§ è§£ææ—¶é•¿å­—ç¬¦ä¸² '{':'.join(time_parts)}' ä¸º {audio_duration} ç§’")
                            except ValueError as e:
                                logger.warning(f"âš ï¸ æ— æ³•è§£ææ—¶é•¿å­—ç¬¦ä¸² '{audio_duration}': {e}")

                        logger.info(f"ğŸµ æœ€ç»ˆéŸ³é¢‘ä¿¡æ¯: ç ç‡={audio_bitrate}, æ—¶é•¿={audio_duration}")

                        # æ„å»ºæˆåŠŸæ¶ˆæ¯
                        success_text = f"âœ… **æ–‡ä»¶ä¸‹è½½å®Œæˆ**\n\n"
                        success_text += f"ğŸ“ **æ–‡ä»¶å**: `{self._escape_markdown(file_name)}`\n"
                        success_text += f"ğŸ’¾ **æ–‡ä»¶å¤§å°**: `{file_size_mb:.2f}MB`\n"

                        # å¦‚æœæœ‰è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯ï¼Œæ˜¾ç¤ºåœ¨æ–‡ä»¶å¤§å°ä¸‹é¢
                        if video_width and video_height:
                            # åˆ¤æ–­åˆ†è¾¨ç‡ç­‰çº§
                            resolution_label = ""
                            max_dimension = max(video_width, video_height)
                            if max_dimension >= 3840:  # 4K
                                resolution_label = " (4K)"
                            elif max_dimension >= 2560:  # 2K
                                resolution_label = " (2K)"
                            elif max_dimension >= 1920:  # 1080p
                                resolution_label = " (1080p)"
                            elif max_dimension >= 1280:  # 720p
                                resolution_label = " (720p)"
                            elif max_dimension >= 854:   # 480p
                                resolution_label = " (480p)"

                            success_text += f"ğŸ¥ **åˆ†è¾¨ç‡**: `{video_width}x{video_height}{resolution_label}`\n"

                        # å¦‚æœæ˜¯éŸ³é¢‘æ–‡ä»¶ï¼Œæ˜¾ç¤ºç ç‡ä¿¡æ¯
                        if is_audio_file and audio_bitrate:
                            success_text += f"ğŸµ **ç ç‡**: `{self._escape_markdown(str(audio_bitrate))}kbps`\n"

                        # æ˜¾ç¤ºæ—¶é•¿ä¿¡æ¯ï¼ˆéŸ³é¢‘æˆ–è§†é¢‘ï¼‰
                        duration_to_show = audio_duration if is_audio_file else video_duration
                        if duration_to_show:
                            minutes, seconds = divmod(int(duration_to_show), 60)
                            duration_str = f"{minutes:02d}:{seconds:02d}"
                            success_text += f"â±ï¸ **æ—¶é•¿**: `{self._escape_markdown(duration_str)}`\n"

                        success_text += f"ğŸ“ **ä¿å­˜è·¯å¾„**: `{self._escape_markdown(os.path.dirname(downloaded_file))}`"
                        
                        await context.bot.edit_message_text(
                            text=success_text,
                            chat_id=chat_id,
                            message_id=status_message.message_id,
                            parse_mode=ParseMode.MARKDOWN_V2
                        )
                        logger.info(f"âœ… åª’ä½“æ–‡ä»¶ä¸‹è½½å®Œæˆ: {downloaded_file}")
                    else:
                        await context.bot.edit_message_text(
                            text="âŒ ä¸‹è½½å¤±è´¥ï¼šæ— æ³•è·å–æ–‡ä»¶",
                            chat_id=chat_id,
                            message_id=status_message.message_id
                        )
                        logger.error("âŒ åª’ä½“æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼šæ— æ³•è·å–æ–‡ä»¶")
                        
                except Exception as e:
                    logger.error(f"âŒ åª’ä½“æ–‡ä»¶ä¸‹è½½å¤±è´¥: {e}", exc_info=True)
                    await context.bot.edit_message_text(
                        text=f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}",
                        chat_id=chat_id,
                        message_id=status_message.message_id
                    )
            else:
                await context.bot.edit_message_text(
                    text="âŒ æ— æ³•æ‰¾åˆ°åŒ¹é…çš„åª’ä½“æ¶ˆæ¯ï¼Œè¯·é‡è¯•",
                    chat_id=chat_id,
                    message_id=status_message.message_id
                )
                logger.error("âŒ æ— æ³•æ‰¾åˆ°åŒ¹é…çš„Telethonæ¶ˆæ¯")
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†åª’ä½“æ¶ˆæ¯æ—¶å‡ºé”™: {e}", exc_info=True)
            await context.bot.edit_message_text(
                text=f"âŒ å¤„ç†å¤±è´¥: {str(e)}",
                chat_id=chat_id,
                message_id=status_message.message_id
            )

    async def error_handler(self, update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
        """è®°å½•æ‰€æœ‰ PTB æŠ›å‡ºçš„é”™è¯¯å¹¶å¤„ç†ç½‘ç»œé”™è¯¯"""
        error = context.error
        error_msg = str(error)
        error_type = type(error).__name__

        # æ£€æŸ¥æ˜¯å¦ä¸ºç½‘ç»œç›¸å…³é”™è¯¯
        is_network_error = any(keyword in error_msg.lower() for keyword in [
            'connection', 'timeout', 'network', 'remote', 'protocol',
            'httpx', 'telegram', 'api', 'server', 'unavailable',
            'connecterror', 'timeoutexception', 'httperror', 'ssl',
            'dns', 'resolve', 'unreachable', 'refused', 'reset',
            'broken pipe', 'connection reset', 'connection aborted',
            'read timeout', 'write timeout', 'connect timeout',
            'pool timeout', 'proxy', 'gateway', 'service unavailable'
        ])

        if is_network_error:
            logger.warning(f"ğŸŒ æ£€æµ‹åˆ°ç½‘ç»œé”™è¯¯: {error_type}: {error_msg}")
            logger.info("ğŸ”„ ç½‘ç»œé”™è¯¯å°†ç”±å¥åº·æ£€æŸ¥æœºåˆ¶è‡ªåŠ¨å¤„ç†")
        else:
            logger.error(f"âŒ PTB é”™è¯¯: {error_type}: {error_msg}", exc_info=error)

        # å¯¹äºä¸¥é‡çš„ç½‘ç»œé”™è¯¯ï¼Œè§¦å‘ç«‹å³å¥åº·æ£€æŸ¥
        if is_network_error and any(critical in error_msg.lower() for critical in [
            'connection reset', 'connection aborted', 'broken pipe', 'ssl'
        ]):
            logger.warning("ğŸš¨ æ£€æµ‹åˆ°ä¸¥é‡ç½‘ç»œé”™è¯¯ï¼Œè§¦å‘ç«‹å³å¥åº·æ£€æŸ¥")
            # è¿™é‡Œå¯ä»¥è§¦å‘ç«‹å³çš„å¥åº·æ£€æŸ¥ï¼Œä½†è¦é¿å…é€’å½’è°ƒç”¨


class GlobalProgressManager:
    """å…¨å±€è¿›åº¦ç®¡ç†å™¨ï¼Œç»Ÿä¸€ç®¡ç†æ‰€æœ‰ä¸‹è½½ä»»åŠ¡çš„è¿›åº¦æ›´æ–°"""

    def __init__(self):
        self.last_update_time = time.time()
        self.update_interval = 15  # å…¨å±€æ›´æ–°é—´éš”15ç§’
        self.active_downloads = {}  # å­˜å‚¨æ´»è·ƒä¸‹è½½ä»»åŠ¡
        self.lock = asyncio.Lock()

    async def update_progress(
        self, task_id: str, progress_data: dict, context, status_message
    ):
        """æ›´æ–°å•ä¸ªä»»åŠ¡çš„è¿›åº¦"""
        async with self.lock:
            self.active_downloads[task_id] = progress_data

            now = time.time()
            if now - self.last_update_time < self.update_interval:
                return  # æœªåˆ°æ›´æ–°æ—¶é—´

            # æ„å»ºæ±‡æ€»è¿›åº¦æ¶ˆæ¯
            await self._send_summary_progress(context, status_message)
            self.last_update_time = now

    async def _send_summary_progress(self, context, status_message):
        """å‘é€æ±‡æ€»è¿›åº¦æ¶ˆæ¯"""
        if not self.active_downloads:
            return

        total_tasks = len(self.active_downloads)
        completed_tasks = sum(
            1
            for data in self.active_downloads.values()
            if data.get("status") == "finished"
        )

        # æ„å»ºè¿›åº¦æ¶ˆæ¯
        progress_lines = []
        progress_lines.append(f"ğŸ“¦ **æ‰¹é‡ä¸‹è½½è¿›åº¦** ({completed_tasks}/{total_tasks})")

        # æ˜¾ç¤ºå‰3ä¸ªæ´»è·ƒä»»åŠ¡
        active_tasks = [
            data
            for data in self.active_downloads.values()
            if data.get("status") == "downloading"
        ][:3]

        for i, data in enumerate(active_tasks, 1):
            filename = os.path.basename(data.get("filename", "æœªçŸ¥æ–‡ä»¶"))
            progress = data.get("progress", 0)
            speed = data.get("speed", 0)

            if speed and speed > 0:
                speed_mb = speed / (1024 * 1024)
                speed_str = f"{speed_mb:.1f}MB/s"
            else:
                speed_str = "æœªçŸ¥"

            progress_lines.append(f"{i}. `{filename}` - {progress:.1f}% ({speed_str})")

        if len(active_tasks) < total_tasks - completed_tasks:
            remaining = total_tasks - completed_tasks - len(active_tasks)
            progress_lines.append(f"... è¿˜æœ‰ {remaining} ä¸ªä»»åŠ¡è¿›è¡Œä¸­")

        progress_text = "\n".join(progress_lines)

        try:
            await context.bot.edit_message_text(
                text=progress_text,
                chat_id=status_message.chat_id,
                message_id=status_message.message_id,
                parse_mode=ParseMode.MARKDOWN_V2,
            )
        except Exception as e:
            if "Message is not modified" not in str(e) and "Flood control" not in str(
                e
            ):
                logger.warning(f"æ›´æ–°æ±‡æ€»è¿›åº¦å¤±è´¥: {e}")

    def remove_task(self, task_id: str):
        """ç§»é™¤å®Œæˆçš„ä»»åŠ¡"""
        if task_id in self.active_downloads:
            del self.active_downloads[task_id]


# å…¨å±€è¿›åº¦ç®¡ç†å™¨å®ä¾‹
global_progress_manager = GlobalProgressManager()


async def test_network_connectivity():
    """æµ‹è¯•ç½‘ç»œè¿æ¥æ€§"""
    import httpx
    test_urls = [
        "https://api.telegram.org",
        "https://www.google.com",
        "https://1.1.1.1"
    ]

    for url in test_urls:
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(url)
                if response.status_code == 200:
                    logger.info(f"ğŸŸ¢ ç½‘ç»œè¿æ¥æµ‹è¯•æˆåŠŸ: {url}")
                    return True
        except Exception as e:
            logger.warning(f"ğŸŸ¡ ç½‘ç»œè¿æ¥æµ‹è¯•å¤±è´¥: {url} - {e}")
            continue

    logger.error(f"ğŸ”´ æ‰€æœ‰ç½‘ç»œè¿æ¥æµ‹è¯•éƒ½å¤±è´¥")
    return False

async def main():
    """ä¸»å‡½æ•° (å¼‚æ­¥)"""
    # å¯åŠ¨æ—¶ç¯å¢ƒæ£€æŸ¥
    logger.info("ğŸ” å¼€å§‹å¯åŠ¨å‰ç¯å¢ƒæ£€æŸ¥...")

    # æ£€æŸ¥å…³é”®ç¯å¢ƒå˜é‡
    required_env_vars = ["TELEGRAM_BOT_TOKEN"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    if missing_vars:
        logger.error(f"âŒ ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {missing_vars}")
        return

    # æ˜¾ç¤ºç½‘ç»œé‡è¯•é…ç½®
    max_retries = int(os.getenv("TELEGRAM_MAX_RETRIES", "10"))
    base_delay = float(os.getenv("TELEGRAM_BASE_DELAY", "5.0"))
    max_delay = float(os.getenv("TELEGRAM_MAX_DELAY", "300.0"))
    logger.info(f"ğŸ“Š ç½‘ç»œé‡è¯•é…ç½®: æœ€å¤§é‡è¯•={max_retries}, åŸºç¡€å»¶è¿Ÿ={base_delay}s, æœ€å¤§å»¶è¿Ÿ={max_delay}s")

    # æµ‹è¯•ç½‘ç»œè¿æ¥
    logger.info("ğŸ” å¼€å§‹ç½‘ç»œè¿æ¥æµ‹è¯•...")
    if not await test_network_connectivity():
        logger.warning("âš ï¸ ç½‘ç»œè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œä½†å°†ç»§ç»­å°è¯•å¯åŠ¨")
        # ä¸è¦ç›´æ¥é€€å‡ºï¼Œç»§ç»­å°è¯•å¯åŠ¨ï¼Œå¯èƒ½æ˜¯æµ‹è¯•URLçš„é—®é¢˜

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¥åº·æ£€æŸ¥æœåŠ¡å™¨
    enable_health_check = os.getenv("ENABLE_HEALTH_CHECK", "true").lower() == "true"

    if enable_health_check:
        # å¯åŠ¨ Flask health check server in a background thread
        health_thread = threading.Thread(target=run_health_check_server, daemon=True)
        health_thread.start()
        logger.info(
            f"â¤ï¸ å¥åº·æ£€æŸ¥å’Œç™»å½•æœåŠ¡å™¨å·²åœ¨åå°çº¿ç¨‹å¯åŠ¨ï¼Œç«¯å£ {os.getenv('HEALTHCHECK_PORT', 8080)}"
        )
    else:
        logger.info("å¥åº·æ£€æŸ¥æœåŠ¡å™¨å·²ç¦ç”¨")
    bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
    download_path = os.getenv("DOWNLOAD_PATH", "/downloads")
    x_cookies_path = os.getenv("X_COOKIES")
    b_cookies_path = os.getenv("BILIBILI_COOKIES")
    youtube_cookies_path = os.getenv("YOUTUBE_COOKIES")
    douyin_cookies_path = os.getenv("DOUYIN_COOKIES")
    kuaishou_cookies_path = os.getenv("KUAISHOU_COOKIES")

    if not bot_token:
        logger.error("è¯·è®¾ç½® TELEGRAM_BOT_TOKEN ç¯å¢ƒå˜é‡")
        sys.exit(1)

    logger.info(f"ä¸‹è½½è·¯å¾„: {download_path}")
    if x_cookies_path:
        logger.info(f"X Cookies è·¯å¾„: {x_cookies_path}")
    if b_cookies_path:
        logger.info(f"Bilibili Cookies è·¯å¾„: {b_cookies_path}")
    if youtube_cookies_path:
        logger.info(f"ğŸª ä½¿ç”¨YouTube cookies: {youtube_cookies_path}")
    if douyin_cookies_path:
        logger.info(f"ğŸ¬ ä½¿ç”¨æŠ–éŸ³ cookies: {douyin_cookies_path}")
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(douyin_cookies_path):
            file_size = os.path.getsize(douyin_cookies_path)
            logger.info(f"âœ… æŠ–éŸ³ cookies æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {file_size} å­—èŠ‚")
            
            # è¯»å–å¹¶æ˜¾ç¤ºå‰å‡ è¡Œå†…å®¹
            try:
                with open(douyin_cookies_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    logger.info(f"ğŸ“„ æŠ–éŸ³ cookies æ–‡ä»¶åŒ…å« {len(lines)} è¡Œ")
                    if lines:
                        logger.info(f"ğŸ“ ç¬¬ä¸€è¡Œå†…å®¹: {lines[0].strip()}")
                        if len(lines) > 1:
                            logger.info(f"ğŸ“ ç¬¬äºŒè¡Œå†…å®¹: {lines[1].strip()}")
            except Exception as e:
                logger.error(f"âŒ è¯»å–æŠ–éŸ³ cookies æ–‡ä»¶å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ æŠ–éŸ³ cookies æ–‡ä»¶ä¸å­˜åœ¨: {douyin_cookies_path}")
    else:
        logger.warning("âš ï¸ æœªè®¾ç½® DOUYIN_COOKIES ç¯å¢ƒå˜é‡")

    # æ£€æŸ¥å¿«æ‰‹cookies
    if kuaishou_cookies_path:
        logger.info(f"âš¡ ä½¿ç”¨å¿«æ‰‹ cookies: {kuaishou_cookies_path}")
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(kuaishou_cookies_path):
            file_size = os.path.getsize(kuaishou_cookies_path)
            logger.info(f"âœ… å¿«æ‰‹ cookies æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {file_size} å­—èŠ‚")

            # è¯»å–å¹¶æ˜¾ç¤ºå‰å‡ è¡Œå†…å®¹
            try:
                with open(kuaishou_cookies_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    logger.info(f"ğŸ“„ å¿«æ‰‹ cookies æ–‡ä»¶åŒ…å« {len(lines)} è¡Œ")
                    if lines:
                        logger.info(f"ğŸ“ ç¬¬ä¸€è¡Œå†…å®¹: {lines[0].strip()}")
                        if len(lines) > 1:
                            logger.info(f"ğŸ“ ç¬¬äºŒè¡Œå†…å®¹: {lines[1].strip()}")
            except Exception as e:
                logger.error(f"âŒ è¯»å–å¿«æ‰‹ cookies æ–‡ä»¶å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ å¿«æ‰‹ cookies æ–‡ä»¶ä¸å­˜åœ¨: {kuaishou_cookies_path}")
    else:
        logger.warning("âš ï¸ æœªè®¾ç½® KUAISHOU_COOKIES ç¯å¢ƒå˜é‡")

    # åˆ›å»ºä¸‹è½½å™¨å’Œæœºå™¨äºº
    downloader = VideoDownloader(
        download_path, x_cookies_path, b_cookies_path, youtube_cookies_path, douyin_cookies_path, kuaishou_cookies_path
    )
    bot = TelegramBot(bot_token, downloader)

    # ç½‘ç»œé”™è¯¯é‡è¯•æœºåˆ¶ - ä½¿ç”¨æ‚¨çš„é…ç½®å‚æ•°
    max_retries = int(os.getenv("TELEGRAM_MAX_RETRIES", "10"))  # å¢åŠ é‡è¯•æ¬¡æ•°
    base_delay = float(os.getenv("TELEGRAM_BASE_DELAY", "5.0"))  # ä½¿ç”¨æ‚¨çš„åŸºç¡€å»¶è¿Ÿ
    max_delay = float(os.getenv("TELEGRAM_MAX_DELAY", "300.0"))  # ä½¿ç”¨æ‚¨çš„æœ€å¤§å»¶è¿Ÿ
    
    retry_count = 0
    while retry_count < max_retries:
        try:
            logger.info(f"ğŸ”„ å°è¯•å¯åŠ¨Telegram Bot (ç¬¬ {retry_count + 1}/{max_retries} æ¬¡)")

            # åœ¨é‡è¯•å‰æµ‹è¯•ç½‘ç»œè¿æ¥
            if retry_count > 0:
                logger.info("ğŸ” é‡è¯•å‰æµ‹è¯•ç½‘ç»œè¿æ¥...")
                await test_network_connectivity()

            await bot.run()
            logger.info("âœ… Telegram Botå¯åŠ¨æˆåŠŸï¼")
            break  # æˆåŠŸå¯åŠ¨ï¼Œé€€å‡ºé‡è¯•å¾ªç¯

        except Exception as e:
            retry_count += 1
            error_msg = str(e)
            error_type = type(e).__name__

            logger.error(f"âŒ Telegram Botå¯åŠ¨å¤±è´¥ (ç¬¬ {retry_count} æ¬¡): {error_type}: {error_msg}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºç½‘ç»œç›¸å…³é”™è¯¯ - å¢å¼ºé”™è¯¯æ£€æµ‹
            is_network_error = any(keyword in error_msg.lower() for keyword in [
                'connection', 'timeout', 'network', 'remote', 'protocol',
                'httpx', 'telegram', 'api', 'server', 'unavailable',
                'connecterror', 'timeoutexception', 'httperror', 'ssl',
                'dns', 'resolve', 'unreachable', 'refused', 'reset',
                'broken pipe', 'connection reset', 'connection aborted',
                'read timeout', 'write timeout', 'connect timeout',
                'pool timeout', 'proxy', 'gateway', 'service unavailable'
            ])

            if is_network_error and retry_count < max_retries:
                # è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿ
                delay = min(base_delay * (2 ** (retry_count - 1)), max_delay)
                logger.warning(f"ğŸŒ æ£€æµ‹åˆ°ç½‘ç»œé”™è¯¯ï¼Œ{delay:.1f}ç§’åé‡è¯• ({retry_count}/{max_retries})")
                logger.info(f"ğŸ“Š é‡è¯•ç­–ç•¥: åŸºç¡€å»¶è¿Ÿ={base_delay}s, æœ€å¤§å»¶è¿Ÿ={max_delay}s, å½“å‰å»¶è¿Ÿ={delay:.1f}s")
                await asyncio.sleep(delay)
            else:
                # éç½‘ç»œé”™è¯¯æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                if retry_count >= max_retries:
                    logger.error(f"ğŸ’€ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                    logger.error(f"ğŸ’¡ å»ºè®®æ£€æŸ¥: 1) ç½‘ç»œè¿æ¥ 2) Telegram APIè®¿é—® 3) ä»£ç†è®¾ç½® 4) é˜²ç«å¢™é…ç½®")
                else:
                    logger.error(f"ğŸ’€ Telegram Botå¯åŠ¨å¤±è´¥ï¼Œéç½‘ç»œé”™è¯¯: {error_type}")
                raise e


if __name__ == "__main__":
    try:
        update_heartbeat()  # åˆå§‹åŒ–å¿ƒè·³
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("æœºå™¨äººå·²åœæ­¢ã€‚")


















